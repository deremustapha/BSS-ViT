{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYdI7X1ZTFW8"
   },
   "source": [
    "# A Vision Transformer without Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXaPjKytTFXB"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RVFy9lyMTFXC"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'vega-embed': 'https://cdn.jsdelivr.net/npm/vega-embed@6/build/vega-embed.min', 'vega-lite': 'https://cdn.jsdelivr.net/npm/vega-lite@5/build/vega-lite.min', 'vega': 'https://cdn.jsdelivr.net/npm/vega@5/build/vega.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"vega-embed\"], function(vegaEmbed) {\n",
       "\twindow.vegaEmbed = vegaEmbed\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"vega-lite\"], function(vl) {\n",
       "\twindow.vl = vl\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"vega\"], function(vega) {\n",
       "\twindow.vega = vega\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 5;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }    if (((window['vega'] !== undefined) && (!(window['vega'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/vega@5'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['vegaLite'] !== undefined) && (!(window['vegaLite'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/vega-lite@5'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['vegaEmbed'] !== undefined) && (!(window['vegaEmbed'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/vega-embed@6'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.jsdelivr.net/npm/vega@5\", \"https://cdn.jsdelivr.net/npm/vega-lite@5\", \"https://cdn.jsdelivr.net/npm/vega-embed@6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.css\", \"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/debugger.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/widgets.css\"];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n",
       "    },    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'vega-embed': 'https://cdn.jsdelivr.net/npm/vega-embed@6/build/vega-embed.min', 'vega-lite': 'https://cdn.jsdelivr.net/npm/vega-lite@5/build/vega-lite.min', 'vega': 'https://cdn.jsdelivr.net/npm/vega@5/build/vega.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"vega-embed\"], function(vegaEmbed) {\n\twindow.vegaEmbed = vegaEmbed\n\ton_load()\n      })\n      require([\"vega-lite\"], function(vl) {\n\twindow.vl = vl\n\ton_load()\n      })\n      require([\"vega\"], function(vega) {\n\twindow.vega = vega\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 5;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['vega'] !== undefined) && (!(window['vega'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/vega@5'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['vegaLite'] !== undefined) && (!(window['vegaLite'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/vega-lite@5'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['vegaEmbed'] !== undefined) && (!(window['vegaEmbed'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/vega-embed@6'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.jsdelivr.net/npm/vega@5\", \"https://cdn.jsdelivr.net/npm/vega-lite@5\", \"https://cdn.jsdelivr.net/npm/vega-embed@6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.css\", \"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/debugger.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/widgets.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from emgdecompy.decomposition import *\n",
    "from emgdecompy.contrast import *\n",
    "from emgdecompy.viz import *\n",
    "from emgdecompy.preprocessing import *\n",
    "from db1_preprocess_utils import *\n",
    "from feature_extraction import *\n",
    "from experiment_one_utils import *\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.signal import stft\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Setting seed for reproducibiltiy\n",
    "SEED = 42\n",
    "keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfBMfVPwTFXD"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Gux4BYkhTFXE"
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    # DATA\n",
    "    batch_size = 36 \n",
    "    buffer_size = batch_size * 2\n",
    "    num_classes = 34\n",
    "    \n",
    "\n",
    "    # ARCHITECTURE\n",
    "    patch_size = 4\n",
    "    projected_dim = 96\n",
    "    num_shift_blocks_per_stages = [2, 4, 8, 2]\n",
    "    epsilon = 1e-5\n",
    "    stochastic_depth_rate = 0.2\n",
    "    mlp_dropout_rate = 0.2\n",
    "    num_div = 12\n",
    "    shift_pixel = 1\n",
    "    mlp_expand_ratio = 2\n",
    "\n",
    "    # OPTIMIZER\n",
    "    lr_start = 1e-5\n",
    "    lr_max = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    # TRAINING\n",
    "    epochs = 150\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8bQMiLSDTFXE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################\n",
      "Loading subject 1\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17152, 128, 102, 1)\n",
      "The input label shape is (17152,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Training samples: 17152\n",
      "Validation samples: 4288\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\\\AI-Workspace\\\\sEMGClassification\\\\GestureClassificationUsingCViT\\\\data\\\\DB1\\\\raw'\n",
    "\n",
    "signal_type='raw'\n",
    "input_type='raw'\n",
    "n_channels=64\n",
    "low_cut=20\n",
    "high_cut=50\n",
    "order=6 \n",
    "window_length=50\n",
    "overlap=50\n",
    "fs=2048\n",
    "\n",
    "whiten=False\n",
    "center=True\n",
    "extend=True\n",
    "extend_size=1\n",
    "normalize=False\n",
    "mu=0\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "start_subject = 1\n",
    "total_subject = 20\n",
    "session=[1,2]\n",
    "ratio = 0.2\n",
    "\n",
    "noise_db = [5,10,15]\n",
    "std = 1\n",
    "type_of_experiment = 3\n",
    "\n",
    "X_train, y_label, X_test, y_test = get_experiment_data(path, subjects=start_subject, sessions=session,\n",
    "                                                       signal_type='raw', input_type=input_type, \n",
    "                                                       channels=n_channels, low_cut=20, high_cut=500,\n",
    "                                                      order=6, window_size=window_length, overlap=overlap, fs=fs, \n",
    "                                                      extend=extend, center=center, \n",
    "                                                      extend_size=extend_size, whiten=whiten,\n",
    "                                                      normalize=False, mu=0, ratio=ratio)\n",
    "\n",
    "input_size = X_train.shape[0:]\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcNKAkSjTFXG"
   },
   "source": [
    "#### The MLP block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wnHOJVXBTFXG"
   },
   "outputs": [],
   "source": [
    "class MLP(layers.Layer):\n",
    "    \"\"\"Get the MLP layer for each shift block.\n",
    "\n",
    "    Args:\n",
    "        mlp_expand_ratio (int): The ratio with which the first feature map is expanded.\n",
    "        mlp_dropout_rate (float): The rate for dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mlp_expand_ratio, mlp_dropout_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_expand_ratio = mlp_expand_ratio\n",
    "        self.mlp_dropout_rate = mlp_dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_channels = input_shape[-1]\n",
    "        initial_filters = int(self.mlp_expand_ratio * input_channels)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=initial_filters, activation=tf.nn.gelu,),\n",
    "                layers.Dropout(rate=self.mlp_dropout_rate),\n",
    "                layers.Dense(units=input_channels),\n",
    "                layers.Dropout(rate=self.mlp_dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7uxZ01hTFXH"
   },
   "source": [
    "#### The DropPath layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BV6bd-2kTFXH"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DropPath(layers.Layer):\n",
    "    \"\"\"Drop Path also known as the Stochastic Depth layer.\n",
    "\n",
    "    Refernece:\n",
    "        - https://keras.io/examples/vision/cct/#stochastic-depth-for-regularization\n",
    "        - github.com:rwightman/pytorch-image-models\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, drop_path_prob, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_path_prob = drop_path_prob\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_path_prob\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EylUSDgsTFXI"
   },
   "outputs": [],
   "source": [
    "class ShiftViTBlock(layers.Layer):\n",
    "    \"\"\"A unit ShiftViT Block\n",
    "\n",
    "    Args:\n",
    "        shift_pixel (int): The number of pixels to shift. Default to 1.\n",
    "        mlp_expand_ratio (int): The ratio with which MLP features are\n",
    "            expanded. Default to 2.\n",
    "        mlp_dropout_rate (float): The dropout rate used in MLP.\n",
    "        num_div (int): The number of divisions of the feature map's channel.\n",
    "            Totally, 4/num_div of channels will be shifted. Defaults to 12.\n",
    "        epsilon (float): Epsilon constant.\n",
    "        drop_path_prob (float): The drop probability for drop path.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon,\n",
    "        drop_path_prob,\n",
    "        mlp_dropout_rate,\n",
    "        num_div=12,\n",
    "        shift_pixel=1,\n",
    "        mlp_expand_ratio=2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.shift_pixel = shift_pixel\n",
    "        self.mlp_expand_ratio = mlp_expand_ratio\n",
    "        self.mlp_dropout_rate = mlp_dropout_rate\n",
    "        self.num_div = num_div\n",
    "        self.epsilon = epsilon\n",
    "        self.drop_path_prob = drop_path_prob\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.H = input_shape[1]\n",
    "        self.W = input_shape[2]\n",
    "        self.C = input_shape[3]\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=self.epsilon)\n",
    "        self.drop_path = (\n",
    "            DropPath(drop_path_prob=self.drop_path_prob)\n",
    "            if self.drop_path_prob > 0.0\n",
    "            else layers.Activation(\"linear\")\n",
    "        )\n",
    "        self.mlp = MLP(\n",
    "            mlp_expand_ratio=self.mlp_expand_ratio,\n",
    "            mlp_dropout_rate=self.mlp_dropout_rate,\n",
    "        )\n",
    "\n",
    "    def get_shift_pad(self, x, mode):\n",
    "        \"\"\"Shifts the channels according to the mode chosen.\"\"\"\n",
    "        if mode == \"left\":\n",
    "            offset_height = 0\n",
    "            offset_width = 0\n",
    "            target_height = 0\n",
    "            target_width = self.shift_pixel\n",
    "        elif mode == \"right\":\n",
    "            offset_height = 0\n",
    "            offset_width = self.shift_pixel\n",
    "            target_height = 0\n",
    "            target_width = self.shift_pixel\n",
    "        elif mode == \"up\":\n",
    "            offset_height = 0\n",
    "            offset_width = 0\n",
    "            target_height = self.shift_pixel\n",
    "            target_width = 0\n",
    "        else:\n",
    "            offset_height = self.shift_pixel\n",
    "            offset_width = 0\n",
    "            target_height = self.shift_pixel\n",
    "            target_width = 0\n",
    "        crop = tf.image.crop_to_bounding_box(\n",
    "            x,\n",
    "            offset_height=offset_height,\n",
    "            offset_width=offset_width,\n",
    "            target_height=self.H - target_height,\n",
    "            target_width=self.W - target_width,\n",
    "        )\n",
    "        shift_pad = tf.image.pad_to_bounding_box(\n",
    "            crop,\n",
    "            offset_height=offset_height,\n",
    "            offset_width=offset_width,\n",
    "            target_height=self.H,\n",
    "            target_width=self.W,\n",
    "        )\n",
    "        return shift_pad\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # Split the feature maps\n",
    "        x_splits = tf.split(x, num_or_size_splits=self.C // self.num_div, axis=-1)\n",
    "\n",
    "        # Shift the feature maps\n",
    "        x_splits[0] = self.get_shift_pad(x_splits[0], mode=\"left\")\n",
    "        x_splits[1] = self.get_shift_pad(x_splits[1], mode=\"right\")\n",
    "        x_splits[2] = self.get_shift_pad(x_splits[2], mode=\"up\")\n",
    "        x_splits[3] = self.get_shift_pad(x_splits[3], mode=\"down\")\n",
    "\n",
    "        # Concatenate the shifted and unshifted feature maps\n",
    "        x = tf.concat(x_splits, axis=-1)\n",
    "\n",
    "        # Add the residual connection\n",
    "        shortcut = x\n",
    "        x = shortcut + self.drop_path(self.mlp(self.layer_norm(x)), training=training)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P4IM9hZTFXJ"
   },
   "source": [
    "#### The PatchMerging layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0b9kIabiTFXK"
   },
   "outputs": [],
   "source": [
    "\n",
    "class PatchMerging(layers.Layer):\n",
    "    \"\"\"The Patch Merging layer.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): The epsilon constant.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        filters = 2 * input_shape[-1]\n",
    "        self.reduction = layers.Conv2D(\n",
    "            filters=filters, kernel_size=2, strides=2, padding=\"same\", use_bias=False\n",
    "        )\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=self.epsilon)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply the patch merging algorithm on the feature maps\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.reduction(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17152, 128, 102, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijuL4RoSTFXK"
   },
   "source": [
    "#### Stacked Shift Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l6mYQtrGTFXK"
   },
   "outputs": [],
   "source": [
    "# Note: This layer will have a different depth of stacking\n",
    "# for different stages on the model.\n",
    "class StackedShiftBlocks(layers.Layer):\n",
    "    \"\"\"The layer containing stacked ShiftViTBlocks.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): The epsilon constant.\n",
    "        mlp_dropout_rate (float): The dropout rate used in the MLP block.\n",
    "        num_shift_blocks (int): The number of shift vit blocks for this stage.\n",
    "        stochastic_depth_rate (float): The maximum drop path rate chosen.\n",
    "        is_merge (boolean): A flag that determines the use of the Patch Merge\n",
    "            layer after the shift vit blocks.\n",
    "        num_div (int): The division of channels of the feature map. Defaults to 12.\n",
    "        shift_pixel (int): The number of pixels to shift. Defaults to 1.\n",
    "        mlp_expand_ratio (int): The ratio with which the initial dense layer of\n",
    "            the MLP is expanded Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon,\n",
    "        mlp_dropout_rate,\n",
    "        num_shift_blocks,\n",
    "        stochastic_depth_rate,\n",
    "        is_merge,\n",
    "        num_div=12,\n",
    "        shift_pixel=1,\n",
    "        mlp_expand_ratio=2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.mlp_dropout_rate = mlp_dropout_rate\n",
    "        self.num_shift_blocks = num_shift_blocks\n",
    "        self.stochastic_depth_rate = stochastic_depth_rate\n",
    "        self.is_merge = is_merge\n",
    "        self.num_div = num_div\n",
    "        self.shift_pixel = shift_pixel\n",
    "        self.mlp_expand_ratio = mlp_expand_ratio\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        # Calculate stochastic depth probabilities.\n",
    "        # Reference: https://keras.io/examples/vision/cct/#the-final-cct-model\n",
    "        dpr = [\n",
    "            x\n",
    "            for x in np.linspace(\n",
    "                start=0, stop=self.stochastic_depth_rate, num=self.num_shift_blocks\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Build the shift blocks as a list of ShiftViT Blocks\n",
    "        self.shift_blocks = list()\n",
    "        for num in range(self.num_shift_blocks):\n",
    "            self.shift_blocks.append(\n",
    "                ShiftViTBlock(\n",
    "                    num_div=self.num_div,\n",
    "                    epsilon=self.epsilon,\n",
    "                    drop_path_prob=dpr[num],\n",
    "                    mlp_dropout_rate=self.mlp_dropout_rate,\n",
    "                    shift_pixel=self.shift_pixel,\n",
    "                    mlp_expand_ratio=self.mlp_expand_ratio,\n",
    "                )\n",
    "            )\n",
    "        if self.is_merge:\n",
    "            self.patch_merge = PatchMerging(epsilon=self.epsilon)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for shift_block in self.shift_blocks:\n",
    "            x = shift_block(x, training=training)\n",
    "        if self.is_merge:\n",
    "            x = self.patch_merge(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiRqze8_TFXL"
   },
   "source": [
    "## The ShiftViT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vCeRmE6zTFXL"
   },
   "outputs": [],
   "source": [
    "class ShiftViTModel(keras.Model):\n",
    "    \"\"\"The ShiftViT Model.\n",
    "\n",
    "    Args:\n",
    "        data_augmentation (keras.Model): A data augmentation model.\n",
    "        projected_dim (int): The dimension to which the patches of the image are\n",
    "            projected.\n",
    "        patch_size (int): The patch size of the images.\n",
    "        num_shift_blocks_per_stages (list[int]): A list of all the number of shit\n",
    "            blocks per stage.\n",
    "        epsilon (float): The epsilon constant.\n",
    "        mlp_dropout_rate (float): The dropout rate used in the MLP block.\n",
    "        stochastic_depth_rate (float): The maximum drop rate probability.\n",
    "        num_div (int): The number of divisions of the channesl of the feature\n",
    "            map. Defaults to 12.\n",
    "        shift_pixel (int): The number of pixel to shift. Default to 1.\n",
    "        mlp_expand_ratio (int): The ratio with which the initial mlp dense layer\n",
    "            is expanded to. Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        projected_dim,\n",
    "        patch_size,\n",
    "        num_shift_blocks_per_stages,\n",
    "        epsilon,\n",
    "        mlp_dropout_rate,\n",
    "        stochastic_depth_rate,\n",
    "        num_div=12,\n",
    "        shift_pixel=1,\n",
    "        mlp_expand_ratio=2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_projection = layers.Conv2D(\n",
    "            filters=projected_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.stages = list()\n",
    "        for index, num_shift_blocks in enumerate(num_shift_blocks_per_stages):\n",
    "            if index == len(num_shift_blocks_per_stages) - 1:\n",
    "                # This is the last stage, do not use the patch merge here.\n",
    "                is_merge = False\n",
    "            else:\n",
    "                is_merge = True\n",
    "            # Build the stages.\n",
    "            self.stages.append(\n",
    "                StackedShiftBlocks(\n",
    "                    epsilon=epsilon,\n",
    "                    mlp_dropout_rate=mlp_dropout_rate,\n",
    "                    num_shift_blocks=num_shift_blocks,\n",
    "                    stochastic_depth_rate=stochastic_depth_rate,\n",
    "                    is_merge=is_merge,\n",
    "                    num_div=num_div,\n",
    "                    shift_pixel=shift_pixel,\n",
    "                    mlp_expand_ratio=mlp_expand_ratio,\n",
    "                )\n",
    "            )\n",
    "        self.global_avg_pool = layers.GlobalAveragePooling2D()\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"patch_projection\": self.patch_projection,\n",
    "                \"stages\": self.stages,\n",
    "                \"global_avg_pool\": self.global_avg_pool,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def _calculate_loss(self, data, training=False):\n",
    "        (images, labels) = data\n",
    "\n",
    "        # Create patches and project the pathces.\n",
    "        projected_patches = self.patch_projection(images)\n",
    "\n",
    "        # Pass through the stages\n",
    "        x = projected_patches\n",
    "        for stage in self.stages:\n",
    "            x = stage(x, training=training)\n",
    "\n",
    "        # Get the logits.\n",
    "        logits = self.global_avg_pool(x)\n",
    "\n",
    "        # Calculate the loss and return it.\n",
    "        total_loss = self.compiled_loss(labels, logits)\n",
    "        return total_loss, labels, logits\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, labels, logits = self._calculate_loss(\n",
    "                data=inputs, training=True\n",
    "            )\n",
    "\n",
    "        # Apply gradients.\n",
    "        train_vars = [\n",
    "            self.patch_projection.trainable_variables,\n",
    "            self.global_avg_pool.trainable_variables,\n",
    "        ]\n",
    "        train_vars = train_vars + [stage.trainable_variables for stage in self.stages]\n",
    "\n",
    "        # Optimize the gradients.\n",
    "        grads = tape.gradient(total_loss, train_vars)\n",
    "        trainable_variable_list = []\n",
    "        for (grad, var) in zip(grads, train_vars):\n",
    "            for g, v in zip(grad, var):\n",
    "                trainable_variable_list.append((g, v))\n",
    "        self.optimizer.apply_gradients(trainable_variable_list)\n",
    "\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(labels, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        _, labels, logits = self._calculate_loss(data=data, training=False)\n",
    "\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(labels, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAM-XfFeTFXM"
   },
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8tPoJlzRTFXM"
   },
   "outputs": [],
   "source": [
    "model = ShiftViTModel(\n",
    "    projected_dim=config.projected_dim,\n",
    "    patch_size=config.patch_size,\n",
    "    num_shift_blocks_per_stages=config.num_shift_blocks_per_stages,\n",
    "    epsilon=config.epsilon,\n",
    "    mlp_dropout_rate=config.mlp_dropout_rate,\n",
    "    stochastic_depth_rate=config.stochastic_depth_rate,\n",
    "    num_div=config.num_div,\n",
    "    shift_pixel=config.shift_pixel,\n",
    "    mlp_expand_ratio=config.mlp_expand_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXJ77G1-TFXM"
   },
   "source": [
    "## Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QYAlXS7CTFXN"
   },
   "outputs": [],
   "source": [
    "# Some code is taken from:\n",
    "# https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2.\n",
    "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"A LearningRateSchedule that uses a warmup cosine decay schedule.\"\"\"\n",
    "\n",
    "    def __init__(self, lr_start, lr_max, warmup_steps, total_steps):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lr_start: The initial learning rate\n",
    "            lr_max: The maximum learning rate to which lr should increase to in\n",
    "                the warmup steps\n",
    "            warmup_steps: The number of steps for which the model warms up\n",
    "            total_steps: The total number of steps for the model training\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lr_start = lr_start\n",
    "        self.lr_max = lr_max\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.pi = tf.constant(np.pi)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # Check whether the total number of steps is larger than the warmup\n",
    "        # steps. If not, then throw a value error.\n",
    "        if self.total_steps < self.warmup_steps:\n",
    "            raise ValueError(\n",
    "                f\"Total number of steps {self.total_steps} must be\"\n",
    "                + f\"larger or equal to warmup steps {self.warmup_steps}.\"\n",
    "            )\n",
    "\n",
    "        # `cos_annealed_lr` is a graph that increases to 1 from the initial\n",
    "        # step to the warmup step. After that this graph decays to -1 at the\n",
    "        # final step mark.\n",
    "        cos_annealed_lr = tf.cos(\n",
    "            self.pi\n",
    "            * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
    "            / tf.cast(self.total_steps - self.warmup_steps, tf.float32)\n",
    "        )\n",
    "\n",
    "        # Shift the mean of the `cos_annealed_lr` graph to 1. Now the grpah goes\n",
    "        # from 0 to 2. Normalize the graph with 0.5 so that now it goes from 0\n",
    "        # to 1. With the normalized graph we scale it with `lr_max` such that\n",
    "        # it goes from 0 to `lr_max`\n",
    "        learning_rate = 0.5 * self.lr_max * (1 + cos_annealed_lr)\n",
    "\n",
    "        # Check whether warmup_steps is more than 0.\n",
    "        if self.warmup_steps > 0:\n",
    "            # Check whether lr_max is larger that lr_start. If not, throw a value\n",
    "            # error.\n",
    "            if self.lr_max < self.lr_start:\n",
    "                raise ValueError(\n",
    "                    f\"lr_start {self.lr_start} must be smaller or\"\n",
    "                    + f\"equal to lr_max {self.lr_max}.\"\n",
    "                )\n",
    "\n",
    "            # Calculate the slope with which the learning rate should increase\n",
    "            # in the warumup schedule. The formula for slope is m = ((b-a)/steps)\n",
    "            slope = (self.lr_max - self.lr_start) / self.warmup_steps\n",
    "\n",
    "            # With the formula for a straight line (y = mx+c) build the warmup\n",
    "            # schedule\n",
    "            warmup_rate = slope * tf.cast(step, tf.float32) + self.lr_start\n",
    "\n",
    "            # When the current step is lesser that warmup steps, get the line\n",
    "            # graph. When the current step is greater than the warmup steps, get\n",
    "            # the scaled cos graph.\n",
    "            learning_rate = tf.where(\n",
    "                step < self.warmup_steps, warmup_rate, learning_rate\n",
    "            )\n",
    "\n",
    "        # When the current step is more that the total steps, return 0 else return\n",
    "        # the calculated graph.\n",
    "        return tf.where(\n",
    "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "total_steps = int((int(input_size[0]) / n_batches) * n_epochs)\n",
    "\n",
    "# Calculate the number of steps for warmup.\n",
    "warmup_epoch_percentage = 0.15\n",
    "warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "\n",
    "# Initialize the warmupcosine schedule.\n",
    "scheduled_lrs = WarmUpCosine(lr_start=lr_start, lr_max=lr_max, warmup_steps=warmup_steps, total_steps=total_steps)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "optimizer = tfa.optimizers.AdamW(learning_rate=scheduled_lrs, weight_decay=weight_decay)\n",
    "model.compile(optimizer=optimizer,\n",
    "                      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])\n",
    "\n",
    "history = model.fit(X_train[train], y_train[train], batch_size=n_batches, \n",
    "                            epochs= n_epochs, verbose=1, \n",
    "                            callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD2XZMxmTFXN"
   },
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(input_size, n_folds, n_batches, n_epochs, start_subject, total_subject, session, path, \n",
    "                       input_type,n_channels, extend, extend_size, center, whiten, ratio, noise_db, std,\n",
    "                       dims, patch_size, num_shift_blocks_per_stages,\n",
    "                        epsilon, mlp_dropout_rate, stochastic_depth_rate, num_div, shift_pixel,\n",
    "                        mlp_expand_ratio, type_of_experiment, lr_start, lr_max, weight_decay):\n",
    "   \n",
    "    \n",
    "    if  type_of_experiment == 1:\n",
    "        print('************************************************')\n",
    "        print('Experiment One')\n",
    "        print('************************************************')\n",
    "    elif type_of_experiment == 2:\n",
    "        print('************************************************')\n",
    "        print('Experiment Two')\n",
    "        print('************************************************')\n",
    "    elif type_of_experiment == 3:\n",
    "        print('************************************************')\n",
    "        print('Experiment Three')\n",
    "        print('************************************************')\n",
    "    else:\n",
    "        print('************************************************')\n",
    "        print('Enter Valid Experiment')\n",
    "        print('************************************************')\n",
    "        \n",
    "        \n",
    "    result = pd.DataFrame({\n",
    "    'Subject': [0],\n",
    "    'Validation_accuracy': [0],\n",
    "    'No_noise': [0],\n",
    "    '5_dB': [0],\n",
    "    '10_dB': [0],\n",
    "    '15_dB': [0],\n",
    "    'Fold_1': [0],\n",
    "    'Fold_2': [0],\n",
    "    'Fold_3': [0]\n",
    "    })\n",
    "    \n",
    "            \n",
    "    total_steps = int((int(input_size[0]) / n_batches) * n_epochs)\n",
    "\n",
    "    # Calculate the number of steps for warmup.\n",
    "    warmup_epoch_percentage = 0.15\n",
    "    warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "\n",
    "    # Initialize the warmupcosine schedule.\n",
    "    scheduled_lrs = WarmUpCosine(lr_start=lr_start, lr_max=lr_max, warmup_steps=warmup_steps, total_steps=total_steps)\n",
    "    \n",
    "    \n",
    "    for s in range(start_subject, (total_subject+1)):\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = get_experiment_data(path, subjects=s, sessions=session,\n",
    "                                                       signal_type='raw', input_type=input_type, \n",
    "                                                       channels=n_channels, low_cut=20, high_cut=500,\n",
    "                                                      order=6, window_size=50, overlap=50, fs=2048, \n",
    "                                                      extend=extend,  extend_size=extend_size, \n",
    "                                                      center=center, whiten=whiten,\n",
    "                                                      normalize=False, mu=0, ratio=ratio)\n",
    "\n",
    "    \n",
    "        #X_train, y_train, X_test, y_test = spilt_data(data, label, ratio)\n",
    "        if input_type == 'raw':\n",
    "            print('Adding noise to RAW input test data')\n",
    "            X_test = np.expand_dims(X_test, axis=3)\n",
    "            X_test_1 = add_noise_all_channel(X_test, noise_db[0], std)\n",
    "            X_test_2 = add_noise_all_channel(X_test, noise_db[1], std)\n",
    "            X_test_3 = add_noise_all_channel(X_test, noise_db[2], std)\n",
    "            \n",
    "            print(\"Size of the input test data is {}\".format(X_test_3.shape))\n",
    "      \n",
    "            \n",
    "        elif input_type == 'tkeo':\n",
    "            print('Adding noise to  TKEO input test data')\n",
    "            X_test = tkeo_image(X_test)\n",
    "            X_test = np.expand_dims(X_test, axis=3)\n",
    "            \n",
    "            X_test_1 = add_noise_all_channel(X_test, noise_db[0], std)\n",
    "            X_test_2 = add_noise_all_channel(X_test, noise_db[1], std)\n",
    "            X_test_3 = add_noise_all_channel(X_test, noise_db[2], std)\n",
    "            \n",
    "            \n",
    "            print(\"Size of the input test data is {}\".format(X_test_3.shape))\n",
    "\n",
    "            \n",
    "        elif input_type == 'stft':\n",
    "            print('Adding noise to STFT input test data')\n",
    "            \n",
    "            \n",
    "            X_test_1 = add_noise_all_channel(X_test, noise_db[0], std)\n",
    "            X_test_1 = stft_image(X_test_1, samples=X_test_1.shape[2])\n",
    "            \n",
    "            X_test_2 = add_noise_all_channel(X_test, noise_db[1], std)\n",
    "            X_test_2 = stft_image(X_test_2, samples=X_test_2.shape[2])\n",
    "            \n",
    "            X_test_3 = add_noise_all_channel(X_test, noise_db[2], std)\n",
    "            X_test_3 = stft_image(X_test_3, samples=X_test_3.shape[2])\n",
    "            \n",
    "            X_test = stft_image(X_test, samples=X_test.shape[2])\n",
    "            \n",
    "            \n",
    "            print(\"Size of the input test data is {}\".format(X_test_3.shape))\n",
    "            \n",
    "        else:\n",
    "            print('Use correct input type')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get the optimizer.\n",
    "        optimizer = tfa.optimizers.AdamW(learning_rate=scheduled_lrs, weight_decay=weight_decay)\n",
    "        \n",
    "        kfold = KFold(n_splits=n_folds, shuffle=False)\n",
    "        accuracy_per_fold = []\n",
    "        loss_per_fold = []\n",
    "        fold_no = 1\n",
    "        \n",
    "        convergence_speed = []\n",
    "        \n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=10, mode=\"auto\")\n",
    "        \n",
    "        for train, test in kfold.split(X_train, y_train):\n",
    "        \n",
    "            \n",
    "            \n",
    "            model = ShiftViTModel(\n",
    "            projected_dim=dims,\n",
    "            patch_size=patch_size,\n",
    "            num_shift_blocks_per_stages=num_shift_blocks_per_stages,\n",
    "            epsilon=epsilon,\n",
    "            mlp_dropout_rate=mlp_dropout_rate,\n",
    "            stochastic_depth_rate=stochastic_depth_rate,\n",
    "            num_div=num_div,\n",
    "            shift_pixel=shift_pixel,\n",
    "            mlp_expand_ratio=mlp_expand_ratio,\n",
    "            )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            model.compile(optimizer=optimizer,\n",
    "                          loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])\n",
    "            \n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} -------')\n",
    "            \n",
    "            history = model.fit(X_train[train], y_train[train], batch_size=n_batches, \n",
    "                                epochs= n_epochs, verbose=1, \n",
    "                                callbacks=callback)\n",
    "            \n",
    "            conv_speed = len(history.history['accuracy'])\n",
    "            convergence_speed.append(conv_speed)\n",
    "            \n",
    "            scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "            print(f'Score for fold  {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "            accuracy_per_fold.append(scores[1] *100)\n",
    "            loss_per_fold.append(scores[0])\n",
    "                  \n",
    "            fold_no = fold_no + 1\n",
    "        \n",
    "        print(\"Average Score per fold \")\n",
    "    \n",
    "        for i in range(0, len(accuracy_per_fold)):\n",
    "            print('-----------------------------------------------')\n",
    "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
    "        print('-----------------------------------------------')\n",
    "        print('Average Metrics for all folds: ')\n",
    "        print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
    "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "        print('-----------------------------------------------')\n",
    "        \n",
    "        print('************************************************')\n",
    "        print(f'For subject {s} without noise')\n",
    "        scores_0 = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print('The loss is {} and accuracy is {}%'.format(scores_0[0], (scores_0[1]*100)))\n",
    "        print(f'For subject {s} and noise 5 dB')\n",
    "        scores_1 = model.evaluate(X_test_1, y_test, verbose=0)\n",
    "        print('The loss is {} and accuracy is {}%'.format(scores_1[0], (scores_1[1]*100)))\n",
    "        print(f'For subject {s} and noise 10 dB')\n",
    "        scores_2 = model.evaluate(X_test_2, y_test, verbose=0)\n",
    "        print('The loss is {} and accuracy is {}%'.format(scores_2[0], (scores_2[1]*100)))\n",
    "        print(f'For subject {s} and noise 15 dB')  \n",
    "        scores_3 = model.evaluate(X_test_3, y_test, verbose=0) \n",
    "        print('The loss is {} and accuracy is {}%'.format(scores_3[0], (scores_3[1]*100)))\n",
    "        print('************************************************') \n",
    "\n",
    "        \n",
    "        result.at[s-1, 'Subject'] =  s\n",
    "        result.at[s-1, 'Validation_accuracy'] =  np.mean(accuracy_per_fold)       \n",
    "        result.at[s-1, 'No_noise'] =  scores_0[1]*100             \n",
    "        result.at[s-1, '5_dB'] =  scores_1[1]*100    \n",
    "        result.at[s-1, '10_dB'] =  scores_2[1]*100\n",
    "        result.at[s-1, '15_dB'] =  scores_3[1]*100   \n",
    "        \n",
    "        result.at[s-1, 'Fold_1'] =  convergence_speed[0]\n",
    "        result.at[s-1, 'Fold_2'] =  convergence_speed[1]\n",
    "        result.at[s-1, 'Fold_3'] =  convergence_speed[2] \n",
    "        \n",
    "        save_path = 'without_attention_raw_all.csv'\n",
    "        result.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "Experiment Three\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 1\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17152, 128, 102, 1)\n",
      "The input label shape is (17152,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4288, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 101s 175ms/step - loss: 4.2236 - accuracy: 0.0270\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 3.6007 - accuracy: 0.0526\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 54s 170ms/step - loss: 3.0593 - accuracy: 0.1554\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 52s 164ms/step - loss: 1.9768 - accuracy: 0.4354\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 51s 161ms/step - loss: 1.1459 - accuracy: 0.6789\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 70s 222ms/step - loss: 0.7784 - accuracy: 0.7802\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 54s 170ms/step - loss: 0.5922 - accuracy: 0.8378\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 52s 163ms/step - loss: 0.4888 - accuracy: 0.8653\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 53s 166ms/step - loss: 0.3942 - accuracy: 0.8935\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 53s 166ms/step - loss: 0.3403 - accuracy: 0.9048\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 52s 164ms/step - loss: 0.3219 - accuracy: 0.9091\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 51s 161ms/step - loss: 0.2870 - accuracy: 0.9206\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 57s 180ms/step - loss: 0.2811 - accuracy: 0.9227\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 60s 190ms/step - loss: 0.2322 - accuracy: 0.9356\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 148s 466ms/step - loss: 0.2228 - accuracy: 0.9385\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.2181 - accuracy: 0.9387\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 51s 159ms/step - loss: 0.2249 - accuracy: 0.9358\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1891 - accuracy: 0.9447\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1795 - accuracy: 0.9469\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 51s 159ms/step - loss: 0.1804 - accuracy: 0.9474\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 51s 161ms/step - loss: 0.1620 - accuracy: 0.9527\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 51s 161ms/step - loss: 0.1816 - accuracy: 0.9453\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1294 - accuracy: 0.9621\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 51s 159ms/step - loss: 0.1513 - accuracy: 0.9545\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1403 - accuracy: 0.9610\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1240 - accuracy: 0.9624\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 51s 159ms/step - loss: 0.1501 - accuracy: 0.9548\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1260 - accuracy: 0.9615\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1118 - accuracy: 0.9655\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1106 - accuracy: 0.9680\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 51s 159ms/step - loss: 0.1175 - accuracy: 0.9627\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.1181 - accuracy: 0.9636\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 51s 161ms/step - loss: 0.1115 - accuracy: 0.9662\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 51s 159ms/step - loss: 0.1075 - accuracy: 0.9660\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.0730 - accuracy: 0.9761\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 51s 160ms/step - loss: 0.0834 - accuracy: 0.9759\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 53s 167ms/step - loss: 0.0931 - accuracy: 0.9702\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 51s 161ms/step - loss: 0.0541 - accuracy: 0.9859\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 52s 163ms/step - loss: 0.0901 - accuracy: 0.9729\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 52s 162ms/step - loss: 0.0705 - accuracy: 0.9780\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 55s 173ms/step - loss: 0.0678 - accuracy: 0.9794\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 53s 168ms/step - loss: 0.0491 - accuracy: 0.9874\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.0787 - accuracy: 0.9741\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 57s 178ms/step - loss: 0.0527 - accuracy: 0.9856\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 75s 238ms/step - loss: 0.0532 - accuracy: 0.9839\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 52s 164ms/step - loss: 0.0637 - accuracy: 0.9818\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 52s 162ms/step - loss: 0.0656 - accuracy: 0.9797\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 65s 203ms/step - loss: 0.0444 - accuracy: 0.9872\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 61s 191ms/step - loss: 0.0361 - accuracy: 0.9891\n",
      "Epoch 50/150\n",
      "318/318 [==============================] - 59s 185ms/step - loss: 0.0529 - accuracy: 0.9854\n",
      "Epoch 51/150\n",
      "318/318 [==============================] - 55s 172ms/step - loss: 0.0494 - accuracy: 0.9849\n",
      "Epoch 52/150\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.0604 - accuracy: 0.9811\n",
      "Epoch 53/150\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.0495 - accuracy: 0.9860\n",
      "Epoch 54/150\n",
      "318/318 [==============================] - 51s 159ms/step - loss: 0.0313 - accuracy: 0.9900\n",
      "Epoch 55/150\n",
      "318/318 [==============================] - 53s 165ms/step - loss: 0.0302 - accuracy: 0.9921\n",
      "Epoch 56/150\n",
      "318/318 [==============================] - 52s 165ms/step - loss: 0.0475 - accuracy: 0.9841\n",
      "Epoch 57/150\n",
      "318/318 [==============================] - 55s 173ms/step - loss: 0.0438 - accuracy: 0.9870\n",
      "Epoch 58/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0576 - accuracy: 0.9833\n",
      "Epoch 59/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0441 - accuracy: 0.9874\n",
      "Epoch 60/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0233 - accuracy: 0.9932\n",
      "Epoch 61/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0194 - accuracy: 0.9950\n",
      "Epoch 62/150\n",
      "318/318 [==============================] - 46s 145ms/step - loss: 0.0516 - accuracy: 0.9843\n",
      "Epoch 63/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0446 - accuracy: 0.9874\n",
      "Epoch 64/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0269 - accuracy: 0.9936\n",
      "Epoch 65/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0374 - accuracy: 0.9900\n",
      "Epoch 66/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0519 - accuracy: 0.9843\n",
      "Epoch 67/150\n",
      "318/318 [==============================] - 47s 146ms/step - loss: 0.0505 - accuracy: 0.9851\n",
      "Epoch 68/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0183 - accuracy: 0.9958\n",
      "Epoch 69/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0193 - accuracy: 0.9946\n",
      "Epoch 70/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0337 - accuracy: 0.9915\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0587 - accuracy: 0.9822\n",
      "Epoch 72/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0321 - accuracy: 0.9906\n",
      "Epoch 73/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0192 - accuracy: 0.9957\n",
      "Epoch 74/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0269 - accuracy: 0.9929\n",
      "Epoch 75/150\n",
      "318/318 [==============================] - 47s 148ms/step - loss: 0.0306 - accuracy: 0.9911\n",
      "Epoch 76/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0419 - accuracy: 0.9881\n",
      "Epoch 77/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0346 - accuracy: 0.9898\n",
      "Epoch 78/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0271 - accuracy: 0.9932\n",
      "Score for fold  1: loss of 0.030169272795319557; accuracy of 99.05561208724976%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 62s 137ms/step - loss: 4.6381 - accuracy: 0.0282\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 3.6097 - accuracy: 0.0322\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 3.5830 - accuracy: 0.0295\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 3.5729 - accuracy: 0.0297\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 3.5334 - accuracy: 0.0374\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 3.3861 - accuracy: 0.0617\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.1611 - accuracy: 0.1119\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 2.7493 - accuracy: 0.2122\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 2.1259 - accuracy: 0.3676\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 1.3913 - accuracy: 0.5686\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.8761 - accuracy: 0.7235\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.5957 - accuracy: 0.8189\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.4560 - accuracy: 0.8616\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.3778 - accuracy: 0.8889\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.3308 - accuracy: 0.9014\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.2739 - accuracy: 0.9195\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.2728 - accuracy: 0.9195\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.2362 - accuracy: 0.9320\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.2108 - accuracy: 0.9386\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1957 - accuracy: 0.9424\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1911 - accuracy: 0.9454\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1658 - accuracy: 0.9536\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1576 - accuracy: 0.9553\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1561 - accuracy: 0.9553\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 46s 145ms/step - loss: 0.1466 - accuracy: 0.9569\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.1324 - accuracy: 0.9639\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1197 - accuracy: 0.9669\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1265 - accuracy: 0.9635\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1173 - accuracy: 0.9660\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1184 - accuracy: 0.9655\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1162 - accuracy: 0.9673\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0985 - accuracy: 0.9725\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0851 - accuracy: 0.9780\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0852 - accuracy: 0.9766\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0851 - accuracy: 0.9764\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0826 - accuracy: 0.9774\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0744 - accuracy: 0.9787\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0647 - accuracy: 0.9823\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0627 - accuracy: 0.9839\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0598 - accuracy: 0.9824\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0494 - accuracy: 0.9875\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0541 - accuracy: 0.9858\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0475 - accuracy: 0.9878\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0507 - accuracy: 0.9863\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0542 - accuracy: 0.9864\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0488 - accuracy: 0.9872\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0386 - accuracy: 0.9903\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0324 - accuracy: 0.9929\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0336 - accuracy: 0.9908\n",
      "Epoch 50/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0507 - accuracy: 0.9870\n",
      "Epoch 51/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0302 - accuracy: 0.9926\n",
      "Epoch 52/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0483 - accuracy: 0.9873\n",
      "Epoch 53/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0308 - accuracy: 0.9916\n",
      "Epoch 54/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0402 - accuracy: 0.9895\n",
      "Epoch 55/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0369 - accuracy: 0.9906\n",
      "Epoch 56/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0293 - accuracy: 0.9935\n",
      "Epoch 57/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0276 - accuracy: 0.9933\n",
      "Epoch 58/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0304 - accuracy: 0.9934\n",
      "Epoch 59/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0255 - accuracy: 0.9948\n",
      "Epoch 60/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0495 - accuracy: 0.9877\n",
      "Epoch 61/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0285 - accuracy: 0.9939\n",
      "Epoch 62/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0250 - accuracy: 0.9953\n",
      "Epoch 63/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0453 - accuracy: 0.9888\n",
      "Epoch 64/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0201 - accuracy: 0.9969\n",
      "Epoch 65/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0173 - accuracy: 0.9968\n",
      "Epoch 66/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0364 - accuracy: 0.9919\n",
      "Epoch 67/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0461 - accuracy: 0.9896\n",
      "Epoch 68/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0223 - accuracy: 0.9953\n",
      "Epoch 69/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0330 - accuracy: 0.9918\n",
      "Epoch 70/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0193 - accuracy: 0.9966\n",
      "Epoch 71/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0511 - accuracy: 0.9869\n",
      "Epoch 72/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0249 - accuracy: 0.9946\n",
      "Epoch 73/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0193 - accuracy: 0.9966\n",
      "Epoch 74/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0277 - accuracy: 0.9941\n",
      "Score for fold  2: loss of 0.050383519381284714; accuracy of 98.7755835056305%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 62s 138ms/step - loss: 3.9831 - accuracy: 0.0349\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 3.4882 - accuracy: 0.0563\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 3.3096 - accuracy: 0.0848\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 3.0130 - accuracy: 0.1427\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 2.4419 - accuracy: 0.2847\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 1.7718 - accuracy: 0.4765\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 1.2533 - accuracy: 0.6253\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.8562 - accuracy: 0.7579\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.5941 - accuracy: 0.8316\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.4456 - accuracy: 0.8826\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.3591 - accuracy: 0.9055\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.2935 - accuracy: 0.9254\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.2565 - accuracy: 0.9346\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.2189 - accuracy: 0.9451\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1946 - accuracy: 0.9514\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1745 - accuracy: 0.9587\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1605 - accuracy: 0.9596\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1482 - accuracy: 0.9644\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1363 - accuracy: 0.9668\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1102 - accuracy: 0.9765\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1141 - accuracy: 0.9735\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0993 - accuracy: 0.9808\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1049 - accuracy: 0.9763\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0944 - accuracy: 0.9794\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0877 - accuracy: 0.9815\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0866 - accuracy: 0.9822\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0737 - accuracy: 0.9863\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0930 - accuracy: 0.9800\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0854 - accuracy: 0.9835\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0803 - accuracy: 0.9848\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0743 - accuracy: 0.9866\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0774 - accuracy: 0.9865\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0772 - accuracy: 0.9857\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0742 - accuracy: 0.9867\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0850 - accuracy: 0.9824\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0784 - accuracy: 0.9868\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0720 - accuracy: 0.9886\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0755 - accuracy: 0.9883\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0734 - accuracy: 0.9898\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0823 - accuracy: 0.9864\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0844 - accuracy: 0.9875\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0829 - accuracy: 0.9866\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0848 - accuracy: 0.9876\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0949 - accuracy: 0.9837\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0904 - accuracy: 0.9878\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0940 - accuracy: 0.9858\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1029 - accuracy: 0.9836\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1089 - accuracy: 0.9848\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1103 - accuracy: 0.9842\n",
      "Score for fold  3: loss of 0.08224499225616455; accuracy of 98.09340834617615%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.030169272795319557 - Accuracy: 99.05561208724976%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.050383519381284714 - Accuracy: 98.7755835056305%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.08224499225616455 - Accuracy: 98.09340834617615%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 98.64153464635213 (+- 0.40409226037245854)\n",
      "> Loss: 0.05426592814425627\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 1 without noise\n",
      "The loss is 0.09612154960632324 and accuracy is 97.78451323509216%\n",
      "For subject 1 and noise 5 dB\n",
      "The loss is 0.22615639865398407 and accuracy is 96.66511416435242%\n",
      "For subject 1 and noise 10 dB\n",
      "The loss is 0.20672357082366943 and accuracy is 96.7350721359253%\n",
      "For subject 1 and noise 15 dB\n",
      "The loss is 0.21289825439453125 and accuracy is 96.57182693481445%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 2\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17279, 128, 102, 1)\n",
      "The input label shape is (17279,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4320, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 63s 138ms/step - loss: 4.2318 - accuracy: 0.0280\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 3.5589 - accuracy: 0.0569\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 2.9221 - accuracy: 0.1735\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 2.3402 - accuracy: 0.3204\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 45s 139ms/step - loss: 1.9280 - accuracy: 0.4338\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 1.5496 - accuracy: 0.5537\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 1.2698 - accuracy: 0.6304\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 1.0201 - accuracy: 0.7064\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.8485 - accuracy: 0.7588\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.7273 - accuracy: 0.7880\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.6196 - accuracy: 0.8239\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.5354 - accuracy: 0.8478\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 44s 137ms/step - loss: 0.5125 - accuracy: 0.8486\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.4542 - accuracy: 0.8660\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 44s 137ms/step - loss: 0.4135 - accuracy: 0.8779\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.3939 - accuracy: 0.8837\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.3637 - accuracy: 0.8882\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.3215 - accuracy: 0.9075\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.3227 - accuracy: 0.9029\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.2846 - accuracy: 0.9151\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.2934 - accuracy: 0.9084\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.2670 - accuracy: 0.9193\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.2339 - accuracy: 0.9291\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.2389 - accuracy: 0.9257\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2352 - accuracy: 0.9267\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.2253 - accuracy: 0.9315\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.2233 - accuracy: 0.9338\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1852 - accuracy: 0.9437\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2173 - accuracy: 0.9329\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1936 - accuracy: 0.9389\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1904 - accuracy: 0.9394\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1856 - accuracy: 0.9439\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1669 - accuracy: 0.9495\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1757 - accuracy: 0.9411\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1600 - accuracy: 0.9482\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1388 - accuracy: 0.9573\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1377 - accuracy: 0.9572\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1287 - accuracy: 0.9594\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1063 - accuracy: 0.9668\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1019 - accuracy: 0.9700\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1379 - accuracy: 0.9567\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1084 - accuracy: 0.9687\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1034 - accuracy: 0.9684\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0904 - accuracy: 0.9715\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0916 - accuracy: 0.9725\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0956 - accuracy: 0.9720\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1040 - accuracy: 0.9671\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0709 - accuracy: 0.9773\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0638 - accuracy: 0.9819\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1024 - accuracy: 0.9674\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0909 - accuracy: 0.9727\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0828 - accuracy: 0.9743\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0651 - accuracy: 0.9799\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0666 - accuracy: 0.9794\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0805 - accuracy: 0.9760\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0610 - accuracy: 0.9817\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0748 - accuracy: 0.9768\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0625 - accuracy: 0.9813\n",
      "Epoch 59/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0544 - accuracy: 0.9845\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0696 - accuracy: 0.9782\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0660 - accuracy: 0.9797\n",
      "Epoch 62/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0610 - accuracy: 0.9826\n",
      "Epoch 63/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0538 - accuracy: 0.9841\n",
      "Epoch 64/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0663 - accuracy: 0.9816\n",
      "Epoch 65/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0694 - accuracy: 0.9786\n",
      "Epoch 66/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0727 - accuracy: 0.9786\n",
      "Epoch 67/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0437 - accuracy: 0.9876\n",
      "Epoch 68/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0501 - accuracy: 0.9842\n",
      "Epoch 69/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0570 - accuracy: 0.9831\n",
      "Epoch 70/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0509 - accuracy: 0.9856\n",
      "Epoch 71/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0634 - accuracy: 0.9811\n",
      "Epoch 72/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0417 - accuracy: 0.9895\n",
      "Epoch 73/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0423 - accuracy: 0.9888\n",
      "Epoch 74/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0535 - accuracy: 0.9846\n",
      "Epoch 75/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0600 - accuracy: 0.9822\n",
      "Epoch 76/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0573 - accuracy: 0.9825\n",
      "Epoch 77/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0391 - accuracy: 0.9898\n",
      "Epoch 78/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0561 - accuracy: 0.9836\n",
      "Epoch 79/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0402 - accuracy: 0.9891\n",
      "Epoch 80/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0356 - accuracy: 0.9910\n",
      "Epoch 81/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0623 - accuracy: 0.9813\n",
      "Epoch 82/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0476 - accuracy: 0.9861\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0670 - accuracy: 0.9806\n",
      "Epoch 84/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0273 - accuracy: 0.9945\n",
      "Epoch 85/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0385 - accuracy: 0.9897\n",
      "Epoch 86/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0484 - accuracy: 0.9873\n",
      "Epoch 87/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0437 - accuracy: 0.9889\n",
      "Epoch 88/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0637 - accuracy: 0.9812\n",
      "Epoch 89/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0410 - accuracy: 0.9890\n",
      "Epoch 90/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0379 - accuracy: 0.9900\n",
      "Epoch 91/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0371 - accuracy: 0.9905\n",
      "Epoch 92/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0476 - accuracy: 0.9870\n",
      "Epoch 93/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0379 - accuracy: 0.9905\n",
      "Epoch 94/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0511 - accuracy: 0.9866\n",
      "Score for fold  1: loss of 0.07923278957605362; accuracy of 97.65625%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 62s 138ms/step - loss: 4.5179 - accuracy: 0.0319\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 3.4742 - accuracy: 0.0584\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 3.3000 - accuracy: 0.0774\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 3.0946 - accuracy: 0.1149\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 2.7925 - accuracy: 0.1781\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 2.4397 - accuracy: 0.2786\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 2.1094 - accuracy: 0.3707\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 1.7648 - accuracy: 0.4682\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 1.4426 - accuracy: 0.5592\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 1.1848 - accuracy: 0.6339\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.9445 - accuracy: 0.7109\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.7608 - accuracy: 0.7687\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.6015 - accuracy: 0.8176\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.4979 - accuracy: 0.8510\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.4111 - accuracy: 0.8790\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.3609 - accuracy: 0.8950\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.3176 - accuracy: 0.9068\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2763 - accuracy: 0.9211\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2543 - accuracy: 0.9277\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.2243 - accuracy: 0.9348\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2035 - accuracy: 0.9410\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1872 - accuracy: 0.9463\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.1760 - accuracy: 0.9498\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1535 - accuracy: 0.9564\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.1463 - accuracy: 0.9591\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1296 - accuracy: 0.9653\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1167 - accuracy: 0.9682\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1077 - accuracy: 0.9715\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1266 - accuracy: 0.9659\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1059 - accuracy: 0.9707\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1070 - accuracy: 0.9717\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0882 - accuracy: 0.9748\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0895 - accuracy: 0.9749\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1025 - accuracy: 0.9707\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0741 - accuracy: 0.9810\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0691 - accuracy: 0.9812\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0838 - accuracy: 0.9773\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0647 - accuracy: 0.9831\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0690 - accuracy: 0.9828\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0610 - accuracy: 0.9851\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0729 - accuracy: 0.9806\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0611 - accuracy: 0.9849\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0642 - accuracy: 0.9837\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0634 - accuracy: 0.9844\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0722 - accuracy: 0.9814\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0559 - accuracy: 0.9859\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0463 - accuracy: 0.9894\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0607 - accuracy: 0.9853\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0538 - accuracy: 0.9871\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0465 - accuracy: 0.9883\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0634 - accuracy: 0.9842\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0581 - accuracy: 0.9848\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0608 - accuracy: 0.9847\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0436 - accuracy: 0.9915\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0507 - accuracy: 0.9887\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0513 - accuracy: 0.9889\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0434 - accuracy: 0.9911\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0534 - accuracy: 0.9876\n",
      "Epoch 59/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0467 - accuracy: 0.9891\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0525 - accuracy: 0.9878\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0533 - accuracy: 0.9885\n",
      "Epoch 62/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0461 - accuracy: 0.9911\n",
      "Epoch 63/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0417 - accuracy: 0.9919\n",
      "Epoch 64/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0528 - accuracy: 0.9884\n",
      "Epoch 65/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0444 - accuracy: 0.9909\n",
      "Epoch 66/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0585 - accuracy: 0.9873\n",
      "Epoch 67/150\n",
      "320/320 [==============================] - 47s 145ms/step - loss: 0.0397 - accuracy: 0.9926\n",
      "Epoch 68/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0461 - accuracy: 0.9910\n",
      "Epoch 69/150\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0420 - accuracy: 0.9924\n",
      "Epoch 70/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0483 - accuracy: 0.9906\n",
      "Epoch 71/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0580 - accuracy: 0.9879\n",
      "Epoch 72/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0557 - accuracy: 0.9890\n",
      "Epoch 73/150\n",
      "320/320 [==============================] - 45s 142ms/step - loss: 0.0419 - accuracy: 0.9922\n",
      "Epoch 74/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0466 - accuracy: 0.9916\n",
      "Epoch 75/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0429 - accuracy: 0.9924\n",
      "Epoch 76/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0636 - accuracy: 0.9859\n",
      "Epoch 77/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0498 - accuracy: 0.9912\n",
      "Score for fold  2: loss of 0.07982414215803146; accuracy of 97.88194298744202%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 50s 113ms/step - loss: 3.6991 - accuracy: 0.0590\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 2.8398 - accuracy: 0.1688\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 2.1488 - accuracy: 0.3672\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 1.7292 - accuracy: 0.4925\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 1.4401 - accuracy: 0.5870\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 1.2544 - accuracy: 0.6458\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 38s 119ms/step - loss: 1.0741 - accuracy: 0.6998\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 37s 116ms/step - loss: 0.9127 - accuracy: 0.7463\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 0.7928 - accuracy: 0.7857\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.6919 - accuracy: 0.8143\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.6028 - accuracy: 0.8384\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 38s 119ms/step - loss: 0.5482 - accuracy: 0.8572\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 37s 116ms/step - loss: 0.4953 - accuracy: 0.8718\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 38s 118ms/step - loss: 0.4547 - accuracy: 0.8826\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 0.4301 - accuracy: 0.8904\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3938 - accuracy: 0.9012\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3772 - accuracy: 0.9102\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3666 - accuracy: 0.9119\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3499 - accuracy: 0.9144\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3364 - accuracy: 0.9184\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3197 - accuracy: 0.9302\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3214 - accuracy: 0.9284\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 38s 118ms/step - loss: 0.3125 - accuracy: 0.9307\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 0.3150 - accuracy: 0.9331\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.3196 - accuracy: 0.9315\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3143 - accuracy: 0.9342\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3254 - accuracy: 0.9306\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3182 - accuracy: 0.9353\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3359 - accuracy: 0.9285\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3399 - accuracy: 0.9295\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3467 - accuracy: 0.9317\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3659 - accuracy: 0.9253\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3811 - accuracy: 0.9226\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.4026 - accuracy: 0.9234\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.4136 - accuracy: 0.9199\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.4516 - accuracy: 0.9114\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.4679 - accuracy: 0.9134\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.5054 - accuracy: 0.9060\n",
      "Score for fold  3: loss of 0.34011825919151306; accuracy of 92.46397018432617%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.07923278957605362 - Accuracy: 97.65625%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.07982414215803146 - Accuracy: 97.88194298744202%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.34011825919151306 - Accuracy: 92.46397018432617%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 96.00072105725606 (+- 2.5025572766036595)\n",
      "> Loss: 0.16639173030853271\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 2 without noise\n",
      "The loss is 0.34489279985427856 and accuracy is 91.99073910713196%\n",
      "For subject 2 and noise 5 dB\n",
      "The loss is 0.4322645962238312 and accuracy is 90.55555462837219%\n",
      "For subject 2 and noise 10 dB\n",
      "The loss is 0.43827107548713684 and accuracy is 90.41666388511658%\n",
      "For subject 2 and noise 15 dB\n",
      "The loss is 0.4501558542251587 and accuracy is 90.32407402992249%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 3\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (16896, 128, 102, 1)\n",
      "The input label shape is (16896,)\n",
      "The total number of classes is 33\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4224, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "313/313 [==============================] - 61s 136ms/step - loss: 4.1622 - accuracy: 0.0287\n",
      "Epoch 2/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 3.5872 - accuracy: 0.0528\n",
      "Epoch 3/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 2.3460 - accuracy: 0.3020\n",
      "Epoch 4/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 1.5361 - accuracy: 0.5438\n",
      "Epoch 5/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 1.0790 - accuracy: 0.6881\n",
      "Epoch 6/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.8075 - accuracy: 0.7717\n",
      "Epoch 7/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.6378 - accuracy: 0.8217\n",
      "Epoch 8/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.5530 - accuracy: 0.8478\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 43s 138ms/step - loss: 0.4871 - accuracy: 0.8634\n",
      "Epoch 10/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.4357 - accuracy: 0.8786\n",
      "Epoch 11/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.3813 - accuracy: 0.8928\n",
      "Epoch 12/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.3500 - accuracy: 0.8998\n",
      "Epoch 13/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.3557 - accuracy: 0.8948\n",
      "Epoch 14/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2990 - accuracy: 0.9157\n",
      "Epoch 15/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2950 - accuracy: 0.9140\n",
      "Epoch 16/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2580 - accuracy: 0.9283\n",
      "Epoch 17/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2685 - accuracy: 0.9165\n",
      "Epoch 18/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.2482 - accuracy: 0.9269\n",
      "Epoch 19/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2225 - accuracy: 0.9356\n",
      "Epoch 20/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2129 - accuracy: 0.9359\n",
      "Epoch 21/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.2147 - accuracy: 0.9350\n",
      "Epoch 22/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2015 - accuracy: 0.9399\n",
      "Epoch 23/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.1887 - accuracy: 0.9417\n",
      "Epoch 24/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1956 - accuracy: 0.9398\n",
      "Epoch 25/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1747 - accuracy: 0.9499\n",
      "Epoch 26/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1566 - accuracy: 0.9505\n",
      "Epoch 27/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1670 - accuracy: 0.9466\n",
      "Epoch 28/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1641 - accuracy: 0.9513\n",
      "Epoch 29/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1282 - accuracy: 0.9605\n",
      "Epoch 30/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1434 - accuracy: 0.9560\n",
      "Epoch 31/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1520 - accuracy: 0.9521\n",
      "Epoch 32/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1250 - accuracy: 0.9644\n",
      "Epoch 33/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1443 - accuracy: 0.9562\n",
      "Epoch 34/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1067 - accuracy: 0.9670\n",
      "Epoch 35/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1052 - accuracy: 0.9695\n",
      "Epoch 36/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1288 - accuracy: 0.9621\n",
      "Epoch 37/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0906 - accuracy: 0.9739\n",
      "Epoch 38/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.0814 - accuracy: 0.9751\n",
      "Epoch 39/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0706 - accuracy: 0.9796\n",
      "Epoch 40/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0746 - accuracy: 0.9792\n",
      "Epoch 41/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0798 - accuracy: 0.9766\n",
      "Epoch 42/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0916 - accuracy: 0.9724\n",
      "Epoch 43/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0589 - accuracy: 0.9830\n",
      "Epoch 44/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0745 - accuracy: 0.9774\n",
      "Epoch 45/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0799 - accuracy: 0.9752\n",
      "Epoch 46/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0531 - accuracy: 0.9841\n",
      "Epoch 47/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0518 - accuracy: 0.9843\n",
      "Epoch 48/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0698 - accuracy: 0.9787\n",
      "Epoch 49/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0581 - accuracy: 0.9834\n",
      "Epoch 50/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0635 - accuracy: 0.9803\n",
      "Epoch 51/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0600 - accuracy: 0.9815\n",
      "Epoch 52/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0409 - accuracy: 0.9882\n",
      "Epoch 53/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0558 - accuracy: 0.9832\n",
      "Epoch 54/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0576 - accuracy: 0.9830\n",
      "Epoch 55/150\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 0.0455 - accuracy: 0.9876\n",
      "Epoch 56/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0515 - accuracy: 0.9850\n",
      "Epoch 57/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0409 - accuracy: 0.9889\n",
      "Epoch 58/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0407 - accuracy: 0.9884\n",
      "Epoch 59/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0616 - accuracy: 0.9814\n",
      "Epoch 60/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0480 - accuracy: 0.9857\n",
      "Epoch 61/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0366 - accuracy: 0.9905\n",
      "Epoch 62/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0578 - accuracy: 0.9841\n",
      "Epoch 63/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0464 - accuracy: 0.9859\n",
      "Epoch 64/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0359 - accuracy: 0.9905\n",
      "Epoch 65/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0384 - accuracy: 0.9887\n",
      "Epoch 66/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0524 - accuracy: 0.9838\n",
      "Epoch 67/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0332 - accuracy: 0.9894\n",
      "Epoch 68/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0431 - accuracy: 0.9884\n",
      "Epoch 69/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0541 - accuracy: 0.9838\n",
      "Epoch 70/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0227 - accuracy: 0.9943\n",
      "Epoch 71/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0419 - accuracy: 0.9878\n",
      "Epoch 72/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0422 - accuracy: 0.9878\n",
      "Epoch 73/150\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 0.0308 - accuracy: 0.9916\n",
      "Epoch 74/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0261 - accuracy: 0.9935\n",
      "Epoch 75/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0481 - accuracy: 0.9856\n",
      "Epoch 76/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0293 - accuracy: 0.9933\n",
      "Epoch 77/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0432 - accuracy: 0.9871\n",
      "Epoch 78/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0397 - accuracy: 0.9878\n",
      "Epoch 79/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0429 - accuracy: 0.9877\n",
      "Epoch 80/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0253 - accuracy: 0.9941\n",
      "Score for fold  1: loss of 0.07233645021915436; accuracy of 98.17116260528564%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "313/313 [==============================] - 62s 138ms/step - loss: 4.6061 - accuracy: 0.0310\n",
      "Epoch 2/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 3.6033 - accuracy: 0.0312\n",
      "Epoch 3/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 3.5561 - accuracy: 0.0285\n",
      "Epoch 4/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.5491 - accuracy: 0.0300\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 43s 139ms/step - loss: 3.5363 - accuracy: 0.0276\n",
      "Epoch 6/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.5309 - accuracy: 0.0297\n",
      "Epoch 7/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.5283 - accuracy: 0.0295\n",
      "Epoch 8/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.5240 - accuracy: 0.0357\n",
      "Epoch 9/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.5221 - accuracy: 0.0274\n",
      "Epoch 10/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 3.5203 - accuracy: 0.0299\n",
      "Epoch 11/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.5173 - accuracy: 0.0282\n",
      "Epoch 12/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 3.5147 - accuracy: 0.0315\n",
      "Epoch 13/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.5103 - accuracy: 0.0305\n",
      "Epoch 14/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 3.5142 - accuracy: 0.0308\n",
      "Epoch 15/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 3.4936 - accuracy: 0.0380\n",
      "Epoch 16/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 3.3537 - accuracy: 0.0636\n",
      "Epoch 17/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 2.6714 - accuracy: 0.1915\n",
      "Epoch 18/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 2.2640 - accuracy: 0.3018\n",
      "Epoch 19/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 1.8063 - accuracy: 0.4488\n",
      "Epoch 20/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 1.3922 - accuracy: 0.5812\n",
      "Epoch 21/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 1.1009 - accuracy: 0.6714\n",
      "Epoch 22/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.9121 - accuracy: 0.7317\n",
      "Epoch 23/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.7417 - accuracy: 0.7904\n",
      "Epoch 24/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.6134 - accuracy: 0.8275\n",
      "Epoch 25/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.5002 - accuracy: 0.8594\n",
      "Epoch 26/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.4185 - accuracy: 0.8820\n",
      "Epoch 27/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.3742 - accuracy: 0.8913\n",
      "Epoch 28/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.3120 - accuracy: 0.9114\n",
      "Epoch 29/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.2801 - accuracy: 0.9229\n",
      "Epoch 30/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.2438 - accuracy: 0.9304\n",
      "Epoch 31/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2161 - accuracy: 0.9362\n",
      "Epoch 32/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1943 - accuracy: 0.9446\n",
      "Epoch 33/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1773 - accuracy: 0.9512\n",
      "Epoch 34/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1631 - accuracy: 0.9537\n",
      "Epoch 35/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1364 - accuracy: 0.9621\n",
      "Epoch 36/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1318 - accuracy: 0.9632\n",
      "Epoch 37/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1336 - accuracy: 0.9625\n",
      "Epoch 38/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1275 - accuracy: 0.9639\n",
      "Epoch 39/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1054 - accuracy: 0.9727\n",
      "Epoch 40/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1002 - accuracy: 0.9732\n",
      "Epoch 41/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.1019 - accuracy: 0.9733\n",
      "Epoch 42/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0853 - accuracy: 0.9782\n",
      "Epoch 43/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0867 - accuracy: 0.9787\n",
      "Epoch 44/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0812 - accuracy: 0.9782\n",
      "Epoch 45/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0802 - accuracy: 0.9794\n",
      "Epoch 46/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0654 - accuracy: 0.9846\n",
      "Epoch 47/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0840 - accuracy: 0.9780\n",
      "Epoch 48/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0831 - accuracy: 0.9776\n",
      "Epoch 49/150\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 0.0654 - accuracy: 0.9848\n",
      "Epoch 50/150\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.0672 - accuracy: 0.9835\n",
      "Epoch 51/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.0671 - accuracy: 0.9839\n",
      "Epoch 52/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0502 - accuracy: 0.9898\n",
      "Epoch 53/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0565 - accuracy: 0.9868\n",
      "Epoch 54/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0657 - accuracy: 0.9846\n",
      "Epoch 55/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0600 - accuracy: 0.9877\n",
      "Epoch 56/150\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.0598 - accuracy: 0.9860\n",
      "Epoch 57/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0551 - accuracy: 0.9869\n",
      "Epoch 58/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0646 - accuracy: 0.9840\n",
      "Epoch 59/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0538 - accuracy: 0.9870\n",
      "Epoch 60/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0470 - accuracy: 0.9916\n",
      "Epoch 61/150\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0404 - accuracy: 0.9919\n",
      "Epoch 62/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0644 - accuracy: 0.9854\n",
      "Epoch 63/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0489 - accuracy: 0.9898\n",
      "Epoch 64/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0728 - accuracy: 0.9828\n",
      "Epoch 65/150\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.0434 - accuracy: 0.9913\n",
      "Epoch 66/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.0477 - accuracy: 0.9902\n",
      "Epoch 67/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0483 - accuracy: 0.9901\n",
      "Epoch 68/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0396 - accuracy: 0.9936\n",
      "Epoch 69/150\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.0409 - accuracy: 0.9934\n",
      "Epoch 70/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0638 - accuracy: 0.9857\n",
      "Epoch 71/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0431 - accuracy: 0.9922\n",
      "Epoch 72/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0571 - accuracy: 0.9866\n",
      "Epoch 73/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0321 - accuracy: 0.9958\n",
      "Epoch 74/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0503 - accuracy: 0.9899\n",
      "Epoch 75/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0521 - accuracy: 0.9885\n",
      "Epoch 76/150\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0394 - accuracy: 0.9935\n",
      "Epoch 77/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0500 - accuracy: 0.9898\n",
      "Epoch 78/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0436 - accuracy: 0.9924\n",
      "Epoch 79/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0460 - accuracy: 0.9921\n",
      "Epoch 80/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0481 - accuracy: 0.9906\n",
      "Epoch 81/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0466 - accuracy: 0.9925\n",
      "Epoch 82/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0384 - accuracy: 0.9932\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0448 - accuracy: 0.9923\n",
      "Score for fold  2: loss of 0.09740223735570908; accuracy of 97.33664989471436%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "313/313 [==============================] - 63s 141ms/step - loss: 3.9126 - accuracy: 0.0306\n",
      "Epoch 2/150\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 3.5501 - accuracy: 0.0382\n",
      "Epoch 3/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 3.4531 - accuracy: 0.0522\n",
      "Epoch 4/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 2.7150 - accuracy: 0.1827\n",
      "Epoch 5/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 1.8926 - accuracy: 0.4239\n",
      "Epoch 6/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 1.3391 - accuracy: 0.6078\n",
      "Epoch 7/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 1.0268 - accuracy: 0.7054\n",
      "Epoch 8/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.7965 - accuracy: 0.7817\n",
      "Epoch 9/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.6283 - accuracy: 0.8336\n",
      "Epoch 10/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.5213 - accuracy: 0.8608\n",
      "Epoch 11/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.4343 - accuracy: 0.8885\n",
      "Epoch 12/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.3744 - accuracy: 0.9039\n",
      "Epoch 13/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.3313 - accuracy: 0.9184\n",
      "Epoch 14/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.2962 - accuracy: 0.9244\n",
      "Epoch 15/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.2579 - accuracy: 0.9370\n",
      "Epoch 16/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.2345 - accuracy: 0.9418\n",
      "Epoch 17/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.2222 - accuracy: 0.9459\n",
      "Epoch 18/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.2062 - accuracy: 0.9509\n",
      "Epoch 19/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.1907 - accuracy: 0.9572\n",
      "Epoch 20/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1811 - accuracy: 0.9572\n",
      "Epoch 21/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1695 - accuracy: 0.9627\n",
      "Epoch 22/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1638 - accuracy: 0.9617\n",
      "Epoch 23/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1547 - accuracy: 0.9652\n",
      "Epoch 24/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1455 - accuracy: 0.9688\n",
      "Epoch 25/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1369 - accuracy: 0.9718\n",
      "Epoch 26/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1423 - accuracy: 0.9693\n",
      "Epoch 27/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1378 - accuracy: 0.9709\n",
      "Epoch 28/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1387 - accuracy: 0.9721\n",
      "Epoch 29/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1366 - accuracy: 0.9727\n",
      "Epoch 30/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.1436 - accuracy: 0.9700\n",
      "Epoch 31/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1342 - accuracy: 0.9743\n",
      "Epoch 32/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1448 - accuracy: 0.9705\n",
      "Epoch 33/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1341 - accuracy: 0.9767\n",
      "Epoch 34/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.1363 - accuracy: 0.9747\n",
      "Epoch 35/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.1426 - accuracy: 0.9724\n",
      "Epoch 36/150\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.1396 - accuracy: 0.9751\n",
      "Epoch 37/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1484 - accuracy: 0.9726\n",
      "Epoch 38/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1534 - accuracy: 0.9723\n",
      "Epoch 39/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1558 - accuracy: 0.9743\n",
      "Epoch 40/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1610 - accuracy: 0.9711\n",
      "Epoch 41/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1688 - accuracy: 0.9715\n",
      "Epoch 42/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.1710 - accuracy: 0.9699\n",
      "Epoch 43/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1943 - accuracy: 0.9660\n",
      "Score for fold  3: loss of 0.1666492372751236; accuracy of 95.86292505264282%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.07233645021915436 - Accuracy: 98.17116260528564%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.09740223735570908 - Accuracy: 97.33664989471436%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.1666492372751236 - Accuracy: 95.86292505264282%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 97.12357918421428 (+- 0.9543023614530804)\n",
      "> Loss: 0.11212930828332901\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 3 without noise\n",
      "The loss is 0.18800729513168335 and accuracy is 95.54924368858337%\n",
      "For subject 3 and noise 5 dB\n",
      "The loss is 0.2760515809059143 and accuracy is 94.48390007019043%\n",
      "For subject 3 and noise 10 dB\n",
      "The loss is 0.2789876461029053 and accuracy is 94.48390007019043%\n",
      "For subject 3 and noise 15 dB\n",
      "The loss is 0.30180391669273376 and accuracy is 94.15246248245239%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 4\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17279, 128, 102, 1)\n",
      "The input label shape is (17279,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4320, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 65s 139ms/step - loss: 4.2192 - accuracy: 0.0319\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 3.5427 - accuracy: 0.0646\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 2.6660 - accuracy: 0.2173\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 1.7531 - accuracy: 0.4564\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 1.2621 - accuracy: 0.6149\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.9372 - accuracy: 0.7203\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 45s 142ms/step - loss: 0.7433 - accuracy: 0.7788\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 45s 142ms/step - loss: 0.6084 - accuracy: 0.8176\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 45s 142ms/step - loss: 0.5038 - accuracy: 0.8526\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.4253 - accuracy: 0.8788\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.3731 - accuracy: 0.8926\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.3472 - accuracy: 0.8980\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.2923 - accuracy: 0.9146\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.2971 - accuracy: 0.9097\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.2699 - accuracy: 0.9197\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 47s 148ms/step - loss: 0.2398 - accuracy: 0.9274\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.2038 - accuracy: 0.9376\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.2132 - accuracy: 0.9367\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.2162 - accuracy: 0.9345\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.1693 - accuracy: 0.9503\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.2015 - accuracy: 0.9377\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.1773 - accuracy: 0.9483\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.1632 - accuracy: 0.9542\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.1541 - accuracy: 0.9523\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.1565 - accuracy: 0.9529\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.1811 - accuracy: 0.9440\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.1226 - accuracy: 0.9609\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.1318 - accuracy: 0.9584\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1491 - accuracy: 0.9532\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 45s 142ms/step - loss: 0.1206 - accuracy: 0.9618\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.1228 - accuracy: 0.9619\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1204 - accuracy: 0.9613\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0998 - accuracy: 0.9694\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1025 - accuracy: 0.9694\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0940 - accuracy: 0.9714\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1070 - accuracy: 0.9681\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0798 - accuracy: 0.9753\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0655 - accuracy: 0.9787\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0891 - accuracy: 0.9727\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0780 - accuracy: 0.9771\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0725 - accuracy: 0.9780\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0683 - accuracy: 0.9803\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0576 - accuracy: 0.9833\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0615 - accuracy: 0.9807\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0797 - accuracy: 0.9764\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0317 - accuracy: 0.9917\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0457 - accuracy: 0.9878\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0801 - accuracy: 0.9745\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 44s 137ms/step - loss: 0.0614 - accuracy: 0.9827\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0718 - accuracy: 0.9792\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0521 - accuracy: 0.9849\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 44s 137ms/step - loss: 0.0397 - accuracy: 0.9895\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0413 - accuracy: 0.9878\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 44s 137ms/step - loss: 0.0273 - accuracy: 0.9937\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0523 - accuracy: 0.9848\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0599 - accuracy: 0.9821\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0524 - accuracy: 0.9845\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0366 - accuracy: 0.9900\n",
      "Epoch 59/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0410 - accuracy: 0.9891\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 44s 137ms/step - loss: 0.0422 - accuracy: 0.9868\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0595 - accuracy: 0.9815\n",
      "Epoch 62/150\n",
      "320/320 [==============================] - 44s 137ms/step - loss: 0.0242 - accuracy: 0.9937\n",
      "Epoch 63/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0250 - accuracy: 0.9937\n",
      "Epoch 64/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0402 - accuracy: 0.9893\n",
      "Score for fold  1: loss of 0.10195209830999374; accuracy of 97.13541865348816%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 63s 138ms/step - loss: 4.5932 - accuracy: 0.0269\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 3.6354 - accuracy: 0.0284\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 3.5926 - accuracy: 0.0282\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 3.5811 - accuracy: 0.0298\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 3.5658 - accuracy: 0.0294\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 3.5621 - accuracy: 0.0316\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 3.5579 - accuracy: 0.0310\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 3.5562 - accuracy: 0.0311\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 3.5120 - accuracy: 0.0412\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 3.4059 - accuracy: 0.0670\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 3.1693 - accuracy: 0.1111\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 2.8066 - accuracy: 0.1781\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 2.2120 - accuracy: 0.3214\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 1.6708 - accuracy: 0.4689\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 1.2092 - accuracy: 0.6115\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.8590 - accuracy: 0.7271\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.6451 - accuracy: 0.7980\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.5155 - accuracy: 0.8395\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.4184 - accuracy: 0.8717\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.3511 - accuracy: 0.8936\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.2975 - accuracy: 0.9109\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.2642 - accuracy: 0.9225\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.2263 - accuracy: 0.9320\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.2159 - accuracy: 0.9384\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.1872 - accuracy: 0.9475\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1969 - accuracy: 0.9429\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1664 - accuracy: 0.9527\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1630 - accuracy: 0.9522\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1547 - accuracy: 0.9560\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.1302 - accuracy: 0.9648\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1333 - accuracy: 0.9623\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.1325 - accuracy: 0.9641\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1306 - accuracy: 0.9637\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.1053 - accuracy: 0.9724\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.1138 - accuracy: 0.9689\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0924 - accuracy: 0.9738\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0982 - accuracy: 0.9728\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0780 - accuracy: 0.9793\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0680 - accuracy: 0.9824\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0785 - accuracy: 0.9777\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0638 - accuracy: 0.9839\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0619 - accuracy: 0.9836\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0574 - accuracy: 0.9844\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0505 - accuracy: 0.9868\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0450 - accuracy: 0.9889\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0644 - accuracy: 0.9822\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0274 - accuracy: 0.9946\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0509 - accuracy: 0.9869\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0450 - accuracy: 0.9888\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0408 - accuracy: 0.9905\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0633 - accuracy: 0.9819\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0365 - accuracy: 0.9908\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0354 - accuracy: 0.9918\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0410 - accuracy: 0.9893\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0435 - accuracy: 0.9889\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0316 - accuracy: 0.9931\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.0401 - accuracy: 0.9905\n",
      "Score for fold  2: loss of 0.09271614998579025; accuracy of 97.46527671813965%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 50s 112ms/step - loss: 4.2844 - accuracy: 0.0276\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 3.6075 - accuracy: 0.0284\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 3.4663 - accuracy: 0.0535\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 3.1154 - accuracy: 0.1141\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 2.4362 - accuracy: 0.2472\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 1.8759 - accuracy: 0.4011\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 1.3510 - accuracy: 0.5648\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.9185 - accuracy: 0.7145\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.6395 - accuracy: 0.8041\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.4854 - accuracy: 0.8541\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.3859 - accuracy: 0.8860\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3181 - accuracy: 0.9066\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.2760 - accuracy: 0.9198\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.2476 - accuracy: 0.9299\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.2142 - accuracy: 0.9391\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.1959 - accuracy: 0.9473\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.1754 - accuracy: 0.9512\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.1590 - accuracy: 0.9571\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.1524 - accuracy: 0.9579\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1462 - accuracy: 0.9612\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.1284 - accuracy: 0.9674\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1121 - accuracy: 0.9722\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1038 - accuracy: 0.9723\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.1078 - accuracy: 0.9725\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0877 - accuracy: 0.9781\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0931 - accuracy: 0.9773\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0796 - accuracy: 0.9801\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0881 - accuracy: 0.9766\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0715 - accuracy: 0.9821\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0610 - accuracy: 0.9869\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0567 - accuracy: 0.9865\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0688 - accuracy: 0.9826\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0525 - accuracy: 0.9886\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0842 - accuracy: 0.9788\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0559 - accuracy: 0.9878\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0466 - accuracy: 0.9896\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0505 - accuracy: 0.9883\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0459 - accuracy: 0.9908\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0605 - accuracy: 0.9861\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0633 - accuracy: 0.9862\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0552 - accuracy: 0.9865\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0431 - accuracy: 0.9920\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0512 - accuracy: 0.9885\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0543 - accuracy: 0.9897\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0449 - accuracy: 0.9912\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0526 - accuracy: 0.9890\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0505 - accuracy: 0.9895\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0519 - accuracy: 0.9894\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0467 - accuracy: 0.9916\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0451 - accuracy: 0.9912\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0598 - accuracy: 0.9862\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0421 - accuracy: 0.9930\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0581 - accuracy: 0.9882\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0528 - accuracy: 0.9898\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0393 - accuracy: 0.9945\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0640 - accuracy: 0.9865\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0627 - accuracy: 0.9880\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0538 - accuracy: 0.9905\n",
      "Epoch 59/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0497 - accuracy: 0.9911\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0567 - accuracy: 0.9899\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0555 - accuracy: 0.9910\n",
      "Epoch 62/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0643 - accuracy: 0.9885\n",
      "Epoch 63/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0561 - accuracy: 0.9903\n",
      "Epoch 64/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0667 - accuracy: 0.9879\n",
      "Epoch 65/150\n",
      "320/320 [==============================] - 36s 112ms/step - loss: 0.0645 - accuracy: 0.9891\n",
      "Score for fold  3: loss of 0.06180237606167793; accuracy of 98.38513731956482%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.10195209830999374 - Accuracy: 97.13541865348816%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.09271614998579025 - Accuracy: 97.46527671813965%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.06180237606167793 - Accuracy: 98.38513731956482%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 97.66194423039754 (+- 0.5288085783900688)\n",
      "> Loss: 0.08549020811915398\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 4 without noise\n",
      "The loss is 0.05396484211087227 and accuracy is 98.61111044883728%\n",
      "For subject 4 and noise 5 dB\n",
      "The loss is 0.1091788187623024 and accuracy is 97.47685194015503%\n",
      "For subject 4 and noise 10 dB\n",
      "The loss is 0.11558777093887329 and accuracy is 97.29166626930237%\n",
      "For subject 4 and noise 15 dB\n",
      "The loss is 0.13011570274829865 and accuracy is 97.12963104248047%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 5\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17152, 128, 102, 1)\n",
      "The input label shape is (17152,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4288, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 62s 136ms/step - loss: 4.2472 - accuracy: 0.0281\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 3.7183 - accuracy: 0.0318\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 3.5241 - accuracy: 0.0646\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 2.8639 - accuracy: 0.1855\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 2.2252 - accuracy: 0.3382\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 1.6792 - accuracy: 0.4942\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 1.3068 - accuracy: 0.6132\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 1.0586 - accuracy: 0.6879\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.8619 - accuracy: 0.7517\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.7049 - accuracy: 0.7988\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.6175 - accuracy: 0.8238\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.5320 - accuracy: 0.8476\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.4774 - accuracy: 0.8664\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.4335 - accuracy: 0.8751\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.3812 - accuracy: 0.8930\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.3817 - accuracy: 0.8863\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.3606 - accuracy: 0.8907\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3212 - accuracy: 0.9091\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.2952 - accuracy: 0.9159\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.2716 - accuracy: 0.9186\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.2868 - accuracy: 0.9125\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.2565 - accuracy: 0.9238\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.2339 - accuracy: 0.9280\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.2285 - accuracy: 0.9306\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.2101 - accuracy: 0.9361\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.2166 - accuracy: 0.9320\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.2121 - accuracy: 0.9359\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.2351 - accuracy: 0.9278\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1869 - accuracy: 0.9405\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1839 - accuracy: 0.9448\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1843 - accuracy: 0.9439\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1648 - accuracy: 0.9480\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1679 - accuracy: 0.9483\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1675 - accuracy: 0.9474\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1484 - accuracy: 0.9520\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1284 - accuracy: 0.9604\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1107 - accuracy: 0.9661\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1263 - accuracy: 0.9610\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1176 - accuracy: 0.9648\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1145 - accuracy: 0.9645\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1233 - accuracy: 0.9619\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0858 - accuracy: 0.9753\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0963 - accuracy: 0.9709\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1118 - accuracy: 0.9659\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0858 - accuracy: 0.9750\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1023 - accuracy: 0.9689\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0854 - accuracy: 0.9734\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0880 - accuracy: 0.9727\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0659 - accuracy: 0.9815\n",
      "Epoch 50/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0883 - accuracy: 0.9731\n",
      "Epoch 51/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0972 - accuracy: 0.9690\n",
      "Epoch 52/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0615 - accuracy: 0.9828\n",
      "Epoch 53/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0530 - accuracy: 0.9857\n",
      "Epoch 54/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0892 - accuracy: 0.9726\n",
      "Epoch 55/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0799 - accuracy: 0.9759\n",
      "Epoch 56/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0706 - accuracy: 0.9796\n",
      "Epoch 57/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0540 - accuracy: 0.9842\n",
      "Epoch 58/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0547 - accuracy: 0.9844\n",
      "Epoch 59/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0892 - accuracy: 0.9717\n",
      "Epoch 60/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0721 - accuracy: 0.9794\n",
      "Epoch 61/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0475 - accuracy: 0.9867\n",
      "Epoch 62/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0504 - accuracy: 0.9851\n",
      "Epoch 63/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0577 - accuracy: 0.9845\n",
      "Epoch 64/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0844 - accuracy: 0.9771\n",
      "Epoch 65/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0539 - accuracy: 0.9853\n",
      "Epoch 66/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0458 - accuracy: 0.9878\n",
      "Epoch 67/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0401 - accuracy: 0.9898\n",
      "Epoch 68/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0604 - accuracy: 0.9825\n",
      "Epoch 69/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0690 - accuracy: 0.9796\n",
      "Epoch 70/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0424 - accuracy: 0.9888\n",
      "Epoch 71/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0507 - accuracy: 0.9856\n",
      "Epoch 72/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0410 - accuracy: 0.9884\n",
      "Epoch 73/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0553 - accuracy: 0.9854\n",
      "Epoch 74/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0644 - accuracy: 0.9815\n",
      "Epoch 75/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.0411 - accuracy: 0.9898\n",
      "Epoch 76/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0470 - accuracy: 0.9875\n",
      "Epoch 77/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0702 - accuracy: 0.9808\n",
      "Score for fold  1: loss of 0.13865461945533752; accuracy of 95.94263434410095%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 63s 137ms/step - loss: 4.7230 - accuracy: 0.0303\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 3.6222 - accuracy: 0.0297\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 3.5926 - accuracy: 0.0270\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.5694 - accuracy: 0.0303\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 3.5589 - accuracy: 0.0300\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 3.5582 - accuracy: 0.0289\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.5472 - accuracy: 0.0325\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 3.5279 - accuracy: 0.0367\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 3.5040 - accuracy: 0.0446\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 3.3311 - accuracy: 0.0722\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 2.9227 - accuracy: 0.1487\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 2.6523 - accuracy: 0.2094\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 2.3033 - accuracy: 0.2977\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 2.0203 - accuracy: 0.3742\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 1.7211 - accuracy: 0.4630\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 1.4328 - accuracy: 0.5502\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 1.1508 - accuracy: 0.6418\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.9539 - accuracy: 0.7098\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.7610 - accuracy: 0.7688\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.6175 - accuracy: 0.8144\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.5380 - accuracy: 0.8444\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.4423 - accuracy: 0.8671\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.4012 - accuracy: 0.8812\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3519 - accuracy: 0.8958\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.3237 - accuracy: 0.9046\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.2964 - accuracy: 0.9132\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.2684 - accuracy: 0.9241\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.2532 - accuracy: 0.9247\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.2268 - accuracy: 0.9363\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.2199 - accuracy: 0.9351\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1913 - accuracy: 0.9446\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1777 - accuracy: 0.9498\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1665 - accuracy: 0.9524\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1638 - accuracy: 0.9533\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1438 - accuracy: 0.9613\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1438 - accuracy: 0.9578\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1333 - accuracy: 0.9621\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.1367 - accuracy: 0.9599\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1211 - accuracy: 0.9651\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1046 - accuracy: 0.9717\n",
      "Epoch 41/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 44s 137ms/step - loss: 0.1105 - accuracy: 0.9711\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.1119 - accuracy: 0.9676\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0946 - accuracy: 0.9745\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0825 - accuracy: 0.9769\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0872 - accuracy: 0.9775\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0861 - accuracy: 0.9764\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0877 - accuracy: 0.9759\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0755 - accuracy: 0.9802\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0782 - accuracy: 0.9798\n",
      "Epoch 50/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0669 - accuracy: 0.9841\n",
      "Epoch 51/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0699 - accuracy: 0.9820\n",
      "Epoch 52/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0778 - accuracy: 0.9796\n",
      "Epoch 53/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0633 - accuracy: 0.9850\n",
      "Epoch 54/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0653 - accuracy: 0.9844\n",
      "Epoch 55/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.0776 - accuracy: 0.9803\n",
      "Epoch 56/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0599 - accuracy: 0.9860\n",
      "Epoch 57/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0655 - accuracy: 0.9836\n",
      "Epoch 58/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0552 - accuracy: 0.9865\n",
      "Epoch 59/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0750 - accuracy: 0.9822\n",
      "Epoch 60/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0519 - accuracy: 0.9894\n",
      "Epoch 61/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0508 - accuracy: 0.9889\n",
      "Epoch 62/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0564 - accuracy: 0.9869\n",
      "Epoch 63/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0788 - accuracy: 0.9798\n",
      "Epoch 64/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0633 - accuracy: 0.9840\n",
      "Epoch 65/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0476 - accuracy: 0.9906\n",
      "Epoch 66/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0532 - accuracy: 0.9878\n",
      "Epoch 67/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0533 - accuracy: 0.9885\n",
      "Epoch 68/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0638 - accuracy: 0.9845\n",
      "Epoch 69/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0484 - accuracy: 0.9892\n",
      "Epoch 70/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0557 - accuracy: 0.9870\n",
      "Epoch 71/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0679 - accuracy: 0.9846\n",
      "Epoch 72/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0498 - accuracy: 0.9893\n",
      "Epoch 73/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0403 - accuracy: 0.9923\n",
      "Epoch 74/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.0539 - accuracy: 0.9877\n",
      "Epoch 75/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0539 - accuracy: 0.9893\n",
      "Epoch 76/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0581 - accuracy: 0.9865\n",
      "Epoch 77/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.0541 - accuracy: 0.9886\n",
      "Epoch 78/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.0475 - accuracy: 0.9912\n",
      "Epoch 79/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0538 - accuracy: 0.9888\n",
      "Epoch 80/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0558 - accuracy: 0.9872\n",
      "Epoch 81/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0541 - accuracy: 0.9889\n",
      "Epoch 82/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0413 - accuracy: 0.9927\n",
      "Epoch 83/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0552 - accuracy: 0.9892\n",
      "Epoch 84/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0514 - accuracy: 0.9903\n",
      "Epoch 85/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.0575 - accuracy: 0.9890\n",
      "Epoch 86/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 0.0492 - accuracy: 0.9910\n",
      "Epoch 87/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0498 - accuracy: 0.9911\n",
      "Epoch 88/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.0536 - accuracy: 0.9899\n",
      "Epoch 89/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0472 - accuracy: 0.9931\n",
      "Epoch 90/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0620 - accuracy: 0.9879\n",
      "Epoch 91/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0530 - accuracy: 0.9903\n",
      "Epoch 92/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0569 - accuracy: 0.9892\n",
      "Epoch 93/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0581 - accuracy: 0.9898\n",
      "Epoch 94/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0536 - accuracy: 0.9917\n",
      "Epoch 95/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0597 - accuracy: 0.9899\n",
      "Epoch 96/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0562 - accuracy: 0.9899\n",
      "Epoch 97/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.0584 - accuracy: 0.9911\n",
      "Epoch 98/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.0592 - accuracy: 0.9900\n",
      "Epoch 99/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.0623 - accuracy: 0.9891\n",
      "Score for fold  2: loss of 0.0634126290678978; accuracy of 98.30330610275269%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 62s 137ms/step - loss: 3.8386 - accuracy: 0.0390\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 43s 137ms/step - loss: 3.4655 - accuracy: 0.0693\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 3.1768 - accuracy: 0.1202\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 2.5713 - accuracy: 0.2426\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 1.9389 - accuracy: 0.4229\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 1.4682 - accuracy: 0.5688\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 1.1639 - accuracy: 0.6676\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.9554 - accuracy: 0.7319\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 43s 136ms/step - loss: 0.8068 - accuracy: 0.7818\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.7056 - accuracy: 0.8134\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.6239 - accuracy: 0.8375\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.5554 - accuracy: 0.8599\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.5038 - accuracy: 0.8674\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.4731 - accuracy: 0.8826\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.4348 - accuracy: 0.8966\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.4220 - accuracy: 0.9000\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.3996 - accuracy: 0.9076\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 44s 139ms/step - loss: 0.3940 - accuracy: 0.9078\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.3732 - accuracy: 0.9133\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.3637 - accuracy: 0.9190\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3570 - accuracy: 0.9226\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.3565 - accuracy: 0.9221\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3669 - accuracy: 0.9209\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3518 - accuracy: 0.9279\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3664 - accuracy: 0.9256\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.3724 - accuracy: 0.9230\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3831 - accuracy: 0.9225\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.3794 - accuracy: 0.9280\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.4012 - accuracy: 0.9227\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.4169 - accuracy: 0.9199\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.4313 - accuracy: 0.9169\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.4557 - accuracy: 0.9153\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.4839 - accuracy: 0.9124\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.5046 - accuracy: 0.9076\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.5319 - accuracy: 0.9056\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.5744 - accuracy: 0.8980\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 44s 137ms/step - loss: 0.6180 - accuracy: 0.8902\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 44s 138ms/step - loss: 0.6692 - accuracy: 0.8861\n",
      "Score for fold  3: loss of 0.4567132294178009; accuracy of 91.30662679672241%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.13865461945533752 - Accuracy: 95.94263434410095%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.0634126290678978 - Accuracy: 98.30330610275269%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.4567132294178009 - Accuracy: 91.30662679672241%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 95.18418908119202 (+- 2.906293141957044)\n",
      "> Loss: 0.21959349264701208\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 5 without noise\n",
      "The loss is 0.4731615483760834 and accuracy is 90.3917908668518%\n",
      "For subject 5 and noise 5 dB\n",
      "The loss is 0.5433658957481384 and accuracy is 89.15578126907349%\n",
      "For subject 5 and noise 10 dB\n",
      "The loss is 0.5441627502441406 and accuracy is 89.27238583564758%\n",
      "For subject 5 and noise 15 dB\n",
      "The loss is 0.5599507093429565 and accuracy is 88.99253606796265%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 6\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17021, 128, 102, 1)\n",
      "The input label shape is (17021,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4256, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "316/316 [==============================] - 62s 136ms/step - loss: 4.2200 - accuracy: 0.0296\n",
      "Epoch 2/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 3.6562 - accuracy: 0.0455\n",
      "Epoch 3/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 3.0977 - accuracy: 0.1464\n",
      "Epoch 4/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 2.0124 - accuracy: 0.4148\n",
      "Epoch 5/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 1.3900 - accuracy: 0.5920\n",
      "Epoch 6/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 1.0389 - accuracy: 0.7041\n",
      "Epoch 7/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.8396 - accuracy: 0.7584\n",
      "Epoch 8/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.7048 - accuracy: 0.8004\n",
      "Epoch 9/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.6222 - accuracy: 0.8252\n",
      "Epoch 10/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.5045 - accuracy: 0.8563\n",
      "Epoch 11/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.4697 - accuracy: 0.8639\n",
      "Epoch 12/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.4299 - accuracy: 0.8713\n",
      "Epoch 13/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.3794 - accuracy: 0.8893\n",
      "Epoch 14/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.3590 - accuracy: 0.8935\n",
      "Epoch 15/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2951 - accuracy: 0.9156\n",
      "Epoch 16/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.3078 - accuracy: 0.9093\n",
      "Epoch 17/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2773 - accuracy: 0.9177\n",
      "Epoch 18/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.2732 - accuracy: 0.9197\n",
      "Epoch 19/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.2776 - accuracy: 0.9135\n",
      "Epoch 20/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2094 - accuracy: 0.9358\n",
      "Epoch 21/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2414 - accuracy: 0.9261\n",
      "Epoch 22/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.1969 - accuracy: 0.9411\n",
      "Epoch 23/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2192 - accuracy: 0.9326\n",
      "Epoch 24/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2060 - accuracy: 0.9358\n",
      "Epoch 25/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1687 - accuracy: 0.9472\n",
      "Epoch 26/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1953 - accuracy: 0.9382\n",
      "Epoch 27/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1604 - accuracy: 0.9514\n",
      "Epoch 28/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1658 - accuracy: 0.9499\n",
      "Epoch 29/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1866 - accuracy: 0.9432\n",
      "Epoch 30/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1346 - accuracy: 0.9588\n",
      "Epoch 31/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1548 - accuracy: 0.9530\n",
      "Epoch 32/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1549 - accuracy: 0.9521\n",
      "Epoch 33/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1490 - accuracy: 0.9529\n",
      "Epoch 34/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1114 - accuracy: 0.9640\n",
      "Epoch 35/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1465 - accuracy: 0.9537\n",
      "Epoch 36/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0885 - accuracy: 0.9722\n",
      "Epoch 37/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0846 - accuracy: 0.9759\n",
      "Epoch 38/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1063 - accuracy: 0.9667\n",
      "Epoch 39/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0809 - accuracy: 0.9751\n",
      "Epoch 40/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0937 - accuracy: 0.9717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0828 - accuracy: 0.9748\n",
      "Epoch 42/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0746 - accuracy: 0.9782\n",
      "Epoch 43/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0927 - accuracy: 0.9725\n",
      "Epoch 44/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0755 - accuracy: 0.9771\n",
      "Epoch 45/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0718 - accuracy: 0.9786\n",
      "Epoch 46/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0447 - accuracy: 0.9862\n",
      "Epoch 47/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0820 - accuracy: 0.9751\n",
      "Epoch 48/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0519 - accuracy: 0.9852\n",
      "Epoch 49/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0989 - accuracy: 0.9696\n",
      "Epoch 50/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0421 - accuracy: 0.9891\n",
      "Epoch 51/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0402 - accuracy: 0.9885\n",
      "Epoch 52/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0713 - accuracy: 0.9786\n",
      "Epoch 53/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0644 - accuracy: 0.9822\n",
      "Epoch 54/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0537 - accuracy: 0.9840\n",
      "Epoch 55/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0585 - accuracy: 0.9816\n",
      "Epoch 56/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0511 - accuracy: 0.9861\n",
      "Epoch 57/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0430 - accuracy: 0.9870\n",
      "Epoch 58/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0676 - accuracy: 0.9805\n",
      "Epoch 59/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0653 - accuracy: 0.9801\n",
      "Epoch 60/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0369 - accuracy: 0.9892\n",
      "Epoch 61/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0389 - accuracy: 0.9893\n",
      "Epoch 62/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0615 - accuracy: 0.9819\n",
      "Epoch 63/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0493 - accuracy: 0.9870\n",
      "Epoch 64/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0359 - accuracy: 0.9905\n",
      "Epoch 65/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0612 - accuracy: 0.9822\n",
      "Epoch 66/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0411 - accuracy: 0.9884\n",
      "Epoch 67/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0356 - accuracy: 0.9906\n",
      "Epoch 68/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0505 - accuracy: 0.9849\n",
      "Epoch 69/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0336 - accuracy: 0.9901\n",
      "Epoch 70/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0390 - accuracy: 0.9889\n",
      "Epoch 71/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0552 - accuracy: 0.9836\n",
      "Epoch 72/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0450 - accuracy: 0.9883\n",
      "Epoch 73/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0312 - accuracy: 0.9923\n",
      "Epoch 74/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0434 - accuracy: 0.9870\n",
      "Epoch 75/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0351 - accuracy: 0.9900\n",
      "Epoch 76/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.0252 - accuracy: 0.9942\n",
      "Epoch 77/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0662 - accuracy: 0.9803\n",
      "Epoch 78/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0273 - accuracy: 0.9932\n",
      "Epoch 79/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0273 - accuracy: 0.9929\n",
      "Epoch 80/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0436 - accuracy: 0.9878\n",
      "Epoch 81/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.0369 - accuracy: 0.9892\n",
      "Epoch 82/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0392 - accuracy: 0.9882\n",
      "Epoch 83/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0342 - accuracy: 0.9904\n",
      "Epoch 84/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0201 - accuracy: 0.9956\n",
      "Epoch 85/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0533 - accuracy: 0.9854\n",
      "Epoch 86/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.0472 - accuracy: 0.9855\n",
      "Epoch 87/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0288 - accuracy: 0.9925\n",
      "Epoch 88/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 0.0288 - accuracy: 0.9926\n",
      "Epoch 89/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0249 - accuracy: 0.9948\n",
      "Epoch 90/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0354 - accuracy: 0.9895\n",
      "Epoch 91/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0495 - accuracy: 0.9868\n",
      "Epoch 92/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0414 - accuracy: 0.9882\n",
      "Epoch 93/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0173 - accuracy: 0.9959\n",
      "Epoch 94/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0120 - accuracy: 0.9983\n",
      "Epoch 95/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0616 - accuracy: 0.9826\n",
      "Epoch 96/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0364 - accuracy: 0.9906\n",
      "Epoch 97/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0269 - accuracy: 0.9929\n",
      "Epoch 98/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0357 - accuracy: 0.9897\n",
      "Epoch 99/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0352 - accuracy: 0.9907\n",
      "Epoch 100/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0257 - accuracy: 0.9940\n",
      "Epoch 101/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0318 - accuracy: 0.9909\n",
      "Epoch 102/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0304 - accuracy: 0.9922\n",
      "Epoch 103/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0298 - accuracy: 0.9924\n",
      "Epoch 104/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0371 - accuracy: 0.9900\n",
      "Score for fold  1: loss of 0.07149146497249603; accuracy of 98.18470478057861%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "316/316 [==============================] - 63s 137ms/step - loss: 4.5727 - accuracy: 0.0285\n",
      "Epoch 2/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 3.6163 - accuracy: 0.0278\n",
      "Epoch 3/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 3.5831 - accuracy: 0.0282\n",
      "Epoch 4/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 3.5702 - accuracy: 0.0293\n",
      "Epoch 5/150\n",
      "316/316 [==============================] - 43s 138ms/step - loss: 3.5483 - accuracy: 0.0365\n",
      "Epoch 6/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 3.3141 - accuracy: 0.0762\n",
      "Epoch 7/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 2.8522 - accuracy: 0.1749\n",
      "Epoch 8/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 2.4374 - accuracy: 0.2906\n",
      "Epoch 9/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 1.9230 - accuracy: 0.4254\n",
      "Epoch 10/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 1.4783 - accuracy: 0.5540\n",
      "Epoch 11/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 1.1983 - accuracy: 0.6326\n",
      "Epoch 12/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.9271 - accuracy: 0.7204\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 44s 139ms/step - loss: 0.7300 - accuracy: 0.7838\n",
      "Epoch 14/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.5674 - accuracy: 0.8324\n",
      "Epoch 15/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.4828 - accuracy: 0.8581\n",
      "Epoch 16/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.3961 - accuracy: 0.8808\n",
      "Epoch 17/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.3405 - accuracy: 0.9023\n",
      "Epoch 18/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2996 - accuracy: 0.9150\n",
      "Epoch 19/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2667 - accuracy: 0.9237\n",
      "Epoch 20/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2281 - accuracy: 0.9360\n",
      "Epoch 21/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2167 - accuracy: 0.9368\n",
      "Epoch 22/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1899 - accuracy: 0.9447\n",
      "Epoch 23/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1690 - accuracy: 0.9538\n",
      "Epoch 24/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1632 - accuracy: 0.9529\n",
      "Epoch 25/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1422 - accuracy: 0.9595\n",
      "Epoch 26/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1223 - accuracy: 0.9656\n",
      "Epoch 27/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1228 - accuracy: 0.9658\n",
      "Epoch 28/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1183 - accuracy: 0.9651\n",
      "Epoch 29/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0986 - accuracy: 0.9725\n",
      "Epoch 30/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1048 - accuracy: 0.9709\n",
      "Epoch 31/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0848 - accuracy: 0.9769\n",
      "Epoch 32/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0796 - accuracy: 0.9792\n",
      "Epoch 33/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0727 - accuracy: 0.9817\n",
      "Epoch 34/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0945 - accuracy: 0.9743\n",
      "Epoch 35/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0638 - accuracy: 0.9846\n",
      "Epoch 36/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0793 - accuracy: 0.9809\n",
      "Epoch 37/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0719 - accuracy: 0.9809\n",
      "Epoch 38/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0480 - accuracy: 0.9890\n",
      "Epoch 39/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0663 - accuracy: 0.9840\n",
      "Epoch 40/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0629 - accuracy: 0.9853\n",
      "Epoch 41/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0582 - accuracy: 0.9860\n",
      "Epoch 42/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0713 - accuracy: 0.9802\n",
      "Epoch 43/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0550 - accuracy: 0.9878\n",
      "Epoch 44/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0442 - accuracy: 0.9909\n",
      "Epoch 45/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0437 - accuracy: 0.9907\n",
      "Epoch 46/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0534 - accuracy: 0.9883\n",
      "Epoch 47/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0427 - accuracy: 0.9926\n",
      "Epoch 48/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0459 - accuracy: 0.9899\n",
      "Epoch 49/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0658 - accuracy: 0.9833\n",
      "Epoch 50/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0521 - accuracy: 0.9882\n",
      "Epoch 51/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0492 - accuracy: 0.9885\n",
      "Epoch 52/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0478 - accuracy: 0.9896\n",
      "Epoch 53/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.0540 - accuracy: 0.9878\n",
      "Epoch 54/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0413 - accuracy: 0.9919\n",
      "Epoch 55/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0491 - accuracy: 0.9903\n",
      "Epoch 56/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0698 - accuracy: 0.9844\n",
      "Epoch 57/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0367 - accuracy: 0.9938\n",
      "Epoch 58/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0415 - accuracy: 0.9918\n",
      "Epoch 59/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0508 - accuracy: 0.9899\n",
      "Epoch 60/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0449 - accuracy: 0.9910\n",
      "Epoch 61/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0416 - accuracy: 0.9931\n",
      "Epoch 62/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0557 - accuracy: 0.9886\n",
      "Epoch 63/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0487 - accuracy: 0.9905\n",
      "Epoch 64/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0549 - accuracy: 0.9874\n",
      "Epoch 65/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0436 - accuracy: 0.9913\n",
      "Epoch 66/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0459 - accuracy: 0.9923\n",
      "Epoch 67/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0588 - accuracy: 0.9883\n",
      "Score for fold  2: loss of 0.06015485152602196; accuracy of 98.18470478057861%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "316/316 [==============================] - 62s 138ms/step - loss: 3.7993 - accuracy: 0.0448\n",
      "Epoch 2/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 3.2438 - accuracy: 0.1064\n",
      "Epoch 3/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 2.4710 - accuracy: 0.2950\n",
      "Epoch 4/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 1.4687 - accuracy: 0.5775\n",
      "Epoch 5/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.9552 - accuracy: 0.7291\n",
      "Epoch 6/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.7035 - accuracy: 0.8068\n",
      "Epoch 7/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.5768 - accuracy: 0.8420\n",
      "Epoch 8/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.4776 - accuracy: 0.8702\n",
      "Epoch 9/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.4165 - accuracy: 0.8883\n",
      "Epoch 10/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.3727 - accuracy: 0.9032\n",
      "Epoch 11/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.3201 - accuracy: 0.9201\n",
      "Epoch 12/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.3017 - accuracy: 0.9232\n",
      "Epoch 13/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.2817 - accuracy: 0.9262\n",
      "Epoch 14/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.2484 - accuracy: 0.9401\n",
      "Epoch 15/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.2327 - accuracy: 0.9443\n",
      "Epoch 16/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.2200 - accuracy: 0.9468\n",
      "Epoch 17/150\n",
      "316/316 [==============================] - 43s 136ms/step - loss: 0.2094 - accuracy: 0.9489\n",
      "Epoch 18/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.2008 - accuracy: 0.9537\n",
      "Epoch 19/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.1937 - accuracy: 0.9560\n",
      "Epoch 20/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1927 - accuracy: 0.9573\n",
      "Epoch 21/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1836 - accuracy: 0.9595\n",
      "Epoch 22/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 43s 138ms/step - loss: 0.1872 - accuracy: 0.9576\n",
      "Epoch 23/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1817 - accuracy: 0.9593\n",
      "Epoch 24/150\n",
      "316/316 [==============================] - 43s 137ms/step - loss: 0.1805 - accuracy: 0.9630\n",
      "Epoch 25/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1773 - accuracy: 0.9641\n",
      "Epoch 26/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1868 - accuracy: 0.9601\n",
      "Epoch 27/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1831 - accuracy: 0.9618\n",
      "Epoch 28/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1865 - accuracy: 0.9629\n",
      "Epoch 29/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1785 - accuracy: 0.9662\n",
      "Epoch 30/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1923 - accuracy: 0.9621\n",
      "Epoch 31/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1931 - accuracy: 0.9641\n",
      "Epoch 32/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.1960 - accuracy: 0.9656\n",
      "Epoch 33/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2127 - accuracy: 0.9603\n",
      "Epoch 34/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2188 - accuracy: 0.9599\n",
      "Epoch 35/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2302 - accuracy: 0.9585\n",
      "Epoch 36/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2413 - accuracy: 0.9571\n",
      "Epoch 37/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2509 - accuracy: 0.9574\n",
      "Epoch 38/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2682 - accuracy: 0.9557\n",
      "Epoch 39/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.2887 - accuracy: 0.9523\n",
      "Score for fold  3: loss of 0.21545512974262238; accuracy of 94.94094848632812%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.07149146497249603 - Accuracy: 98.18470478057861%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.06015485152602196 - Accuracy: 98.18470478057861%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.21545512974262238 - Accuracy: 94.94094848632812%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 97.10345268249512 (+- 1.529121381454044)\n",
      "> Loss: 0.11570048208038013\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 6 without noise\n",
      "The loss is 0.2239099144935608 and accuracy is 94.7133481502533%\n",
      "For subject 6 and noise 5 dB\n",
      "The loss is 0.29188042879104614 and accuracy is 93.65601539611816%\n",
      "For subject 6 and noise 10 dB\n",
      "The loss is 0.29976415634155273 and accuracy is 93.53853464126587%\n",
      "For subject 6 and noise 15 dB\n",
      "The loss is 0.31231260299682617 and accuracy is 93.30357313156128%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 7\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17408, 128, 102, 1)\n",
      "The input label shape is (17408,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4352, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 63s 136ms/step - loss: 4.2189 - accuracy: 0.0271\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 3.5354 - accuracy: 0.0654\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 2.4413 - accuracy: 0.2743\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 1.7207 - accuracy: 0.4761\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 1.3448 - accuracy: 0.5987\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 1.0889 - accuracy: 0.6687\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.9443 - accuracy: 0.7097\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.8124 - accuracy: 0.7511\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.6828 - accuracy: 0.7986\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.6249 - accuracy: 0.8165\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.5725 - accuracy: 0.8283\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.5147 - accuracy: 0.8414\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.4592 - accuracy: 0.8563\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.4402 - accuracy: 0.8670\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.3872 - accuracy: 0.8786\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.3832 - accuracy: 0.8834\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.3396 - accuracy: 0.8927\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.3202 - accuracy: 0.9018\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2988 - accuracy: 0.9070\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2918 - accuracy: 0.9099\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2711 - accuracy: 0.9143\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.2751 - accuracy: 0.9124\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2332 - accuracy: 0.9268\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2476 - accuracy: 0.9216\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2088 - accuracy: 0.9340\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2030 - accuracy: 0.9393\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2303 - accuracy: 0.9269\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1888 - accuracy: 0.9405\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1928 - accuracy: 0.9384\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1621 - accuracy: 0.9503\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1795 - accuracy: 0.9424\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1674 - accuracy: 0.9454\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1689 - accuracy: 0.9467\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1464 - accuracy: 0.9524\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1421 - accuracy: 0.9539\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1426 - accuracy: 0.9553\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0896 - accuracy: 0.9752\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1448 - accuracy: 0.9538\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1117 - accuracy: 0.9653\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0927 - accuracy: 0.9730\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0924 - accuracy: 0.9717\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1047 - accuracy: 0.9674\n",
      "Epoch 43/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0806 - accuracy: 0.9758\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1068 - accuracy: 0.9668\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0715 - accuracy: 0.9779\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0900 - accuracy: 0.9714\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0860 - accuracy: 0.9740\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0676 - accuracy: 0.9798\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0844 - accuracy: 0.9743\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0649 - accuracy: 0.9820\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0693 - accuracy: 0.9800\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.0974 - accuracy: 0.9703\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0745 - accuracy: 0.9760\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0558 - accuracy: 0.9831\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0704 - accuracy: 0.9799\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0480 - accuracy: 0.9863\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0626 - accuracy: 0.9823\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0708 - accuracy: 0.9797\n",
      "Epoch 59/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0518 - accuracy: 0.9856\n",
      "Epoch 60/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0598 - accuracy: 0.9831\n",
      "Epoch 61/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0791 - accuracy: 0.9753\n",
      "Epoch 62/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0551 - accuracy: 0.9838\n",
      "Epoch 63/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0491 - accuracy: 0.9854\n",
      "Epoch 64/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0421 - accuracy: 0.9890\n",
      "Epoch 65/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0618 - accuracy: 0.9819\n",
      "Epoch 66/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0709 - accuracy: 0.9790\n",
      "Epoch 67/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0532 - accuracy: 0.9846\n",
      "Epoch 68/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0619 - accuracy: 0.9814\n",
      "Epoch 69/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0416 - accuracy: 0.9895\n",
      "Epoch 70/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0490 - accuracy: 0.9854\n",
      "Epoch 71/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0695 - accuracy: 0.9791\n",
      "Epoch 72/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0337 - accuracy: 0.9916\n",
      "Epoch 73/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0588 - accuracy: 0.9816\n",
      "Epoch 74/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.0421 - accuracy: 0.9893\n",
      "Epoch 75/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0337 - accuracy: 0.9910\n",
      "Epoch 76/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0699 - accuracy: 0.9789\n",
      "Epoch 77/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.0607 - accuracy: 0.9836\n",
      "Epoch 78/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0388 - accuracy: 0.9892\n",
      "Epoch 79/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.0365 - accuracy: 0.9903\n",
      "Epoch 80/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0604 - accuracy: 0.9817\n",
      "Epoch 81/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0413 - accuracy: 0.9892\n",
      "Epoch 82/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0385 - accuracy: 0.9899\n",
      "Score for fold  1: loss of 0.12187185138463974; accuracy of 96.39841318130493%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 64s 138ms/step - loss: 4.6442 - accuracy: 0.0291\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 3.6089 - accuracy: 0.0283\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 3.5810 - accuracy: 0.0321\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 3.5671 - accuracy: 0.0302\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 3.5256 - accuracy: 0.0421\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 3.3731 - accuracy: 0.0730\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 2.7109 - accuracy: 0.1977\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 2.2235 - accuracy: 0.3141\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 1.8178 - accuracy: 0.4352\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 1.4785 - accuracy: 0.5384\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 1.1950 - accuracy: 0.6216\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.9839 - accuracy: 0.6900\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.8004 - accuracy: 0.7455\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.6815 - accuracy: 0.7846\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.5819 - accuracy: 0.8137\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.5045 - accuracy: 0.8398\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.4474 - accuracy: 0.8606\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.3987 - accuracy: 0.8729\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.3508 - accuracy: 0.8903\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.3014 - accuracy: 0.9094\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2916 - accuracy: 0.9071\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.2477 - accuracy: 0.9240\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2294 - accuracy: 0.9280\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1978 - accuracy: 0.9411\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1719 - accuracy: 0.9478\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1631 - accuracy: 0.9497\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1687 - accuracy: 0.9481\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1274 - accuracy: 0.9636\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1226 - accuracy: 0.9653\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1367 - accuracy: 0.9582\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1299 - accuracy: 0.9630\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0980 - accuracy: 0.9723\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0945 - accuracy: 0.9731\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0890 - accuracy: 0.9748\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0970 - accuracy: 0.9723\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0752 - accuracy: 0.9810\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0755 - accuracy: 0.9791\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0757 - accuracy: 0.9799\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0741 - accuracy: 0.9798\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0612 - accuracy: 0.9849\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0696 - accuracy: 0.9822\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0825 - accuracy: 0.9776\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0650 - accuracy: 0.9835\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0709 - accuracy: 0.9803\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0759 - accuracy: 0.9793\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0511 - accuracy: 0.9875\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.0549 - accuracy: 0.9867\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0547 - accuracy: 0.9873\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.0486 - accuracy: 0.9881\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0797 - accuracy: 0.9773\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0483 - accuracy: 0.9871\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0436 - accuracy: 0.9910\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0488 - accuracy: 0.9882\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0695 - accuracy: 0.9810\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0560 - accuracy: 0.9864\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0477 - accuracy: 0.9897\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0571 - accuracy: 0.9858\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0435 - accuracy: 0.9901\n",
      "Epoch 59/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0435 - accuracy: 0.9903\n",
      "Epoch 60/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0496 - accuracy: 0.9889\n",
      "Epoch 61/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0692 - accuracy: 0.9798\n",
      "Epoch 62/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.0523 - accuracy: 0.9858\n",
      "Score for fold  2: loss of 0.12512555718421936; accuracy of 96.3122546672821%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 63s 137ms/step - loss: 3.9783 - accuracy: 0.0335\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 3.4389 - accuracy: 0.0671\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 3.2090 - accuracy: 0.1006\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 2.5215 - accuracy: 0.2418\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 1.9900 - accuracy: 0.3903\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 1.5529 - accuracy: 0.5198\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 1.2152 - accuracy: 0.6377\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.9745 - accuracy: 0.7094\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.8099 - accuracy: 0.7654\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.6702 - accuracy: 0.8061\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.5689 - accuracy: 0.8366\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.4963 - accuracy: 0.8574\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.4094 - accuracy: 0.8851\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.3670 - accuracy: 0.8973\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.3253 - accuracy: 0.9105\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2867 - accuracy: 0.9214\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2643 - accuracy: 0.9279\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2339 - accuracy: 0.9388\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2055 - accuracy: 0.9469\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1884 - accuracy: 0.9512\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1823 - accuracy: 0.9522\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1759 - accuracy: 0.9552\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1555 - accuracy: 0.9613\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1532 - accuracy: 0.9634\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.1421 - accuracy: 0.9679\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1386 - accuracy: 0.9657\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1341 - accuracy: 0.9671\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1340 - accuracy: 0.9692\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1280 - accuracy: 0.9721\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1221 - accuracy: 0.9719\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1229 - accuracy: 0.9731\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1191 - accuracy: 0.9748\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1262 - accuracy: 0.9716\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1246 - accuracy: 0.9728\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1105 - accuracy: 0.9794\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1205 - accuracy: 0.9761\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1233 - accuracy: 0.9743\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1192 - accuracy: 0.9773\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1156 - accuracy: 0.9784\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1177 - accuracy: 0.9797\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1294 - accuracy: 0.9747\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1233 - accuracy: 0.9764\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1302 - accuracy: 0.9752\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1284 - accuracy: 0.9760\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1362 - accuracy: 0.9752\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1458 - accuracy: 0.9722\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1481 - accuracy: 0.9721\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1497 - accuracy: 0.9737\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1577 - accuracy: 0.9730\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.1657 - accuracy: 0.9716\n",
      "Score for fold  3: loss of 0.16908586025238037; accuracy of 95.51878571510315%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.12187185138463974 - Accuracy: 96.39841318130493%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.12512555718421936 - Accuracy: 96.3122546672821%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.16908586025238037 - Accuracy: 95.51878571510315%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 96.07648452123006 (+- 0.3959181659141133)\n",
      "> Loss: 0.13869442294041315\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 7 without noise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is 0.16237163543701172 and accuracy is 95.58823704719543%\n",
      "For subject 7 and noise 5 dB\n",
      "The loss is 0.24912643432617188 and accuracy is 94.30146813392639%\n",
      "For subject 7 and noise 10 dB\n",
      "The loss is 0.2596457898616791 and accuracy is 94.23253536224365%\n",
      "For subject 7 and noise 15 dB\n",
      "The loss is 0.254042387008667 and accuracy is 94.27849054336548%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 8\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17408, 128, 102, 1)\n",
      "The input label shape is (17408,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4352, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 63s 136ms/step - loss: 4.1742 - accuracy: 0.0271\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 3.5171 - accuracy: 0.0654\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 2.4484 - accuracy: 0.2724\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 1.5922 - accuracy: 0.5209\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 1.1772 - accuracy: 0.6455\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.9121 - accuracy: 0.7329\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.7149 - accuracy: 0.7912\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.5796 - accuracy: 0.8335\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.4855 - accuracy: 0.8635\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.4114 - accuracy: 0.8810\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.3608 - accuracy: 0.8976\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.3044 - accuracy: 0.9121\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.3038 - accuracy: 0.9129\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2463 - accuracy: 0.9262\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.2403 - accuracy: 0.9302\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2159 - accuracy: 0.9393\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2084 - accuracy: 0.9386\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1803 - accuracy: 0.9468\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1969 - accuracy: 0.9428\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1646 - accuracy: 0.9530\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1751 - accuracy: 0.9481\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1473 - accuracy: 0.9555\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1557 - accuracy: 0.9533\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1362 - accuracy: 0.9596\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1238 - accuracy: 0.9614\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1198 - accuracy: 0.9631\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 44s 138ms/step - loss: 0.1385 - accuracy: 0.9607\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1235 - accuracy: 0.9636\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.1236 - accuracy: 0.9610\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 44s 137ms/step - loss: 0.0849 - accuracy: 0.9745\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1056 - accuracy: 0.9674\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1018 - accuracy: 0.9655\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1259 - accuracy: 0.9603\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1102 - accuracy: 0.9683\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0536 - accuracy: 0.9834\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0727 - accuracy: 0.9771\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0712 - accuracy: 0.9788\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0912 - accuracy: 0.9709\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0557 - accuracy: 0.9846\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0635 - accuracy: 0.9815\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0598 - accuracy: 0.9834\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0599 - accuracy: 0.9826\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0640 - accuracy: 0.9805\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0573 - accuracy: 0.9831\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0409 - accuracy: 0.9868\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0785 - accuracy: 0.9757\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0432 - accuracy: 0.9876\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0360 - accuracy: 0.9907\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0445 - accuracy: 0.9872\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0622 - accuracy: 0.9810\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0421 - accuracy: 0.9889\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0434 - accuracy: 0.9872\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0373 - accuracy: 0.9880\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0476 - accuracy: 0.9857\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0366 - accuracy: 0.9904\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0434 - accuracy: 0.9881\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0396 - accuracy: 0.9892\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0383 - accuracy: 0.9894\n",
      "Score for fold  1: loss of 0.07462264597415924; accuracy of 98.20782542228699%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 63s 138ms/step - loss: 5.0454 - accuracy: 0.0268\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 3.6454 - accuracy: 0.0292\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 3.5994 - accuracy: 0.0280\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 3.5817 - accuracy: 0.0307\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 51s 159ms/step - loss: 3.5699 - accuracy: 0.0290\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 3.5651 - accuracy: 0.0269\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 48s 148ms/step - loss: 3.5606 - accuracy: 0.0292\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 49s 153ms/step - loss: 3.5569 - accuracy: 0.0292\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 49s 151ms/step - loss: 3.5552 - accuracy: 0.0288\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 3.5535 - accuracy: 0.0289\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 3.5494 - accuracy: 0.0302\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 49s 151ms/step - loss: 3.5492 - accuracy: 0.0287\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 48s 148ms/step - loss: 3.5469 - accuracy: 0.0292\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 56s 174ms/step - loss: 3.5137 - accuracy: 0.0389\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 52s 161ms/step - loss: 2.8629 - accuracy: 0.1724\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 2.3462 - accuracy: 0.2978\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 1.8861 - accuracy: 0.4465\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 47s 147ms/step - loss: 1.5368 - accuracy: 0.5447\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 1.2962 - accuracy: 0.6153\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 1.1074 - accuracy: 0.6711\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.9485 - accuracy: 0.7150\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.8072 - accuracy: 0.7598\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.6890 - accuracy: 0.7934\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.6312 - accuracy: 0.8105\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.5360 - accuracy: 0.8352\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.4961 - accuracy: 0.8517\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.4215 - accuracy: 0.8698\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.3832 - accuracy: 0.8776\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.3457 - accuracy: 0.8936\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.3222 - accuracy: 0.9015\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2877 - accuracy: 0.9102\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.2541 - accuracy: 0.9199\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2409 - accuracy: 0.9256\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.2278 - accuracy: 0.9296\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 48s 148ms/step - loss: 0.1884 - accuracy: 0.9423\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.1884 - accuracy: 0.9387\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1654 - accuracy: 0.9497\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1387 - accuracy: 0.9565\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.1445 - accuracy: 0.9567\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1369 - accuracy: 0.9587\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1181 - accuracy: 0.9631\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1014 - accuracy: 0.9703\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.1047 - accuracy: 0.9698\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0878 - accuracy: 0.9769\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1048 - accuracy: 0.9710\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0958 - accuracy: 0.9732\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0744 - accuracy: 0.9803\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0806 - accuracy: 0.9776\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0730 - accuracy: 0.9804\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0675 - accuracy: 0.9810\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0621 - accuracy: 0.9831\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0626 - accuracy: 0.9832\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0504 - accuracy: 0.9879\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0581 - accuracy: 0.9849\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0534 - accuracy: 0.9859\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0621 - accuracy: 0.9819\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0627 - accuracy: 0.9833\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0536 - accuracy: 0.9854\n",
      "Epoch 59/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0476 - accuracy: 0.9874\n",
      "Epoch 60/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0372 - accuracy: 0.9917\n",
      "Epoch 61/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0529 - accuracy: 0.9865\n",
      "Epoch 62/150\n",
      "323/323 [==============================] - 48s 148ms/step - loss: 0.0378 - accuracy: 0.9906\n",
      "Epoch 63/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 0.0582 - accuracy: 0.9854\n",
      "Epoch 64/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0418 - accuracy: 0.9900\n",
      "Epoch 65/150\n",
      "323/323 [==============================] - 47s 147ms/step - loss: 0.0395 - accuracy: 0.9907\n",
      "Epoch 66/150\n",
      "323/323 [==============================] - 49s 151ms/step - loss: 0.0358 - accuracy: 0.9916\n",
      "Epoch 67/150\n",
      "323/323 [==============================] - 47s 147ms/step - loss: 0.0486 - accuracy: 0.9887\n",
      "Epoch 68/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0429 - accuracy: 0.9891\n",
      "Epoch 69/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0358 - accuracy: 0.9916\n",
      "Epoch 70/150\n",
      "323/323 [==============================] - 48s 148ms/step - loss: 0.0334 - accuracy: 0.9925\n",
      "Epoch 71/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0403 - accuracy: 0.9908\n",
      "Epoch 72/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 0.0347 - accuracy: 0.9935\n",
      "Epoch 73/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0297 - accuracy: 0.9934\n",
      "Epoch 74/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0361 - accuracy: 0.9921\n",
      "Epoch 75/150\n",
      "323/323 [==============================] - 48s 150ms/step - loss: 0.0308 - accuracy: 0.9941\n",
      "Epoch 76/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0330 - accuracy: 0.9936\n",
      "Epoch 77/150\n",
      "323/323 [==============================] - 47s 147ms/step - loss: 0.0370 - accuracy: 0.9911\n",
      "Epoch 78/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0338 - accuracy: 0.9928\n",
      "Epoch 79/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0294 - accuracy: 0.9943\n",
      "Epoch 80/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0280 - accuracy: 0.9945\n",
      "Epoch 81/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0432 - accuracy: 0.9893\n",
      "Epoch 82/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0218 - accuracy: 0.9967\n",
      "Epoch 83/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0238 - accuracy: 0.9954\n",
      "Epoch 84/150\n",
      "323/323 [==============================] - 49s 152ms/step - loss: 0.0407 - accuracy: 0.9913\n",
      "Epoch 85/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0350 - accuracy: 0.9924\n",
      "Epoch 86/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0308 - accuracy: 0.9929\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 48s 149ms/step - loss: 0.0263 - accuracy: 0.9957\n",
      "Epoch 88/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0200 - accuracy: 0.9972\n",
      "Epoch 89/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0364 - accuracy: 0.9908\n",
      "Epoch 90/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0310 - accuracy: 0.9942\n",
      "Epoch 91/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0357 - accuracy: 0.9931\n",
      "Epoch 92/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 0.0272 - accuracy: 0.9951\n",
      "Epoch 93/150\n",
      "323/323 [==============================] - 50s 154ms/step - loss: 0.0347 - accuracy: 0.9928\n",
      "Epoch 94/150\n",
      "323/323 [==============================] - 48s 149ms/step - loss: 0.0216 - accuracy: 0.9966\n",
      "Epoch 95/150\n",
      "323/323 [==============================] - 47s 147ms/step - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 96/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0297 - accuracy: 0.9947\n",
      "Epoch 97/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 0.0260 - accuracy: 0.9956\n",
      "Epoch 98/150\n",
      "323/323 [==============================] - 48s 148ms/step - loss: 0.0337 - accuracy: 0.9936\n",
      "Score for fold  2: loss of 0.03952721878886223; accuracy of 98.62140417098999%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 66s 143ms/step - loss: 3.9400 - accuracy: 0.0383\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 2.8972 - accuracy: 0.1641\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 1.6694 - accuracy: 0.4890\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 1.0113 - accuracy: 0.6993\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.6908 - accuracy: 0.8005\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.5164 - accuracy: 0.8548\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.3986 - accuracy: 0.8911\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.3282 - accuracy: 0.9113\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.2660 - accuracy: 0.9324\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2197 - accuracy: 0.9434\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1906 - accuracy: 0.9537\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1661 - accuracy: 0.9631\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1437 - accuracy: 0.9682\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1271 - accuracy: 0.9733\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1261 - accuracy: 0.9729\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1130 - accuracy: 0.9767\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0963 - accuracy: 0.9818\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1033 - accuracy: 0.9785\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0993 - accuracy: 0.9808\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0902 - accuracy: 0.9813\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0876 - accuracy: 0.9834\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0803 - accuracy: 0.9862\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0834 - accuracy: 0.9857\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0872 - accuracy: 0.9830\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0836 - accuracy: 0.9845\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0745 - accuracy: 0.9885\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0772 - accuracy: 0.9872\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0787 - accuracy: 0.9861\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0844 - accuracy: 0.9859\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0804 - accuracy: 0.9869\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0838 - accuracy: 0.9860\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0801 - accuracy: 0.9879\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0905 - accuracy: 0.9843\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0848 - accuracy: 0.9877\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0851 - accuracy: 0.9887\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0912 - accuracy: 0.9872\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0936 - accuracy: 0.9867\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0983 - accuracy: 0.9871\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1041 - accuracy: 0.9854\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1087 - accuracy: 0.9848\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1110 - accuracy: 0.9864\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1210 - accuracy: 0.9840\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1277 - accuracy: 0.9826\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1371 - accuracy: 0.9830\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.1474 - accuracy: 0.9800\n",
      "Score for fold  3: loss of 0.09652512520551682; accuracy of 97.9489803314209%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.07462264597415924 - Accuracy: 98.20782542228699%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.03952721878886223 - Accuracy: 98.62140417098999%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.09652512520551682 - Accuracy: 97.9489803314209%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 98.25940330823262 (+- 0.2769279855175058)\n",
      "> Loss: 0.07022499665617943\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 8 without noise\n",
      "The loss is 0.09262415766716003 and accuracy is 97.61029481887817%\n",
      "For subject 8 and noise 5 dB\n",
      "The loss is 0.18916049599647522 and accuracy is 96.50735259056091%\n",
      "For subject 8 and noise 10 dB\n",
      "The loss is 0.20237743854522705 and accuracy is 96.41544222831726%\n",
      "For subject 8 and noise 15 dB\n",
      "The loss is 0.2160739153623581 and accuracy is 96.2775707244873%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 9\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17408, 128, 102, 1)\n",
      "The input label shape is (17408,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4352, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 69s 142ms/step - loss: 4.1767 - accuracy: 0.0304\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 3.6531 - accuracy: 0.0450\n",
      "Epoch 3/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 46s 142ms/step - loss: 2.9698 - accuracy: 0.1612\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 2.1094 - accuracy: 0.3710\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 1.6530 - accuracy: 0.4974\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 1.2987 - accuracy: 0.6034\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 1.0769 - accuracy: 0.6695\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.9002 - accuracy: 0.7294\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.7561 - accuracy: 0.7734\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.6707 - accuracy: 0.7979\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.5831 - accuracy: 0.8233\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.5092 - accuracy: 0.8477\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.4750 - accuracy: 0.8549\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.4445 - accuracy: 0.8660\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3976 - accuracy: 0.8817\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3901 - accuracy: 0.8808\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.3558 - accuracy: 0.8886\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.3342 - accuracy: 0.8969\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.3167 - accuracy: 0.9037\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2965 - accuracy: 0.9093\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.2894 - accuracy: 0.9118\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2594 - accuracy: 0.9186\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.2517 - accuracy: 0.9212\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2413 - accuracy: 0.9211\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2290 - accuracy: 0.9266\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2097 - accuracy: 0.9353\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2060 - accuracy: 0.9327\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2061 - accuracy: 0.9351\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1890 - accuracy: 0.9399\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.1834 - accuracy: 0.9416\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1744 - accuracy: 0.9448\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1550 - accuracy: 0.9510\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1691 - accuracy: 0.9448\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.1534 - accuracy: 0.9530\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1519 - accuracy: 0.9539\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.1289 - accuracy: 0.9586\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0997 - accuracy: 0.9679\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1014 - accuracy: 0.9700\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1153 - accuracy: 0.9633\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1332 - accuracy: 0.9593\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.1140 - accuracy: 0.9651\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0830 - accuracy: 0.9720\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0983 - accuracy: 0.9698\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0991 - accuracy: 0.9697\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.1005 - accuracy: 0.9685\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0785 - accuracy: 0.9755\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0890 - accuracy: 0.9740\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0888 - accuracy: 0.9737\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0494 - accuracy: 0.9866\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.1146 - accuracy: 0.9630\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0711 - accuracy: 0.9796\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0611 - accuracy: 0.9808\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0648 - accuracy: 0.9805\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0750 - accuracy: 0.9770\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0726 - accuracy: 0.9773\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0500 - accuracy: 0.9860\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0642 - accuracy: 0.9804\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0817 - accuracy: 0.9739\n",
      "Epoch 59/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0522 - accuracy: 0.9841\n",
      "Score for fold  1: loss of 0.19536679983139038; accuracy of 94.03756856918335%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 67s 141ms/step - loss: 4.6097 - accuracy: 0.0267\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 3.6157 - accuracy: 0.0308\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 3.5837 - accuracy: 0.0241\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 3.5739 - accuracy: 0.0284\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 3.5640 - accuracy: 0.0269\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 3.5567 - accuracy: 0.0293\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 3.5525 - accuracy: 0.0270\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 3.5413 - accuracy: 0.0321\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 3.4452 - accuracy: 0.0521\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 3.3247 - accuracy: 0.0658\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 3.0795 - accuracy: 0.1115\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 2.6960 - accuracy: 0.2045\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 2.2039 - accuracy: 0.3371\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 1.6955 - accuracy: 0.4694\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 1.4113 - accuracy: 0.5517\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 1.1787 - accuracy: 0.6278\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.9538 - accuracy: 0.6927\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.8206 - accuracy: 0.7410\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.6901 - accuracy: 0.7835\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 45s 139ms/step - loss: 0.5826 - accuracy: 0.8159\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.5179 - accuracy: 0.8352\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.4363 - accuracy: 0.8664\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.3830 - accuracy: 0.8855\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.3483 - accuracy: 0.8927\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.2928 - accuracy: 0.9117\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.2730 - accuracy: 0.9183\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2404 - accuracy: 0.9280\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.2142 - accuracy: 0.9355\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2047 - accuracy: 0.9393\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1743 - accuracy: 0.9496\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 49s 151ms/step - loss: 0.1677 - accuracy: 0.9530\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 47s 147ms/step - loss: 0.1570 - accuracy: 0.9551\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.1501 - accuracy: 0.9571\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1399 - accuracy: 0.9592\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.1187 - accuracy: 0.9675\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1306 - accuracy: 0.9626\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1253 - accuracy: 0.9634\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1153 - accuracy: 0.9667\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0990 - accuracy: 0.9732\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1088 - accuracy: 0.9681\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1033 - accuracy: 0.9691\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0923 - accuracy: 0.9733\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0733 - accuracy: 0.9800\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0751 - accuracy: 0.9810\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0922 - accuracy: 0.9724\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0838 - accuracy: 0.9759\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0676 - accuracy: 0.9811\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0791 - accuracy: 0.9781\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0713 - accuracy: 0.9794\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0711 - accuracy: 0.9809\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0723 - accuracy: 0.9783\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0529 - accuracy: 0.9864\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0708 - accuracy: 0.9805\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0637 - accuracy: 0.9813\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0510 - accuracy: 0.9864\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0518 - accuracy: 0.9870\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0652 - accuracy: 0.9817\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0402 - accuracy: 0.9906\n",
      "Epoch 59/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0556 - accuracy: 0.9848\n",
      "Epoch 60/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0638 - accuracy: 0.9832\n",
      "Epoch 61/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0449 - accuracy: 0.9885\n",
      "Epoch 62/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0332 - accuracy: 0.9922\n",
      "Epoch 63/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0568 - accuracy: 0.9865\n",
      "Epoch 64/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0521 - accuracy: 0.9866\n",
      "Epoch 65/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0527 - accuracy: 0.9858\n",
      "Epoch 66/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0533 - accuracy: 0.9860\n",
      "Epoch 67/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0419 - accuracy: 0.9903\n",
      "Epoch 68/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0481 - accuracy: 0.9873\n",
      "Epoch 69/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0363 - accuracy: 0.9922\n",
      "Epoch 70/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0416 - accuracy: 0.9899\n",
      "Epoch 71/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0565 - accuracy: 0.9842\n",
      "Epoch 72/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0533 - accuracy: 0.9857\n",
      "Score for fold  2: loss of 0.12060435116291046; accuracy of 96.81199193000793%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 66s 143ms/step - loss: 4.1223 - accuracy: 0.0296\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 3.5910 - accuracy: 0.0324\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 3.4526 - accuracy: 0.0620\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 3.0560 - accuracy: 0.1294\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 2.2000 - accuracy: 0.3441\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 1.6235 - accuracy: 0.5073\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 1.3158 - accuracy: 0.6005\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 1.1264 - accuracy: 0.6603\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.9606 - accuracy: 0.7092\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.8265 - accuracy: 0.7558\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.6875 - accuracy: 0.7973\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.6022 - accuracy: 0.8189\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.5120 - accuracy: 0.8494\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.4432 - accuracy: 0.8723\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.3767 - accuracy: 0.8937\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.3453 - accuracy: 0.8977\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2865 - accuracy: 0.9212\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2679 - accuracy: 0.9257\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2422 - accuracy: 0.9306\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2129 - accuracy: 0.9414\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2006 - accuracy: 0.9443\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1726 - accuracy: 0.9543\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1714 - accuracy: 0.9550\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1523 - accuracy: 0.9604\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1424 - accuracy: 0.9605\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1317 - accuracy: 0.9659\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1260 - accuracy: 0.9687\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1164 - accuracy: 0.9713\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1237 - accuracy: 0.9693\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1113 - accuracy: 0.9725\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1094 - accuracy: 0.9721\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 47s 146ms/step - loss: 0.1120 - accuracy: 0.9712\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1043 - accuracy: 0.9751\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0969 - accuracy: 0.9772\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0977 - accuracy: 0.9785\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0953 - accuracy: 0.9787\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0944 - accuracy: 0.9775\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0985 - accuracy: 0.9788\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0971 - accuracy: 0.9790\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0884 - accuracy: 0.9817\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0881 - accuracy: 0.9821\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0979 - accuracy: 0.9798\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0995 - accuracy: 0.9778\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1027 - accuracy: 0.9778\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0912 - accuracy: 0.9829\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0938 - accuracy: 0.9815\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.1022 - accuracy: 0.9785\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0968 - accuracy: 0.9818\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1000 - accuracy: 0.9809\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1100 - accuracy: 0.9778\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1042 - accuracy: 0.9804\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1080 - accuracy: 0.9789\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1120 - accuracy: 0.9785\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1114 - accuracy: 0.9786\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1200 - accuracy: 0.9777\n",
      "Score for fold  3: loss of 0.14388108253479004; accuracy of 96.08755707740784%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.19536679983139038 - Accuracy: 94.03756856918335%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.12060435116291046 - Accuracy: 96.81199193000793%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.14388108253479004 - Accuracy: 96.08755707740784%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 95.64570585886638 (+- 1.1749554944102432)\n",
      "> Loss: 0.1532840778430303\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 9 without noise\n",
      "The loss is 0.14195284247398376 and accuracy is 95.81801295280457%\n",
      "For subject 9 and noise 5 dB\n",
      "The loss is 0.2545224130153656 and accuracy is 94.46231722831726%\n",
      "For subject 9 and noise 10 dB\n",
      "The loss is 0.24724455177783966 and accuracy is 94.50827240943909%\n",
      "For subject 9 and noise 15 dB\n",
      "The loss is 0.23496854305267334 and accuracy is 94.48529481887817%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 10\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17150, 128, 102, 1)\n",
      "The input label shape is (17150,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4288, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 66s 142ms/step - loss: 4.1972 - accuracy: 0.0256\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 3.6162 - accuracy: 0.0434\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 2.7598 - accuracy: 0.2084\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 1.8841 - accuracy: 0.4529\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 1.3189 - accuracy: 0.6251\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.9455 - accuracy: 0.7340\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.7348 - accuracy: 0.7960\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.5812 - accuracy: 0.8395\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.4648 - accuracy: 0.8732\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.3923 - accuracy: 0.8929\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.3664 - accuracy: 0.8993\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.3067 - accuracy: 0.9144\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.2825 - accuracy: 0.9229\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.2823 - accuracy: 0.9177\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.2286 - accuracy: 0.9376\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.2563 - accuracy: 0.9248\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.2176 - accuracy: 0.9375\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.2175 - accuracy: 0.9377\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.1788 - accuracy: 0.9492\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1901 - accuracy: 0.9445\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1798 - accuracy: 0.9466\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.1769 - accuracy: 0.9477\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.1602 - accuracy: 0.9520\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.1494 - accuracy: 0.9544\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.1362 - accuracy: 0.9614\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.1515 - accuracy: 0.9526\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1295 - accuracy: 0.9627\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.1459 - accuracy: 0.9549\n",
      "Epoch 29/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1174 - accuracy: 0.9627\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1259 - accuracy: 0.9623\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1190 - accuracy: 0.9660\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0922 - accuracy: 0.9733\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.1364 - accuracy: 0.9569\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0887 - accuracy: 0.9731\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0931 - accuracy: 0.9701\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0820 - accuracy: 0.9745\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0936 - accuracy: 0.9712\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0566 - accuracy: 0.9828\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0838 - accuracy: 0.9754\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0733 - accuracy: 0.9781\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0828 - accuracy: 0.9769\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0427 - accuracy: 0.9877\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0566 - accuracy: 0.9845\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0883 - accuracy: 0.9731\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0621 - accuracy: 0.9803\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0522 - accuracy: 0.9855\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0663 - accuracy: 0.9812\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0449 - accuracy: 0.9876\n",
      "Epoch 50/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0384 - accuracy: 0.9885\n",
      "Epoch 51/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0750 - accuracy: 0.9771\n",
      "Epoch 52/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0584 - accuracy: 0.9819\n",
      "Epoch 53/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0315 - accuracy: 0.9910\n",
      "Epoch 54/150\n",
      "318/318 [==============================] - 46s 146ms/step - loss: 0.0432 - accuracy: 0.9871\n",
      "Epoch 55/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0678 - accuracy: 0.9791\n",
      "Epoch 56/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0385 - accuracy: 0.9894\n",
      "Epoch 57/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0245 - accuracy: 0.9934\n",
      "Epoch 58/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0529 - accuracy: 0.9846\n",
      "Epoch 59/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0601 - accuracy: 0.9831\n",
      "Epoch 60/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0494 - accuracy: 0.9857\n",
      "Epoch 61/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0415 - accuracy: 0.9889\n",
      "Epoch 62/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0431 - accuracy: 0.9876\n",
      "Epoch 63/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0227 - accuracy: 0.9946\n",
      "Epoch 64/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0377 - accuracy: 0.9904\n",
      "Epoch 65/150\n",
      "318/318 [==============================] - 46s 145ms/step - loss: 0.0467 - accuracy: 0.9868\n",
      "Epoch 66/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0468 - accuracy: 0.9864\n",
      "Epoch 67/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0249 - accuracy: 0.9942\n",
      "Epoch 68/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0155 - accuracy: 0.9965\n",
      "Epoch 69/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.0688 - accuracy: 0.9794\n",
      "Epoch 70/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0319 - accuracy: 0.9916\n",
      "Epoch 71/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0346 - accuracy: 0.9910\n",
      "Epoch 72/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0310 - accuracy: 0.9914\n",
      "Epoch 73/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0332 - accuracy: 0.9913\n",
      "Epoch 74/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0212 - accuracy: 0.9946\n",
      "Epoch 75/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0545 - accuracy: 0.9838\n",
      "Epoch 76/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0387 - accuracy: 0.9884\n",
      "Epoch 77/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.0211 - accuracy: 0.9945\n",
      "Epoch 78/150\n",
      "318/318 [==============================] - 46s 143ms/step - loss: 0.0183 - accuracy: 0.9955\n",
      "Score for fold  1: loss of 0.05746685341000557; accuracy of 98.4082579612732%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 65s 139ms/step - loss: 4.7842 - accuracy: 0.0258\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 3.6200 - accuracy: 0.0301\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 3.5854 - accuracy: 0.0292\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 3.5751 - accuracy: 0.0291\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 3.5633 - accuracy: 0.0295\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.5585 - accuracy: 0.0293\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.5551 - accuracy: 0.0302\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.5498 - accuracy: 0.0293\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.5491 - accuracy: 0.0280\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 3.5448 - accuracy: 0.0294\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 3.5459 - accuracy: 0.0266\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 3.5428 - accuracy: 0.0276\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 3.2649 - accuracy: 0.0691\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 2.6678 - accuracy: 0.2099\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 2.1055 - accuracy: 0.3646\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 1.5423 - accuracy: 0.5370\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 1.1262 - accuracy: 0.6611\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.8291 - accuracy: 0.7535\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.6578 - accuracy: 0.8052\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.5449 - accuracy: 0.8416\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.4446 - accuracy: 0.8715\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.3882 - accuracy: 0.8872\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.3333 - accuracy: 0.9040\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.2965 - accuracy: 0.9158\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.2604 - accuracy: 0.9243\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.2194 - accuracy: 0.9370\n",
      "Epoch 27/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 45s 140ms/step - loss: 0.2077 - accuracy: 0.9403\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1933 - accuracy: 0.9428\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1752 - accuracy: 0.9482\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1651 - accuracy: 0.9507\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1428 - accuracy: 0.9594\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1194 - accuracy: 0.9656\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1319 - accuracy: 0.9603\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1058 - accuracy: 0.9707\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0974 - accuracy: 0.9734\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0962 - accuracy: 0.9721\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0838 - accuracy: 0.9752\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0811 - accuracy: 0.9802\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0729 - accuracy: 0.9808\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0740 - accuracy: 0.9811\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0714 - accuracy: 0.9802\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0638 - accuracy: 0.9830\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0680 - accuracy: 0.9808\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0640 - accuracy: 0.9837\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0536 - accuracy: 0.9872\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0574 - accuracy: 0.9856\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0451 - accuracy: 0.9899\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0650 - accuracy: 0.9821\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0482 - accuracy: 0.9882\n",
      "Epoch 50/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0489 - accuracy: 0.9881\n",
      "Epoch 51/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0476 - accuracy: 0.9880\n",
      "Epoch 52/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0518 - accuracy: 0.9878\n",
      "Epoch 53/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0423 - accuracy: 0.9904\n",
      "Epoch 54/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0403 - accuracy: 0.9906\n",
      "Epoch 55/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0514 - accuracy: 0.9872\n",
      "Epoch 56/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0344 - accuracy: 0.9935\n",
      "Epoch 57/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0534 - accuracy: 0.9871\n",
      "Epoch 58/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0398 - accuracy: 0.9912\n",
      "Epoch 59/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0458 - accuracy: 0.9897\n",
      "Epoch 60/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0364 - accuracy: 0.9922\n",
      "Epoch 61/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0322 - accuracy: 0.9934\n",
      "Epoch 62/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0532 - accuracy: 0.9871\n",
      "Epoch 63/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0317 - accuracy: 0.9945\n",
      "Epoch 64/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0418 - accuracy: 0.9889\n",
      "Epoch 65/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.0379 - accuracy: 0.9928\n",
      "Epoch 66/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0325 - accuracy: 0.9935\n",
      "Epoch 67/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0499 - accuracy: 0.9879\n",
      "Epoch 68/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.0294 - accuracy: 0.9944\n",
      "Epoch 69/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0207 - accuracy: 0.9983\n",
      "Epoch 70/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0364 - accuracy: 0.9922\n",
      "Epoch 71/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0454 - accuracy: 0.9890\n",
      "Epoch 72/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0430 - accuracy: 0.9910\n",
      "Epoch 73/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0275 - accuracy: 0.9951\n",
      "Epoch 74/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0386 - accuracy: 0.9920\n",
      "Epoch 75/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.0279 - accuracy: 0.9956\n",
      "Epoch 76/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0335 - accuracy: 0.9932\n",
      "Epoch 77/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.0469 - accuracy: 0.9904\n",
      "Epoch 78/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0378 - accuracy: 0.9921\n",
      "Epoch 79/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.0268 - accuracy: 0.9961\n",
      "Score for fold  2: loss of 0.045043133199214935; accuracy of 99.10792112350464%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 63s 141ms/step - loss: 3.9534 - accuracy: 0.0357\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 3.5224 - accuracy: 0.0511\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 3.4136 - accuracy: 0.0677\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 3.1360 - accuracy: 0.1281\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 2.3585 - accuracy: 0.2997\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 1.7614 - accuracy: 0.4848\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 1.2928 - accuracy: 0.6301\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.9604 - accuracy: 0.7325\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.7337 - accuracy: 0.8039\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.5819 - accuracy: 0.8435\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.4668 - accuracy: 0.8771\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.3821 - accuracy: 0.9029\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.3287 - accuracy: 0.9150\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 48s 150ms/step - loss: 0.2879 - accuracy: 0.9255\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 47s 146ms/step - loss: 0.2587 - accuracy: 0.9358\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.2234 - accuracy: 0.9443\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1883 - accuracy: 0.9565\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.1835 - accuracy: 0.9575\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 47s 146ms/step - loss: 0.1609 - accuracy: 0.9667\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 46s 145ms/step - loss: 0.1616 - accuracy: 0.9633\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1446 - accuracy: 0.9682\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 48s 152ms/step - loss: 0.1350 - accuracy: 0.9708\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.1299 - accuracy: 0.9727\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1329 - accuracy: 0.9725\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1282 - accuracy: 0.9728\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1161 - accuracy: 0.9773\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1126 - accuracy: 0.9779\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1144 - accuracy: 0.9789\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1064 - accuracy: 0.9807\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1092 - accuracy: 0.9809\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 45s 140ms/step - loss: 0.1061 - accuracy: 0.9801\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1080 - accuracy: 0.9808\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 45s 141ms/step - loss: 0.1044 - accuracy: 0.9834\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 44s 140ms/step - loss: 0.1050 - accuracy: 0.9818\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 44s 139ms/step - loss: 0.1084 - accuracy: 0.9849\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1158 - accuracy: 0.9803\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 47s 149ms/step - loss: 0.1132 - accuracy: 0.9809\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 45s 142ms/step - loss: 0.1126 - accuracy: 0.9824\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 47s 147ms/step - loss: 0.1156 - accuracy: 0.9829\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 47s 147ms/step - loss: 0.1259 - accuracy: 0.9799\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.1289 - accuracy: 0.9801\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 47s 148ms/step - loss: 0.1339 - accuracy: 0.9819\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 48s 151ms/step - loss: 0.1404 - accuracy: 0.9796\n",
      "Epoch 44/150\n",
      "318/318 [==============================] - 45s 143ms/step - loss: 0.1443 - accuracy: 0.9793\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 46s 144ms/step - loss: 0.1533 - accuracy: 0.9786\n",
      "Score for fold  3: loss of 0.11427168548107147; accuracy of 97.30581045150757%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.05746685341000557 - Accuracy: 98.4082579612732%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.045043133199214935 - Accuracy: 99.10792112350464%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.11427168548107147 - Accuracy: 97.30581045150757%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 98.27399651209514 (+- 0.7418087449304694)\n",
      "> Loss: 0.07226055736343066\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 10 without noise\n",
      "The loss is 0.12123600393533707 and accuracy is 96.875%\n",
      "For subject 10 and noise 5 dB\n",
      "The loss is 0.21075282990932465 and accuracy is 95.5690324306488%\n",
      "For subject 10 and noise 10 dB\n",
      "The loss is 0.21830905973911285 and accuracy is 95.59234976768494%\n",
      "For subject 10 and noise 15 dB\n",
      "The loss is 0.23425327241420746 and accuracy is 95.14925479888916%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 11\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (16636, 128, 102, 1)\n",
      "The input label shape is (16636,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4160, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "309/309 [==============================] - 65s 145ms/step - loss: 4.2477 - accuracy: 0.0280\n",
      "Epoch 2/150\n",
      "309/309 [==============================] - 44s 144ms/step - loss: 3.6864 - accuracy: 0.0372\n",
      "Epoch 3/150\n",
      "309/309 [==============================] - 44s 143ms/step - loss: 3.2561 - accuracy: 0.1150\n",
      "Epoch 4/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 2.5026 - accuracy: 0.2748\n",
      "Epoch 5/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 1.9532 - accuracy: 0.4203\n",
      "Epoch 6/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 1.5666 - accuracy: 0.5315\n",
      "Epoch 7/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 1.2552 - accuracy: 0.6258\n",
      "Epoch 8/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 1.0664 - accuracy: 0.6840\n",
      "Epoch 9/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.9475 - accuracy: 0.7227\n",
      "Epoch 10/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.7636 - accuracy: 0.7819\n",
      "Epoch 11/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.6592 - accuracy: 0.8100\n",
      "Epoch 12/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.5999 - accuracy: 0.8226\n",
      "Epoch 13/150\n",
      "309/309 [==============================] - 44s 144ms/step - loss: 0.5160 - accuracy: 0.8525\n",
      "Epoch 14/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.4644 - accuracy: 0.8682\n",
      "Epoch 15/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.4283 - accuracy: 0.8740\n",
      "Epoch 16/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.4217 - accuracy: 0.8757\n",
      "Epoch 17/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.3681 - accuracy: 0.8925\n",
      "Epoch 18/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.3692 - accuracy: 0.8928\n",
      "Epoch 19/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.3196 - accuracy: 0.9090\n",
      "Epoch 20/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.2885 - accuracy: 0.9149\n",
      "Epoch 21/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.2796 - accuracy: 0.9161\n",
      "Epoch 22/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.2542 - accuracy: 0.9224\n",
      "Epoch 23/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.3371 - accuracy: 0.8984\n",
      "Epoch 24/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.2198 - accuracy: 0.9344\n",
      "Epoch 25/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.2042 - accuracy: 0.9399\n",
      "Epoch 26/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.2207 - accuracy: 0.9353\n",
      "Epoch 27/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1968 - accuracy: 0.9404\n",
      "Epoch 28/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.2893 - accuracy: 0.9139\n",
      "Epoch 29/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1674 - accuracy: 0.9490\n",
      "Epoch 30/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1586 - accuracy: 0.9506\n",
      "Epoch 31/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1962 - accuracy: 0.9408\n",
      "Epoch 32/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.1875 - accuracy: 0.9427\n",
      "Epoch 33/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1402 - accuracy: 0.9613\n",
      "Epoch 34/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1719 - accuracy: 0.9474\n",
      "Epoch 35/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1512 - accuracy: 0.9528\n",
      "Epoch 36/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1317 - accuracy: 0.9588\n",
      "Epoch 37/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1228 - accuracy: 0.9628\n",
      "Epoch 38/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1537 - accuracy: 0.9505\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1140 - accuracy: 0.9635\n",
      "Epoch 40/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.1928 - accuracy: 0.9404\n",
      "Epoch 41/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0950 - accuracy: 0.9705\n",
      "Epoch 42/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0872 - accuracy: 0.9746\n",
      "Epoch 43/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0725 - accuracy: 0.9801\n",
      "Epoch 44/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0851 - accuracy: 0.9755\n",
      "Epoch 45/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1213 - accuracy: 0.9626\n",
      "Epoch 46/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.0834 - accuracy: 0.9757\n",
      "Epoch 47/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0818 - accuracy: 0.9747\n",
      "Epoch 48/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0708 - accuracy: 0.9800\n",
      "Epoch 49/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0699 - accuracy: 0.9789\n",
      "Epoch 50/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0972 - accuracy: 0.9715\n",
      "Epoch 51/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0944 - accuracy: 0.9714\n",
      "Epoch 52/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0603 - accuracy: 0.9831\n",
      "Epoch 53/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0687 - accuracy: 0.9800\n",
      "Epoch 54/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.0839 - accuracy: 0.9739\n",
      "Epoch 55/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0701 - accuracy: 0.9801\n",
      "Epoch 56/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0531 - accuracy: 0.9848\n",
      "Epoch 57/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0625 - accuracy: 0.9812\n",
      "Epoch 58/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0769 - accuracy: 0.9770\n",
      "Epoch 59/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0734 - accuracy: 0.9778\n",
      "Epoch 60/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0464 - accuracy: 0.9876\n",
      "Epoch 61/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0561 - accuracy: 0.9830\n",
      "Epoch 62/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0608 - accuracy: 0.9824\n",
      "Epoch 63/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0376 - accuracy: 0.9905\n",
      "Epoch 64/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0711 - accuracy: 0.9798\n",
      "Epoch 65/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.0693 - accuracy: 0.9789\n",
      "Epoch 66/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0590 - accuracy: 0.9828\n",
      "Epoch 67/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1271 - accuracy: 0.9594\n",
      "Epoch 68/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.0313 - accuracy: 0.9922\n",
      "Epoch 69/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0286 - accuracy: 0.9927\n",
      "Epoch 70/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0298 - accuracy: 0.9926\n",
      "Epoch 71/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0487 - accuracy: 0.9877\n",
      "Epoch 72/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0701 - accuracy: 0.9792\n",
      "Epoch 73/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0534 - accuracy: 0.9851\n",
      "Epoch 74/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.0430 - accuracy: 0.9886\n",
      "Epoch 75/150\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0595 - accuracy: 0.9830\n",
      "Epoch 76/150\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0532 - accuracy: 0.9832\n",
      "Epoch 77/150\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0543 - accuracy: 0.9853\n",
      "Epoch 78/150\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0364 - accuracy: 0.9899\n",
      "Epoch 79/150\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.1066 - accuracy: 0.9693\n",
      "Score for fold  1: loss of 0.08083628118038177; accuracy of 97.67400026321411%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "309/309 [==============================] - 72s 145ms/step - loss: 4.8964 - accuracy: 0.0280\n",
      "Epoch 2/150\n",
      "309/309 [==============================] - 44s 144ms/step - loss: 3.6209 - accuracy: 0.0271\n",
      "Epoch 3/150\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 3.5849 - accuracy: 0.0301\n",
      "Epoch 4/150\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 3.5690 - accuracy: 0.0291\n",
      "Epoch 5/150\n",
      "309/309 [==============================] - 44s 143ms/step - loss: 3.5555 - accuracy: 0.0317\n",
      "Epoch 6/150\n",
      "309/309 [==============================] - 44s 143ms/step - loss: 3.5553 - accuracy: 0.0314\n",
      "Epoch 7/150\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 3.5495 - accuracy: 0.0331\n",
      "Epoch 8/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 3.5449 - accuracy: 0.0298\n",
      "Epoch 9/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 3.5157 - accuracy: 0.0412\n",
      "Epoch 10/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 3.4474 - accuracy: 0.0598\n",
      "Epoch 11/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 3.3343 - accuracy: 0.0782\n",
      "Epoch 12/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 3.0076 - accuracy: 0.1482\n",
      "Epoch 13/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 2.4359 - accuracy: 0.2745\n",
      "Epoch 14/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 1.9002 - accuracy: 0.4124\n",
      "Epoch 15/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 1.5355 - accuracy: 0.5250\n",
      "Epoch 16/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 1.2341 - accuracy: 0.6181\n",
      "Epoch 17/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.9833 - accuracy: 0.6980\n",
      "Epoch 18/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.7821 - accuracy: 0.7649\n",
      "Epoch 19/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.6460 - accuracy: 0.8110\n",
      "Epoch 20/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.5454 - accuracy: 0.8390\n",
      "Epoch 21/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.4605 - accuracy: 0.8676\n",
      "Epoch 22/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.4156 - accuracy: 0.8769\n",
      "Epoch 23/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.3651 - accuracy: 0.8957\n",
      "Epoch 24/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.3283 - accuracy: 0.9059\n",
      "Epoch 25/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.2894 - accuracy: 0.9170\n",
      "Epoch 26/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.2783 - accuracy: 0.9225\n",
      "Epoch 27/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.2460 - accuracy: 0.9331\n",
      "Epoch 28/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.2243 - accuracy: 0.9382\n",
      "Epoch 29/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.2109 - accuracy: 0.9425\n",
      "Epoch 30/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.2200 - accuracy: 0.9381\n",
      "Epoch 31/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1971 - accuracy: 0.9468\n",
      "Epoch 32/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.1891 - accuracy: 0.9487\n",
      "Epoch 33/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1809 - accuracy: 0.9514\n",
      "Epoch 34/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1877 - accuracy: 0.9485\n",
      "Epoch 35/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1637 - accuracy: 0.9563\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1737 - accuracy: 0.9527\n",
      "Epoch 37/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1697 - accuracy: 0.9555\n",
      "Epoch 38/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1588 - accuracy: 0.9577\n",
      "Epoch 39/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1439 - accuracy: 0.9621\n",
      "Epoch 40/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.2914 - accuracy: 0.9309\n",
      "Epoch 41/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1736 - accuracy: 0.9571\n",
      "Epoch 42/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1800 - accuracy: 0.9557\n",
      "Epoch 43/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1353 - accuracy: 0.9657\n",
      "Epoch 44/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1519 - accuracy: 0.9606\n",
      "Epoch 45/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1369 - accuracy: 0.9654\n",
      "Epoch 46/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1363 - accuracy: 0.9641\n",
      "Epoch 47/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1284 - accuracy: 0.9676\n",
      "Epoch 48/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1457 - accuracy: 0.9623\n",
      "Epoch 49/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1127 - accuracy: 0.9729\n",
      "Epoch 50/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1167 - accuracy: 0.9713\n",
      "Epoch 51/150\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0953 - accuracy: 0.9766\n",
      "Epoch 52/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1099 - accuracy: 0.9711\n",
      "Epoch 53/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0940 - accuracy: 0.9753\n",
      "Epoch 54/150\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.1038 - accuracy: 0.9736\n",
      "Epoch 55/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0785 - accuracy: 0.9813\n",
      "Epoch 56/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0817 - accuracy: 0.9803\n",
      "Epoch 57/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0852 - accuracy: 0.9780\n",
      "Epoch 58/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0955 - accuracy: 0.9752\n",
      "Epoch 59/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0670 - accuracy: 0.9852\n",
      "Epoch 60/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0667 - accuracy: 0.9838\n",
      "Epoch 61/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0625 - accuracy: 0.9868\n",
      "Epoch 62/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0811 - accuracy: 0.9793\n",
      "Epoch 63/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0513 - accuracy: 0.9888\n",
      "Epoch 64/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0557 - accuracy: 0.9875\n",
      "Epoch 65/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0586 - accuracy: 0.9872\n",
      "Epoch 66/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0657 - accuracy: 0.9834\n",
      "Epoch 67/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0538 - accuracy: 0.9868\n",
      "Epoch 68/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0526 - accuracy: 0.9875\n",
      "Epoch 69/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0564 - accuracy: 0.9877\n",
      "Epoch 70/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0569 - accuracy: 0.9865\n",
      "Epoch 71/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0397 - accuracy: 0.9922\n",
      "Epoch 72/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0520 - accuracy: 0.9878\n",
      "Epoch 73/150\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0671 - accuracy: 0.9850\n",
      "Epoch 74/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0468 - accuracy: 0.9900\n",
      "Epoch 75/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0559 - accuracy: 0.9880\n",
      "Epoch 76/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0352 - accuracy: 0.9939\n",
      "Epoch 77/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0481 - accuracy: 0.9907\n",
      "Epoch 78/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0530 - accuracy: 0.9885\n",
      "Epoch 79/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0500 - accuracy: 0.9894\n",
      "Epoch 80/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0469 - accuracy: 0.9905\n",
      "Epoch 81/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0450 - accuracy: 0.9915\n",
      "Epoch 82/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0372 - accuracy: 0.9935\n",
      "Epoch 83/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0572 - accuracy: 0.9867\n",
      "Epoch 84/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0601 - accuracy: 0.9874\n",
      "Epoch 85/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0581 - accuracy: 0.9880\n",
      "Epoch 86/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0381 - accuracy: 0.9940\n",
      "Epoch 87/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0428 - accuracy: 0.9922\n",
      "Epoch 88/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0538 - accuracy: 0.9880\n",
      "Epoch 89/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0409 - accuracy: 0.9944\n",
      "Epoch 90/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0449 - accuracy: 0.9927\n",
      "Epoch 91/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0497 - accuracy: 0.9902\n",
      "Epoch 92/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0462 - accuracy: 0.9936\n",
      "Epoch 93/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0503 - accuracy: 0.9914\n",
      "Epoch 94/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0528 - accuracy: 0.9896\n",
      "Epoch 95/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0467 - accuracy: 0.9919\n",
      "Epoch 96/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0490 - accuracy: 0.9913\n",
      "Epoch 97/150\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0508 - accuracy: 0.9922\n",
      "Epoch 98/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0535 - accuracy: 0.9903\n",
      "Epoch 99/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0566 - accuracy: 0.9895\n",
      "Score for fold  2: loss of 0.06813918799161911; accuracy of 98.14246892929077%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "309/309 [==============================] - 62s 138ms/step - loss: 3.8586 - accuracy: 0.0374\n",
      "Epoch 2/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 3.3845 - accuracy: 0.0833\n",
      "Epoch 3/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 2.8394 - accuracy: 0.1883\n",
      "Epoch 4/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 2.0963 - accuracy: 0.3700\n",
      "Epoch 5/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 1.6486 - accuracy: 0.5004\n",
      "Epoch 6/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 1.3517 - accuracy: 0.5999\n",
      "Epoch 7/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 1.1278 - accuracy: 0.6758\n",
      "Epoch 8/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.9661 - accuracy: 0.7272\n",
      "Epoch 9/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.8430 - accuracy: 0.7631\n",
      "Epoch 10/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.7353 - accuracy: 0.8016\n",
      "Epoch 11/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.6383 - accuracy: 0.8272\n",
      "Epoch 12/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.5800 - accuracy: 0.8450\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 43s 138ms/step - loss: 0.5268 - accuracy: 0.8599\n",
      "Epoch 14/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.4883 - accuracy: 0.8747\n",
      "Epoch 15/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.4472 - accuracy: 0.8890\n",
      "Epoch 16/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.4165 - accuracy: 0.8955\n",
      "Epoch 17/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.4033 - accuracy: 0.9015\n",
      "Epoch 18/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3773 - accuracy: 0.9080\n",
      "Epoch 19/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.3766 - accuracy: 0.9098\n",
      "Epoch 20/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3610 - accuracy: 0.9135\n",
      "Epoch 21/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3430 - accuracy: 0.9197\n",
      "Epoch 22/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3346 - accuracy: 0.9203\n",
      "Epoch 23/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3411 - accuracy: 0.9222\n",
      "Epoch 24/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3407 - accuracy: 0.9256\n",
      "Epoch 25/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3339 - accuracy: 0.9247\n",
      "Epoch 26/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3351 - accuracy: 0.9264\n",
      "Epoch 27/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.3387 - accuracy: 0.9263\n",
      "Epoch 28/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.3415 - accuracy: 0.9301\n",
      "Epoch 29/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3552 - accuracy: 0.9264\n",
      "Epoch 30/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.3609 - accuracy: 0.9216\n",
      "Epoch 31/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.3615 - accuracy: 0.9298\n",
      "Epoch 32/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.3763 - accuracy: 0.9234\n",
      "Epoch 33/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.3809 - accuracy: 0.9243\n",
      "Epoch 34/150\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.3976 - accuracy: 0.9229\n",
      "Epoch 35/150\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.4327 - accuracy: 0.9176\n",
      "Epoch 36/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.4379 - accuracy: 0.9164\n",
      "Epoch 37/150\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.4707 - accuracy: 0.9100\n",
      "Epoch 38/150\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.4963 - accuracy: 0.9071\n",
      "Score for fold  3: loss of 0.37214162945747375; accuracy of 91.50586128234863%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.08083628118038177 - Accuracy: 97.67400026321411%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.06813918799161911 - Accuracy: 98.14246892929077%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.37214162945747375 - Accuracy: 91.50586128234863%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 95.7741101582845 (+- 3.024161269175283)\n",
      "> Loss: 0.1737056995431582\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 11 without noise\n",
      "The loss is 0.3706642687320709 and accuracy is 91.92307591438293%\n",
      "For subject 11 and noise 5 dB\n",
      "The loss is 0.4479191303253174 and accuracy is 91.03365540504456%\n",
      "For subject 11 and noise 10 dB\n",
      "The loss is 0.4463694989681244 and accuracy is 91.08173251152039%\n",
      "For subject 11 and noise 15 dB\n",
      "The loss is 0.46242785453796387 and accuracy is 90.9375011920929%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 12\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17279, 128, 102, 1)\n",
      "The input label shape is (17279,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4320, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 67s 142ms/step - loss: 4.2140 - accuracy: 0.0315\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 3.3214 - accuracy: 0.0839\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 2.5554 - accuracy: 0.2341\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 1.9301 - accuracy: 0.4150\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 1.4967 - accuracy: 0.5473\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 1.2179 - accuracy: 0.6403\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.9868 - accuracy: 0.7033\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.8591 - accuracy: 0.7383\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.7377 - accuracy: 0.7790\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.6527 - accuracy: 0.8049\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.5794 - accuracy: 0.8272\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.5349 - accuracy: 0.8385\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.4684 - accuracy: 0.8572\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.4350 - accuracy: 0.8681\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.4144 - accuracy: 0.8720\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.3651 - accuracy: 0.8883\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.3148 - accuracy: 0.9053\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.3086 - accuracy: 0.9064\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.3121 - accuracy: 0.9042\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.2808 - accuracy: 0.9115\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.2503 - accuracy: 0.9227\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.2454 - accuracy: 0.9229\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.2263 - accuracy: 0.9292\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.2383 - accuracy: 0.9253\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1913 - accuracy: 0.9415\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.1963 - accuracy: 0.9388\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.2186 - accuracy: 0.9301\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1855 - accuracy: 0.9442\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1499 - accuracy: 0.9536\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1685 - accuracy: 0.9470\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1909 - accuracy: 0.9400\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1570 - accuracy: 0.9509\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1620 - accuracy: 0.9483\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1406 - accuracy: 0.9556\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 46s 142ms/step - loss: 0.1286 - accuracy: 0.9586\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0914 - accuracy: 0.9734\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1273 - accuracy: 0.9592\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1059 - accuracy: 0.9660\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0863 - accuracy: 0.9747\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1017 - accuracy: 0.9682\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1006 - accuracy: 0.9674\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0835 - accuracy: 0.9738\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0977 - accuracy: 0.9698\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0844 - accuracy: 0.9749\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0844 - accuracy: 0.9762\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0899 - accuracy: 0.9713\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0709 - accuracy: 0.9796\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0518 - accuracy: 0.9848\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0726 - accuracy: 0.9776\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0893 - accuracy: 0.9713\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0646 - accuracy: 0.9817\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0502 - accuracy: 0.9843\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0837 - accuracy: 0.9747\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0536 - accuracy: 0.9832\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.0585 - accuracy: 0.9839\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 45s 142ms/step - loss: 0.0689 - accuracy: 0.9799\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0428 - accuracy: 0.9882\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0549 - accuracy: 0.9826\n",
      "Epoch 59/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0796 - accuracy: 0.9770\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0573 - accuracy: 0.9828\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0445 - accuracy: 0.9877\n",
      "Epoch 62/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0513 - accuracy: 0.9845\n",
      "Epoch 63/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0639 - accuracy: 0.9812\n",
      "Epoch 64/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0628 - accuracy: 0.9815\n",
      "Epoch 65/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0414 - accuracy: 0.9876\n",
      "Epoch 66/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0289 - accuracy: 0.9931\n",
      "Epoch 67/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0823 - accuracy: 0.9768\n",
      "Epoch 68/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0562 - accuracy: 0.9838\n",
      "Epoch 69/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.0550 - accuracy: 0.9839\n",
      "Epoch 70/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0420 - accuracy: 0.9885\n",
      "Epoch 71/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0349 - accuracy: 0.9900\n",
      "Epoch 72/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.0486 - accuracy: 0.9862\n",
      "Epoch 73/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.0470 - accuracy: 0.9868\n",
      "Epoch 74/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0402 - accuracy: 0.9883\n",
      "Epoch 75/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0408 - accuracy: 0.9889\n",
      "Epoch 76/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0762 - accuracy: 0.9767\n",
      "Score for fold  1: loss of 0.15781894326210022; accuracy of 95.95485925674438%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 66s 143ms/step - loss: 4.7294 - accuracy: 0.0294\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 3.6231 - accuracy: 0.0286\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 3.5960 - accuracy: 0.0278\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 3.5789 - accuracy: 0.0281\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 3.5486 - accuracy: 0.0331\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 2.9983 - accuracy: 0.1255\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 2.3845 - accuracy: 0.2827\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 2.0013 - accuracy: 0.3900\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 1.7368 - accuracy: 0.4754\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 1.5034 - accuracy: 0.5402\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 1.2626 - accuracy: 0.6128\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 1.0198 - accuracy: 0.6935\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.8115 - accuracy: 0.7550\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.6969 - accuracy: 0.7894\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.5701 - accuracy: 0.8259\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.4898 - accuracy: 0.8491\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.4251 - accuracy: 0.8672\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.3880 - accuracy: 0.8785\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.3392 - accuracy: 0.8953\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.3117 - accuracy: 0.9030\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2657 - accuracy: 0.9184\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.2269 - accuracy: 0.9297\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2102 - accuracy: 0.9341\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1924 - accuracy: 0.9402\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.1712 - accuracy: 0.9461\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1513 - accuracy: 0.9540\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.1511 - accuracy: 0.9549\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1315 - accuracy: 0.9591\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1277 - accuracy: 0.9635\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1132 - accuracy: 0.9661\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1085 - accuracy: 0.9694\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1142 - accuracy: 0.9654\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1003 - accuracy: 0.9704\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0871 - accuracy: 0.9747\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0811 - accuracy: 0.9776\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0829 - accuracy: 0.9755\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0902 - accuracy: 0.9753\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0747 - accuracy: 0.9786\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0676 - accuracy: 0.9810\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0671 - accuracy: 0.9821\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0696 - accuracy: 0.9826\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0726 - accuracy: 0.9787\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0731 - accuracy: 0.9799\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0690 - accuracy: 0.9805\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0419 - accuracy: 0.9915\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0636 - accuracy: 0.9837\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0626 - accuracy: 0.9834\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0457 - accuracy: 0.9885\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0618 - accuracy: 0.9840\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0594 - accuracy: 0.9841\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0565 - accuracy: 0.9848\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0432 - accuracy: 0.9904\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0627 - accuracy: 0.9845\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0463 - accuracy: 0.9891\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0467 - accuracy: 0.9886\n",
      "Score for fold  2: loss of 0.0723741352558136; accuracy of 97.82986044883728%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 51s 113ms/step - loss: 4.0299 - accuracy: 0.0486\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 3.2259 - accuracy: 0.0844\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 3.1041 - accuracy: 0.0921\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 2.8029 - accuracy: 0.1596\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 2.3122 - accuracy: 0.2898\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 1.8070 - accuracy: 0.4424\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 1.4355 - accuracy: 0.5644\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 1.1559 - accuracy: 0.6467\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.9744 - accuracy: 0.7051\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.8149 - accuracy: 0.7530\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.6914 - accuracy: 0.7890\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.6075 - accuracy: 0.8181\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.5136 - accuracy: 0.8477\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.4625 - accuracy: 0.8609\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.4056 - accuracy: 0.8810\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3588 - accuracy: 0.8957\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.3034 - accuracy: 0.9102\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.2691 - accuracy: 0.9240\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.2360 - accuracy: 0.9361\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.2170 - accuracy: 0.9401\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1935 - accuracy: 0.9461\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1746 - accuracy: 0.9539\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1687 - accuracy: 0.9532\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1336 - accuracy: 0.9679\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1248 - accuracy: 0.9701\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1338 - accuracy: 0.9661\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1266 - accuracy: 0.9689\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1093 - accuracy: 0.9740\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1052 - accuracy: 0.9761\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1034 - accuracy: 0.9759\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1058 - accuracy: 0.9752\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0923 - accuracy: 0.9806\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0938 - accuracy: 0.9792\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1001 - accuracy: 0.9768\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1010 - accuracy: 0.9780\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0776 - accuracy: 0.9846\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0836 - accuracy: 0.9822\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0924 - accuracy: 0.9795\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0807 - accuracy: 0.9840\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0913 - accuracy: 0.9807\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0898 - accuracy: 0.9801\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0789 - accuracy: 0.9835\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0916 - accuracy: 0.9807\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0852 - accuracy: 0.9830\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0826 - accuracy: 0.9848\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0886 - accuracy: 0.9824\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0845 - accuracy: 0.9842\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0912 - accuracy: 0.9821\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0957 - accuracy: 0.9806\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0953 - accuracy: 0.9814\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0816 - accuracy: 0.9861\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0887 - accuracy: 0.9844\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.0955 - accuracy: 0.9813\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1029 - accuracy: 0.9811\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1046 - accuracy: 0.9812\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1001 - accuracy: 0.9823\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1043 - accuracy: 0.9808\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1146 - accuracy: 0.9791\n",
      "Epoch 59/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1061 - accuracy: 0.9832\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1180 - accuracy: 0.9806\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 36s 113ms/step - loss: 0.1195 - accuracy: 0.9799\n",
      "Score for fold  3: loss of 0.11512136459350586; accuracy of 96.8397319316864%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.15781894326210022 - Accuracy: 95.95485925674438%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.0723741352558136 - Accuracy: 97.82986044883728%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.11512136459350586 - Accuracy: 96.8397319316864%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 96.87481721242268 (+- 0.7658679608917379)\n",
      "> Loss: 0.11510481437047322\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 12 without noise\n",
      "The loss is 0.11424306780099869 and accuracy is 96.34259343147278%\n",
      "For subject 12 and noise 5 dB\n",
      "The loss is 0.17101725935935974 and accuracy is 95.41666507720947%\n",
      "For subject 12 and noise 10 dB\n",
      "The loss is 0.1823321431875229 and accuracy is 95.37037014961243%\n",
      "For subject 12 and noise 15 dB\n",
      "The loss is 0.18715818226337433 and accuracy is 95.30092477798462%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 13\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17279, 128, 102, 1)\n",
      "The input label shape is (17279,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4320, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 63s 138ms/step - loss: 4.1932 - accuracy: 0.0331\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 3.5253 - accuracy: 0.0656\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 2.7038 - accuracy: 0.2375\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 1.9305 - accuracy: 0.4341\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 1.4502 - accuracy: 0.5776\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 1.0847 - accuracy: 0.6875\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.8287 - accuracy: 0.7711\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.6782 - accuracy: 0.8090\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.5506 - accuracy: 0.8437\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.4879 - accuracy: 0.8600\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 44s 138ms/step - loss: 0.4202 - accuracy: 0.8803\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.3714 - accuracy: 0.8980\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.3233 - accuracy: 0.9075\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.3385 - accuracy: 0.8996\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2759 - accuracy: 0.9191\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2722 - accuracy: 0.9226\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.2504 - accuracy: 0.9255\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2445 - accuracy: 0.9285\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2393 - accuracy: 0.9245\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2087 - accuracy: 0.9379\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.2190 - accuracy: 0.9332\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1919 - accuracy: 0.9409\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.1944 - accuracy: 0.9428\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.1627 - accuracy: 0.9525\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1831 - accuracy: 0.9444\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1525 - accuracy: 0.9546\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1703 - accuracy: 0.9471\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1644 - accuracy: 0.9485\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1575 - accuracy: 0.9516\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1254 - accuracy: 0.9616\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1424 - accuracy: 0.9555\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1365 - accuracy: 0.9592\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1142 - accuracy: 0.9651\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.1303 - accuracy: 0.9583\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0975 - accuracy: 0.9707\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1055 - accuracy: 0.9684\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0905 - accuracy: 0.9720\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0871 - accuracy: 0.9737\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1080 - accuracy: 0.9655\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0893 - accuracy: 0.9707\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0677 - accuracy: 0.9799\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0656 - accuracy: 0.9789\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0931 - accuracy: 0.9722\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.0760 - accuracy: 0.9756\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0692 - accuracy: 0.9773\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0677 - accuracy: 0.9788\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.0582 - accuracy: 0.9835\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0546 - accuracy: 0.9832\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.0614 - accuracy: 0.9809\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.0514 - accuracy: 0.9851\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0624 - accuracy: 0.9821\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.0669 - accuracy: 0.9795\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0332 - accuracy: 0.9911\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0605 - accuracy: 0.9821\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0640 - accuracy: 0.9814\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0470 - accuracy: 0.9855\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0533 - accuracy: 0.9841\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0531 - accuracy: 0.9843\n",
      "Epoch 59/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0470 - accuracy: 0.9863\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0610 - accuracy: 0.9811\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0266 - accuracy: 0.9931\n",
      "Epoch 62/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0249 - accuracy: 0.9936\n",
      "Epoch 63/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0535 - accuracy: 0.9843\n",
      "Epoch 64/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0618 - accuracy: 0.9820\n",
      "Epoch 65/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0378 - accuracy: 0.9884\n",
      "Epoch 66/150\n",
      "320/320 [==============================] - 46s 142ms/step - loss: 0.0496 - accuracy: 0.9863\n",
      "Epoch 67/150\n",
      "320/320 [==============================] - 45s 142ms/step - loss: 0.0400 - accuracy: 0.9885\n",
      "Epoch 68/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0306 - accuracy: 0.9918\n",
      "Epoch 69/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0386 - accuracy: 0.9900\n",
      "Epoch 70/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0456 - accuracy: 0.9865\n",
      "Epoch 71/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.0297 - accuracy: 0.9931\n",
      "Epoch 72/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.0455 - accuracy: 0.9877\n",
      "Score for fold  1: loss of 0.1393759846687317; accuracy of 96.09375%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 66s 144ms/step - loss: 4.5584 - accuracy: 0.0290\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 3.6211 - accuracy: 0.0283\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 3.5827 - accuracy: 0.0300\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 3.5710 - accuracy: 0.0278\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 3.5616 - accuracy: 0.0290\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 3.5591 - accuracy: 0.0303\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 3.5552 - accuracy: 0.0297\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 3.5508 - accuracy: 0.0286\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 3.5220 - accuracy: 0.0418\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 3.3461 - accuracy: 0.0745\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 2.9273 - accuracy: 0.1668\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 2.3010 - accuracy: 0.3209\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 1.8005 - accuracy: 0.4587\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 1.4165 - accuracy: 0.5790\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 1.1395 - accuracy: 0.6562\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.9116 - accuracy: 0.7251\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.7193 - accuracy: 0.7852\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.5739 - accuracy: 0.8298\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.4599 - accuracy: 0.8651\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.3900 - accuracy: 0.8838\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.2984 - accuracy: 0.9123\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.2648 - accuracy: 0.9220\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.2064 - accuracy: 0.9397\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1892 - accuracy: 0.9442\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.1493 - accuracy: 0.9572\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1382 - accuracy: 0.9612\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.1379 - accuracy: 0.9572\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.1013 - accuracy: 0.9739\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 46s 144ms/step - loss: 0.1010 - accuracy: 0.9715\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 46s 143ms/step - loss: 0.1005 - accuracy: 0.9710\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0875 - accuracy: 0.9758\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0792 - accuracy: 0.9790\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0814 - accuracy: 0.9774\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0745 - accuracy: 0.9812\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0600 - accuracy: 0.9832\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0703 - accuracy: 0.9806\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0608 - accuracy: 0.9854\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0489 - accuracy: 0.9885\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0729 - accuracy: 0.9799\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0563 - accuracy: 0.9859\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0535 - accuracy: 0.9868\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0567 - accuracy: 0.9849\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0454 - accuracy: 0.9890\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0414 - accuracy: 0.9900\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0452 - accuracy: 0.9883\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0505 - accuracy: 0.9873\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0434 - accuracy: 0.9902\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0455 - accuracy: 0.9879\n",
      "Epoch 49/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0441 - accuracy: 0.9893\n",
      "Epoch 50/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0616 - accuracy: 0.9838\n",
      "Epoch 51/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0238 - accuracy: 0.9955\n",
      "Epoch 52/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0218 - accuracy: 0.9964\n",
      "Epoch 53/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0539 - accuracy: 0.9862\n",
      "Epoch 54/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0374 - accuracy: 0.9920\n",
      "Epoch 55/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0440 - accuracy: 0.9897\n",
      "Epoch 56/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0425 - accuracy: 0.9898\n",
      "Epoch 57/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0381 - accuracy: 0.9908\n",
      "Epoch 58/150\n",
      "320/320 [==============================] - 44s 139ms/step - loss: 0.0173 - accuracy: 0.9978\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0330 - accuracy: 0.9931\n",
      "Epoch 60/150\n",
      "320/320 [==============================] - 45s 141ms/step - loss: 0.0465 - accuracy: 0.9891\n",
      "Epoch 61/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0371 - accuracy: 0.9921\n",
      "Epoch 62/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 63/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0436 - accuracy: 0.9898\n",
      "Epoch 64/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0325 - accuracy: 0.9928\n",
      "Epoch 65/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0302 - accuracy: 0.9930\n",
      "Epoch 66/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0307 - accuracy: 0.9938\n",
      "Epoch 67/150\n",
      "320/320 [==============================] - 45s 139ms/step - loss: 0.0440 - accuracy: 0.9896\n",
      "Epoch 68/150\n",
      "320/320 [==============================] - 45s 140ms/step - loss: 0.0266 - accuracy: 0.9956\n",
      "Score for fold  2: loss of 0.08181475847959518; accuracy of 97.69096970558167%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "320/320 [==============================] - 51s 114ms/step - loss: 3.9824 - accuracy: 0.0364\n",
      "Epoch 2/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 3.4811 - accuracy: 0.0602\n",
      "Epoch 3/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 3.3478 - accuracy: 0.0817\n",
      "Epoch 4/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 3.0619 - accuracy: 0.1378\n",
      "Epoch 5/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 2.4740 - accuracy: 0.2802\n",
      "Epoch 6/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 1.8358 - accuracy: 0.4592\n",
      "Epoch 7/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 1.4328 - accuracy: 0.5786\n",
      "Epoch 8/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 1.1269 - accuracy: 0.6776\n",
      "Epoch 9/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.8845 - accuracy: 0.7490\n",
      "Epoch 10/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.7341 - accuracy: 0.7968\n",
      "Epoch 11/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.6008 - accuracy: 0.8319\n",
      "Epoch 12/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.5077 - accuracy: 0.8610\n",
      "Epoch 13/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.4198 - accuracy: 0.8884\n",
      "Epoch 14/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.3668 - accuracy: 0.9004\n",
      "Epoch 15/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.3011 - accuracy: 0.9201\n",
      "Epoch 16/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.2532 - accuracy: 0.9366\n",
      "Epoch 17/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.2273 - accuracy: 0.9398\n",
      "Epoch 18/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1982 - accuracy: 0.9522\n",
      "Epoch 19/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.1689 - accuracy: 0.9595\n",
      "Epoch 20/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1554 - accuracy: 0.9636\n",
      "Epoch 21/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.1374 - accuracy: 0.9666\n",
      "Epoch 22/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1267 - accuracy: 0.9686\n",
      "Epoch 23/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1120 - accuracy: 0.9760\n",
      "Epoch 24/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.1102 - accuracy: 0.9753\n",
      "Epoch 25/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.1080 - accuracy: 0.9766\n",
      "Epoch 26/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0985 - accuracy: 0.9794\n",
      "Epoch 27/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0980 - accuracy: 0.9797\n",
      "Epoch 28/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0890 - accuracy: 0.9804\n",
      "Epoch 29/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 0.0922 - accuracy: 0.9805\n",
      "Epoch 30/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0795 - accuracy: 0.9846\n",
      "Epoch 31/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0867 - accuracy: 0.9826\n",
      "Epoch 32/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0826 - accuracy: 0.9845\n",
      "Epoch 33/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0812 - accuracy: 0.9832\n",
      "Epoch 34/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0810 - accuracy: 0.9852\n",
      "Epoch 35/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0821 - accuracy: 0.9828\n",
      "Epoch 36/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0785 - accuracy: 0.9867\n",
      "Epoch 37/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0795 - accuracy: 0.9849\n",
      "Epoch 38/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0758 - accuracy: 0.9878\n",
      "Epoch 39/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0840 - accuracy: 0.9835\n",
      "Epoch 40/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0786 - accuracy: 0.9866\n",
      "Epoch 41/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0894 - accuracy: 0.9825\n",
      "Epoch 42/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0819 - accuracy: 0.9863\n",
      "Epoch 43/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0777 - accuracy: 0.9874\n",
      "Epoch 44/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0841 - accuracy: 0.9861\n",
      "Epoch 45/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0846 - accuracy: 0.9862\n",
      "Epoch 46/150\n",
      "320/320 [==============================] - 37s 114ms/step - loss: 0.0860 - accuracy: 0.9860\n",
      "Epoch 47/150\n",
      "320/320 [==============================] - 37s 115ms/step - loss: 0.0885 - accuracy: 0.9863\n",
      "Epoch 48/150\n",
      "320/320 [==============================] - 36s 114ms/step - loss: 0.0833 - accuracy: 0.9878\n",
      "Score for fold  3: loss of 0.1150326281785965; accuracy of 96.77027463912964%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.1393759846687317 - Accuracy: 96.09375%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.08181475847959518 - Accuracy: 97.69096970558167%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.1150326281785965 - Accuracy: 96.77027463912964%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 96.85166478157043 (+- 0.6545970584715939)\n",
      "> Loss: 0.11207445710897446\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 13 without noise\n",
      "The loss is 0.12343277037143707 and accuracy is 96.34259343147278%\n",
      "For subject 13 and noise 5 dB\n",
      "The loss is 0.2194284051656723 and accuracy is 95.09259462356567%\n",
      "For subject 13 and noise 10 dB\n",
      "The loss is 0.24785825610160828 and accuracy is 94.88425850868225%\n",
      "For subject 13 and noise 15 dB\n",
      "The loss is 0.251186341047287 and accuracy is 94.6759283542633%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 14\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17408, 128, 102, 1)\n",
      "The input label shape is (17408,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4352, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 65s 142ms/step - loss: 4.1919 - accuracy: 0.0290\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 46s 143ms/step - loss: 3.6345 - accuracy: 0.0481\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 3.1377 - accuracy: 0.1392\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 2.2467 - accuracy: 0.3434\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 1.7238 - accuracy: 0.4857\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 1.3682 - accuracy: 0.5971\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 1.1346 - accuracy: 0.6637\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.9222 - accuracy: 0.7296\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.7664 - accuracy: 0.7769\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.6578 - accuracy: 0.8071\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.5709 - accuracy: 0.8326\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.5127 - accuracy: 0.8483\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.4607 - accuracy: 0.8614\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.4283 - accuracy: 0.8712\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3889 - accuracy: 0.8811\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.3556 - accuracy: 0.8941\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3420 - accuracy: 0.8974\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3297 - accuracy: 0.8963\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.2844 - accuracy: 0.9122\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2878 - accuracy: 0.9122\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2567 - accuracy: 0.9225\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.2436 - accuracy: 0.9287\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2577 - accuracy: 0.9199\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2104 - accuracy: 0.9372\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2361 - accuracy: 0.9258\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2001 - accuracy: 0.9379\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2022 - accuracy: 0.9377\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.1767 - accuracy: 0.9452\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.1743 - accuracy: 0.9459\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.1670 - accuracy: 0.9446\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1820 - accuracy: 0.9422\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1850 - accuracy: 0.9417\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1389 - accuracy: 0.9562\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1629 - accuracy: 0.9480\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.1359 - accuracy: 0.9580\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1173 - accuracy: 0.9642\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.1206 - accuracy: 0.9636\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.1367 - accuracy: 0.9562\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0919 - accuracy: 0.9723\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0977 - accuracy: 0.9697\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0963 - accuracy: 0.9699\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0969 - accuracy: 0.9703\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1035 - accuracy: 0.9665\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0729 - accuracy: 0.9780\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.1017 - accuracy: 0.9689\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0825 - accuracy: 0.9744\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0851 - accuracy: 0.9737\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0952 - accuracy: 0.9709\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0730 - accuracy: 0.9779\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0739 - accuracy: 0.9783\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0604 - accuracy: 0.9813\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0961 - accuracy: 0.9702\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0634 - accuracy: 0.9804\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0554 - accuracy: 0.9838\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0567 - accuracy: 0.9832\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0613 - accuracy: 0.9819\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0999 - accuracy: 0.9690\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0481 - accuracy: 0.9863\n",
      "Epoch 59/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0603 - accuracy: 0.9822\n",
      "Epoch 60/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0486 - accuracy: 0.9862\n",
      "Epoch 61/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0756 - accuracy: 0.9781\n",
      "Epoch 62/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0555 - accuracy: 0.9841\n",
      "Epoch 63/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0435 - accuracy: 0.9872\n",
      "Epoch 64/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0569 - accuracy: 0.9831\n",
      "Epoch 65/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0501 - accuracy: 0.9849\n",
      "Epoch 66/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0641 - accuracy: 0.9798\n",
      "Epoch 67/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0369 - accuracy: 0.9907\n",
      "Epoch 68/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0642 - accuracy: 0.9815\n",
      "Epoch 69/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0525 - accuracy: 0.9846\n",
      "Epoch 70/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0513 - accuracy: 0.9842\n",
      "Epoch 71/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0516 - accuracy: 0.9852\n",
      "Epoch 72/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0403 - accuracy: 0.9885\n",
      "Epoch 73/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0579 - accuracy: 0.9845\n",
      "Epoch 74/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0520 - accuracy: 0.9848\n",
      "Epoch 75/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0259 - accuracy: 0.9941\n",
      "Epoch 76/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0563 - accuracy: 0.9836\n",
      "Epoch 77/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.0664 - accuracy: 0.9828\n",
      "Epoch 78/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0318 - accuracy: 0.9927\n",
      "Epoch 79/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0365 - accuracy: 0.9894\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0548 - accuracy: 0.9847\n",
      "Epoch 81/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0547 - accuracy: 0.9834\n",
      "Epoch 82/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0366 - accuracy: 0.9910\n",
      "Epoch 83/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0273 - accuracy: 0.9933\n",
      "Epoch 84/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.0554 - accuracy: 0.9817\n",
      "Epoch 85/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0513 - accuracy: 0.9840\n",
      "Score for fold  1: loss of 0.11009860783815384; accuracy of 96.57074213027954%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 63s 138ms/step - loss: 4.4950 - accuracy: 0.0321\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 3.6128 - accuracy: 0.0303\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 3.5708 - accuracy: 0.0333\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 3.5125 - accuracy: 0.0480\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 3.4718 - accuracy: 0.0561\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 3.4323 - accuracy: 0.0611\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 3.2913 - accuracy: 0.0863\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 3.0248 - accuracy: 0.1361\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 2.6733 - accuracy: 0.2084\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 2.3973 - accuracy: 0.2807\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 2.1379 - accuracy: 0.3473\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 1.8898 - accuracy: 0.4121\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 1.6609 - accuracy: 0.4799\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 1.4685 - accuracy: 0.5442\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 1.2611 - accuracy: 0.6055\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 1.0727 - accuracy: 0.6651\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.8997 - accuracy: 0.7136\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.7675 - accuracy: 0.7631\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.6611 - accuracy: 0.7990\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.5767 - accuracy: 0.8195\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.4875 - accuracy: 0.8471\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.4274 - accuracy: 0.8694\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.3749 - accuracy: 0.8837\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.3365 - accuracy: 0.8976\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.3047 - accuracy: 0.9097\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2739 - accuracy: 0.9182\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2670 - accuracy: 0.9233\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2455 - accuracy: 0.9322\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2332 - accuracy: 0.9322\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2082 - accuracy: 0.9405\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.2070 - accuracy: 0.9414\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.2008 - accuracy: 0.9398\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1883 - accuracy: 0.9460\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.1761 - accuracy: 0.9508\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1682 - accuracy: 0.9524\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1662 - accuracy: 0.9533\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1479 - accuracy: 0.9603\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1433 - accuracy: 0.9611\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1446 - accuracy: 0.9605\n",
      "Epoch 40/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1424 - accuracy: 0.9601\n",
      "Epoch 41/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1313 - accuracy: 0.9631\n",
      "Epoch 42/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1319 - accuracy: 0.9638\n",
      "Epoch 43/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1121 - accuracy: 0.9681\n",
      "Epoch 44/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1359 - accuracy: 0.9616\n",
      "Epoch 45/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.1173 - accuracy: 0.9683\n",
      "Epoch 46/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1142 - accuracy: 0.9677\n",
      "Epoch 47/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1173 - accuracy: 0.9654\n",
      "Epoch 48/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1070 - accuracy: 0.9718\n",
      "Epoch 49/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1106 - accuracy: 0.9673\n",
      "Epoch 50/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.1165 - accuracy: 0.9667\n",
      "Epoch 51/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0820 - accuracy: 0.9788\n",
      "Epoch 52/150\n",
      "323/323 [==============================] - 45s 138ms/step - loss: 0.1019 - accuracy: 0.9716\n",
      "Epoch 53/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0816 - accuracy: 0.9811\n",
      "Epoch 54/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.1017 - accuracy: 0.9725\n",
      "Epoch 55/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0808 - accuracy: 0.9798\n",
      "Epoch 56/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0880 - accuracy: 0.9768\n",
      "Epoch 57/150\n",
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0911 - accuracy: 0.9760\n",
      "Epoch 58/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0885 - accuracy: 0.9780\n",
      "Epoch 59/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0641 - accuracy: 0.9844\n",
      "Epoch 60/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0797 - accuracy: 0.9809\n",
      "Epoch 61/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0686 - accuracy: 0.9841\n",
      "Epoch 62/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0831 - accuracy: 0.9779\n",
      "Epoch 63/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0843 - accuracy: 0.9782\n",
      "Epoch 64/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0708 - accuracy: 0.9835\n",
      "Epoch 65/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0701 - accuracy: 0.9830\n",
      "Epoch 66/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0814 - accuracy: 0.9807\n",
      "Epoch 67/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0695 - accuracy: 0.9840\n",
      "Epoch 68/150\n",
      "323/323 [==============================] - 45s 139ms/step - loss: 0.0628 - accuracy: 0.9871\n",
      "Epoch 69/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0555 - accuracy: 0.9893\n",
      "Epoch 70/150\n",
      "323/323 [==============================] - 46s 141ms/step - loss: 0.0792 - accuracy: 0.9815\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 45s 141ms/step - loss: 0.0699 - accuracy: 0.9847\n",
      "Epoch 72/150\n",
      "323/323 [==============================] - 45s 140ms/step - loss: 0.0652 - accuracy: 0.9857\n",
      "Epoch 73/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0664 - accuracy: 0.9854\n",
      "Epoch 74/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0772 - accuracy: 0.9809\n",
      "Epoch 75/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0784 - accuracy: 0.9812\n",
      "Epoch 76/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.0611 - accuracy: 0.9882\n",
      "Epoch 77/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.0683 - accuracy: 0.9860\n",
      "Epoch 78/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.0685 - accuracy: 0.9866\n",
      "Epoch 79/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.0711 - accuracy: 0.9840\n",
      "Score for fold  2: loss of 0.0649205893278122; accuracy of 98.20782542228699%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "323/323 [==============================] - 67s 143ms/step - loss: 3.8453 - accuracy: 0.0375\n",
      "Epoch 2/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 3.3864 - accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 3.0715 - accuracy: 0.1309\n",
      "Epoch 4/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 2.6172 - accuracy: 0.2456\n",
      "Epoch 5/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 1.9832 - accuracy: 0.4160\n",
      "Epoch 6/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 1.5608 - accuracy: 0.5322\n",
      "Epoch 7/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 1.2302 - accuracy: 0.6306\n",
      "Epoch 8/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.9590 - accuracy: 0.7189\n",
      "Epoch 9/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.7965 - accuracy: 0.7681\n",
      "Epoch 10/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.6593 - accuracy: 0.8127\n",
      "Epoch 11/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.5712 - accuracy: 0.8410\n",
      "Epoch 12/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.4986 - accuracy: 0.8608\n",
      "Epoch 13/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.4474 - accuracy: 0.8770\n",
      "Epoch 14/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.4080 - accuracy: 0.8895\n",
      "Epoch 15/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.3686 - accuracy: 0.8986\n",
      "Epoch 16/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.3409 - accuracy: 0.9112\n",
      "Epoch 17/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3253 - accuracy: 0.9141\n",
      "Epoch 18/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.3003 - accuracy: 0.9229\n",
      "Epoch 19/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2836 - accuracy: 0.9280\n",
      "Epoch 20/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2753 - accuracy: 0.9331\n",
      "Epoch 21/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.2626 - accuracy: 0.9349\n",
      "Epoch 22/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2523 - accuracy: 0.9405\n",
      "Epoch 23/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2405 - accuracy: 0.9455\n",
      "Epoch 24/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2432 - accuracy: 0.9420\n",
      "Epoch 25/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2431 - accuracy: 0.9413\n",
      "Epoch 26/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2427 - accuracy: 0.9454\n",
      "Epoch 27/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2391 - accuracy: 0.9463\n",
      "Epoch 28/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.2351 - accuracy: 0.9479\n",
      "Epoch 29/150\n",
      "323/323 [==============================] - 47s 144ms/step - loss: 0.2367 - accuracy: 0.9511\n",
      "Epoch 30/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2432 - accuracy: 0.9468\n",
      "Epoch 31/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2456 - accuracy: 0.9460\n",
      "Epoch 32/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2484 - accuracy: 0.9488\n",
      "Epoch 33/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2554 - accuracy: 0.9461\n",
      "Epoch 34/150\n",
      "323/323 [==============================] - 47s 145ms/step - loss: 0.2607 - accuracy: 0.9469\n",
      "Epoch 35/150\n",
      "323/323 [==============================] - 46s 142ms/step - loss: 0.2686 - accuracy: 0.9436\n",
      "Epoch 36/150\n",
      "323/323 [==============================] - 46s 144ms/step - loss: 0.2772 - accuracy: 0.9444\n",
      "Epoch 37/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.2897 - accuracy: 0.9427\n",
      "Epoch 38/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3093 - accuracy: 0.9417\n",
      "Epoch 39/150\n",
      "323/323 [==============================] - 46s 143ms/step - loss: 0.3254 - accuracy: 0.9343\n",
      "Score for fold  3: loss of 0.22868408262729645; accuracy of 94.41571831703186%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.11009860783815384 - Accuracy: 96.57074213027954%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.0649205893278122 - Accuracy: 98.20782542228699%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.22868408262729645 - Accuracy: 94.41571831703186%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 96.39809528986613 (+- 1.5529271871877222)\n",
      "> Loss: 0.1345677599310875\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 14 without noise\n",
      "The loss is 0.22776179015636444 and accuracy is 94.18658018112183%\n",
      "For subject 14 and noise 5 dB\n",
      "The loss is 0.2599852383136749 and accuracy is 93.47426295280457%\n",
      "For subject 14 and noise 10 dB\n",
      "The loss is 0.26426243782043457 and accuracy is 93.52021813392639%\n",
      "For subject 14 and noise 15 dB\n",
      "The loss is 0.2695937752723694 and accuracy is 93.31341981887817%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 15\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (17021, 128, 102, 1)\n",
      "The input label shape is (17021,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4256, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "316/316 [==============================] - 67s 141ms/step - loss: 4.2341 - accuracy: 0.0270\n",
      "Epoch 2/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 3.3303 - accuracy: 0.1041\n",
      "Epoch 3/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 2.1984 - accuracy: 0.3667\n",
      "Epoch 4/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 1.4273 - accuracy: 0.5824\n",
      "Epoch 5/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 1.0301 - accuracy: 0.6960\n",
      "Epoch 6/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.7919 - accuracy: 0.7711\n",
      "Epoch 7/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.6362 - accuracy: 0.8134\n",
      "Epoch 8/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.5371 - accuracy: 0.8457\n",
      "Epoch 9/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.4611 - accuracy: 0.8627\n",
      "Epoch 10/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.4320 - accuracy: 0.8692\n",
      "Epoch 11/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.3756 - accuracy: 0.8905\n",
      "Epoch 12/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 45s 142ms/step - loss: 0.3433 - accuracy: 0.8975\n",
      "Epoch 13/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.3193 - accuracy: 0.9024\n",
      "Epoch 14/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.3077 - accuracy: 0.9032\n",
      "Epoch 15/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.2690 - accuracy: 0.9161\n",
      "Epoch 16/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.2656 - accuracy: 0.9199\n",
      "Epoch 17/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.2135 - accuracy: 0.9378\n",
      "Epoch 18/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.2389 - accuracy: 0.9293\n",
      "Epoch 19/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.2361 - accuracy: 0.9301\n",
      "Epoch 20/150\n",
      "316/316 [==============================] - 45s 142ms/step - loss: 0.1792 - accuracy: 0.9441\n",
      "Epoch 21/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.2070 - accuracy: 0.9357\n",
      "Epoch 22/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.1821 - accuracy: 0.9452\n",
      "Epoch 23/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.1601 - accuracy: 0.9523\n",
      "Epoch 24/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.1469 - accuracy: 0.9547\n",
      "Epoch 25/150\n",
      "316/316 [==============================] - 45s 142ms/step - loss: 0.1854 - accuracy: 0.9414\n",
      "Epoch 26/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.1544 - accuracy: 0.9543\n",
      "Epoch 27/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.1356 - accuracy: 0.9567\n",
      "Epoch 28/150\n",
      "316/316 [==============================] - 46s 146ms/step - loss: 0.1487 - accuracy: 0.9535\n",
      "Epoch 29/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.1379 - accuracy: 0.9544\n",
      "Epoch 30/150\n",
      "316/316 [==============================] - 45s 141ms/step - loss: 0.1298 - accuracy: 0.9591\n",
      "Epoch 31/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.1278 - accuracy: 0.9602\n",
      "Epoch 32/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.1141 - accuracy: 0.9663\n",
      "Epoch 33/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.1007 - accuracy: 0.9689\n",
      "Epoch 34/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0935 - accuracy: 0.9703\n",
      "Epoch 35/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.1296 - accuracy: 0.9596\n",
      "Epoch 36/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0885 - accuracy: 0.9731\n",
      "Epoch 37/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1143 - accuracy: 0.9673\n",
      "Epoch 38/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0881 - accuracy: 0.9733\n",
      "Epoch 39/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0773 - accuracy: 0.9763\n",
      "Epoch 40/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0607 - accuracy: 0.9822\n",
      "Epoch 41/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0856 - accuracy: 0.9728\n",
      "Epoch 42/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0502 - accuracy: 0.9847\n",
      "Epoch 43/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0753 - accuracy: 0.9772\n",
      "Epoch 44/150\n",
      "316/316 [==============================] - 44s 138ms/step - loss: 0.0505 - accuracy: 0.9855\n",
      "Epoch 45/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1009 - accuracy: 0.9667\n",
      "Epoch 46/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0575 - accuracy: 0.9822\n",
      "Epoch 47/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0331 - accuracy: 0.9906\n",
      "Epoch 48/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0828 - accuracy: 0.9754\n",
      "Epoch 49/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0580 - accuracy: 0.9824\n",
      "Epoch 50/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0439 - accuracy: 0.9867\n",
      "Epoch 51/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0612 - accuracy: 0.9812\n",
      "Epoch 52/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0673 - accuracy: 0.9805\n",
      "Epoch 53/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0556 - accuracy: 0.9825\n",
      "Epoch 54/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0257 - accuracy: 0.9937\n",
      "Epoch 55/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0387 - accuracy: 0.9903\n",
      "Epoch 56/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.0677 - accuracy: 0.9805\n",
      "Epoch 57/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.0452 - accuracy: 0.9866\n",
      "Epoch 58/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0506 - accuracy: 0.9842\n",
      "Epoch 59/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0501 - accuracy: 0.9855\n",
      "Epoch 60/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.0536 - accuracy: 0.9845\n",
      "Epoch 61/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.0402 - accuracy: 0.9884\n",
      "Epoch 62/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0417 - accuracy: 0.9880\n",
      "Epoch 63/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.0288 - accuracy: 0.9922\n",
      "Epoch 64/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0512 - accuracy: 0.9844\n",
      "Score for fold  1: loss of 0.09843528270721436; accuracy of 97.32111096382141%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "316/316 [==============================] - 63s 138ms/step - loss: 4.6453 - accuracy: 0.0305\n",
      "Epoch 2/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 3.6110 - accuracy: 0.0293\n",
      "Epoch 3/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 3.5959 - accuracy: 0.0287\n",
      "Epoch 4/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 3.5684 - accuracy: 0.0322\n",
      "Epoch 5/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 3.4753 - accuracy: 0.0434\n",
      "Epoch 6/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 2.8804 - accuracy: 0.1539\n",
      "Epoch 7/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 2.1748 - accuracy: 0.3480\n",
      "Epoch 8/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 1.5677 - accuracy: 0.5233\n",
      "Epoch 9/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 1.1747 - accuracy: 0.6452\n",
      "Epoch 10/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.9444 - accuracy: 0.7160\n",
      "Epoch 11/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.7987 - accuracy: 0.7594\n",
      "Epoch 12/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.7096 - accuracy: 0.7854\n",
      "Epoch 13/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.6180 - accuracy: 0.8121\n",
      "Epoch 14/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.5254 - accuracy: 0.8415\n",
      "Epoch 15/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.4817 - accuracy: 0.8532\n",
      "Epoch 16/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.4265 - accuracy: 0.8646\n",
      "Epoch 17/150\n",
      "316/316 [==============================] - 45s 141ms/step - loss: 0.3621 - accuracy: 0.8904\n",
      "Epoch 18/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.3142 - accuracy: 0.9045\n",
      "Epoch 19/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.3005 - accuracy: 0.9077\n",
      "Epoch 20/150\n",
      "316/316 [==============================] - 44s 141ms/step - loss: 0.2574 - accuracy: 0.9195\n",
      "Epoch 21/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.2480 - accuracy: 0.9241\n",
      "Epoch 22/150\n",
      "316/316 [==============================] - 45s 141ms/step - loss: 0.2016 - accuracy: 0.9381\n",
      "Epoch 23/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1964 - accuracy: 0.9413\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1834 - accuracy: 0.9442\n",
      "Epoch 25/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.1633 - accuracy: 0.9514\n",
      "Epoch 26/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1378 - accuracy: 0.9594\n",
      "Epoch 27/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1327 - accuracy: 0.9593\n",
      "Epoch 28/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1233 - accuracy: 0.9625\n",
      "Epoch 29/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.1212 - accuracy: 0.9636\n",
      "Epoch 30/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.1200 - accuracy: 0.9628\n",
      "Epoch 31/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0990 - accuracy: 0.9721\n",
      "Epoch 32/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.1151 - accuracy: 0.9656\n",
      "Epoch 33/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0923 - accuracy: 0.9741\n",
      "Epoch 34/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0828 - accuracy: 0.9763\n",
      "Epoch 35/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0739 - accuracy: 0.9788\n",
      "Epoch 36/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0865 - accuracy: 0.9736\n",
      "Epoch 37/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0817 - accuracy: 0.9773\n",
      "Epoch 38/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0658 - accuracy: 0.9819\n",
      "Epoch 39/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0702 - accuracy: 0.9799\n",
      "Epoch 40/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0563 - accuracy: 0.9855\n",
      "Epoch 41/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0597 - accuracy: 0.9840\n",
      "Epoch 42/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0721 - accuracy: 0.9777\n",
      "Epoch 43/150\n",
      "316/316 [==============================] - 44s 139ms/step - loss: 0.0705 - accuracy: 0.9796\n",
      "Epoch 44/150\n",
      "316/316 [==============================] - 45s 142ms/step - loss: 0.0605 - accuracy: 0.9822\n",
      "Epoch 45/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0527 - accuracy: 0.9858\n",
      "Epoch 46/150\n",
      "316/316 [==============================] - 44s 140ms/step - loss: 0.0538 - accuracy: 0.9848\n",
      "Epoch 47/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0388 - accuracy: 0.9906\n",
      "Epoch 48/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0591 - accuracy: 0.9848\n",
      "Epoch 49/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0546 - accuracy: 0.9857\n",
      "Epoch 50/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0650 - accuracy: 0.9808\n",
      "Epoch 51/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0461 - accuracy: 0.9872\n",
      "Epoch 52/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0231 - accuracy: 0.9959\n",
      "Epoch 53/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0438 - accuracy: 0.9885\n",
      "Epoch 54/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0688 - accuracy: 0.9809\n",
      "Epoch 55/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0334 - accuracy: 0.9930\n",
      "Epoch 56/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0317 - accuracy: 0.9929\n",
      "Epoch 57/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0616 - accuracy: 0.9823\n",
      "Epoch 58/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0399 - accuracy: 0.9906\n",
      "Epoch 59/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0476 - accuracy: 0.9886\n",
      "Epoch 60/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0284 - accuracy: 0.9942\n",
      "Epoch 61/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0263 - accuracy: 0.9944\n",
      "Epoch 62/150\n",
      "316/316 [==============================] - 45s 142ms/step - loss: 0.0493 - accuracy: 0.9880\n",
      "Score for fold  2: loss of 0.07170752435922623; accuracy of 98.0965793132782%\n",
      "---------------------------------------------------\n",
      "Training for fold 3 -------\n",
      "Epoch 1/150\n",
      "316/316 [==============================] - 67s 143ms/step - loss: 4.1672 - accuracy: 0.0296\n",
      "Epoch 2/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 3.5862 - accuracy: 0.0342\n",
      "Epoch 3/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 3.0675 - accuracy: 0.1175\n",
      "Epoch 4/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 2.3302 - accuracy: 0.3119\n",
      "Epoch 5/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 1.6121 - accuracy: 0.5121\n",
      "Epoch 6/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 1.0989 - accuracy: 0.6666\n",
      "Epoch 7/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.7965 - accuracy: 0.7647\n",
      "Epoch 8/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.6441 - accuracy: 0.8085\n",
      "Epoch 9/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.5150 - accuracy: 0.8464\n",
      "Epoch 10/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.4362 - accuracy: 0.8683\n",
      "Epoch 11/150\n",
      "316/316 [==============================] - 46s 146ms/step - loss: 0.3610 - accuracy: 0.8952\n",
      "Epoch 12/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.3054 - accuracy: 0.9082\n",
      "Epoch 13/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.2622 - accuracy: 0.9227\n",
      "Epoch 14/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.2319 - accuracy: 0.9303\n",
      "Epoch 15/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.1967 - accuracy: 0.9415\n",
      "Epoch 16/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.1659 - accuracy: 0.9522\n",
      "Epoch 17/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.1470 - accuracy: 0.9595\n",
      "Epoch 18/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.1397 - accuracy: 0.9582\n",
      "Epoch 19/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.1226 - accuracy: 0.9685\n",
      "Epoch 20/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.1165 - accuracy: 0.9695\n",
      "Epoch 21/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0947 - accuracy: 0.9752\n",
      "Epoch 22/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0974 - accuracy: 0.9738\n",
      "Epoch 23/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0927 - accuracy: 0.9742\n",
      "Epoch 24/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0753 - accuracy: 0.9825\n",
      "Epoch 25/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0787 - accuracy: 0.9800\n",
      "Epoch 26/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0787 - accuracy: 0.9804\n",
      "Epoch 27/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0800 - accuracy: 0.9806\n",
      "Epoch 28/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0709 - accuracy: 0.9827\n",
      "Epoch 29/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0737 - accuracy: 0.9829\n",
      "Epoch 30/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0528 - accuracy: 0.9893\n",
      "Epoch 31/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0632 - accuracy: 0.9851\n",
      "Epoch 32/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0533 - accuracy: 0.9885\n",
      "Epoch 33/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0637 - accuracy: 0.9861\n",
      "Epoch 34/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.0577 - accuracy: 0.9885\n",
      "Epoch 35/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0452 - accuracy: 0.9913\n",
      "Epoch 36/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0652 - accuracy: 0.9846\n",
      "Epoch 37/150\n",
      "316/316 [==============================] - 46s 145ms/step - loss: 0.0486 - accuracy: 0.9904\n",
      "Epoch 38/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0484 - accuracy: 0.9907\n",
      "Epoch 39/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0557 - accuracy: 0.9874\n",
      "Epoch 40/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0560 - accuracy: 0.9885\n",
      "Epoch 41/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0501 - accuracy: 0.9907\n",
      "Epoch 42/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0570 - accuracy: 0.9881\n",
      "Epoch 43/150\n",
      "316/316 [==============================] - 45s 144ms/step - loss: 0.0468 - accuracy: 0.9904\n",
      "Epoch 44/150\n",
      "316/316 [==============================] - 45s 143ms/step - loss: 0.0546 - accuracy: 0.9882\n",
      "Epoch 45/150\n",
      "316/316 [==============================] - 46s 144ms/step - loss: 0.0523 - accuracy: 0.9898\n",
      "Score for fold  3: loss of 0.08479998260736465; accuracy of 97.4440336227417%\n",
      "Average Score per fold \n",
      "-----------------------------------------------\n",
      "> Fold 1 - Loss: 0.09843528270721436 - Accuracy: 97.32111096382141%\n",
      "-----------------------------------------------\n",
      "> Fold 2 - Loss: 0.07170752435922623 - Accuracy: 98.0965793132782%\n",
      "-----------------------------------------------\n",
      "> Fold 3 - Loss: 0.08479998260736465 - Accuracy: 97.4440336227417%\n",
      "-----------------------------------------------\n",
      "Average Metrics for all folds: \n",
      "> Accuracy: 97.62057463328044 (+- 0.3403065642954278)\n",
      "> Loss: 0.08498092989126842\n",
      "-----------------------------------------------\n",
      "************************************************\n",
      "For subject 15 without noise\n",
      "The loss is 0.090732641518116 and accuracy is 97.2744345664978%\n",
      "For subject 15 and noise 5 dB\n",
      "The loss is 0.18166568875312805 and accuracy is 96.12312316894531%\n",
      "For subject 15 and noise 10 dB\n",
      "The loss is 0.2052868902683258 and accuracy is 96.029132604599%\n",
      "For subject 15 and noise 15 dB\n",
      "The loss is 0.2053540050983429 and accuracy is 95.77067494392395%\n",
      "************************************************\n",
      "####################################################################################\n",
      "Loading subject 16\n",
      "####################################################################################\n",
      "Centred.\n",
      "Extended.\n",
      "Size of the input data is (16894, 128, 102, 1)\n",
      "The input label shape is (16894,)\n",
      "The total number of classes is 34\n",
      "************************************************************************************\n",
      "Loaded RAW input data\n",
      "************************************************************************************\n",
      "Adding noise to RAW input test data\n",
      "Size of the input test data is (4224, 128, 102, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/150\n",
      "313/313 [==============================] - 66s 143ms/step - loss: 4.2273 - accuracy: 0.0251\n",
      "Epoch 2/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 3.5709 - accuracy: 0.0590\n",
      "Epoch 3/150\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 2.7217 - accuracy: 0.2186\n",
      "Epoch 4/150\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 2.0200 - accuracy: 0.4174\n",
      "Epoch 5/150\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.5522 - accuracy: 0.5575\n",
      "Epoch 6/150\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.1995 - accuracy: 0.6630\n",
      "Epoch 7/150\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.9619 - accuracy: 0.7304\n",
      "Epoch 8/150\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7828 - accuracy: 0.7797\n",
      "Epoch 9/150\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6642 - accuracy: 0.8145\n",
      "Epoch 10/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.5725 - accuracy: 0.8388\n",
      "Epoch 11/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.4839 - accuracy: 0.8609\n",
      "Epoch 12/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.4445 - accuracy: 0.8697\n",
      "Epoch 13/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.3937 - accuracy: 0.8869\n",
      "Epoch 14/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.3458 - accuracy: 0.9007\n",
      "Epoch 15/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.3003 - accuracy: 0.9123\n",
      "Epoch 16/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.3098 - accuracy: 0.9070\n",
      "Epoch 17/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.2854 - accuracy: 0.9175\n",
      "Epoch 18/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.2543 - accuracy: 0.9260\n",
      "Epoch 19/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.2360 - accuracy: 0.9298\n",
      "Epoch 20/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.2346 - accuracy: 0.9301\n",
      "Epoch 21/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.2077 - accuracy: 0.9385\n",
      "Epoch 22/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1979 - accuracy: 0.9394\n",
      "Epoch 23/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1832 - accuracy: 0.9439\n",
      "Epoch 24/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.1746 - accuracy: 0.9488\n",
      "Epoch 25/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1708 - accuracy: 0.9502\n",
      "Epoch 26/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.1845 - accuracy: 0.9441\n",
      "Epoch 27/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1793 - accuracy: 0.9446\n",
      "Epoch 28/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1505 - accuracy: 0.9527\n",
      "Epoch 29/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.1516 - accuracy: 0.9524\n",
      "Epoch 30/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.1443 - accuracy: 0.9564\n",
      "Epoch 31/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1562 - accuracy: 0.9504\n",
      "Epoch 32/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1434 - accuracy: 0.9579\n",
      "Epoch 33/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.1154 - accuracy: 0.9667\n",
      "Epoch 34/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.1140 - accuracy: 0.9643\n",
      "Epoch 35/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1304 - accuracy: 0.9622\n",
      "Epoch 36/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1086 - accuracy: 0.9668\n",
      "Epoch 37/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0938 - accuracy: 0.9703\n",
      "Epoch 38/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1014 - accuracy: 0.9707\n",
      "Epoch 39/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0724 - accuracy: 0.9779\n",
      "Epoch 40/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0784 - accuracy: 0.9759\n",
      "Epoch 41/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.1145 - accuracy: 0.9667\n",
      "Epoch 42/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0674 - accuracy: 0.9795\n",
      "Epoch 43/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0598 - accuracy: 0.9822\n",
      "Epoch 44/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.0985 - accuracy: 0.9705\n",
      "Epoch 45/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0738 - accuracy: 0.9786\n",
      "Epoch 46/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0732 - accuracy: 0.9786\n",
      "Epoch 47/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0613 - accuracy: 0.9818\n",
      "Epoch 48/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0582 - accuracy: 0.9842\n",
      "Epoch 49/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0605 - accuracy: 0.9836\n",
      "Epoch 50/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0619 - accuracy: 0.9812\n",
      "Epoch 51/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0705 - accuracy: 0.9783\n",
      "Epoch 52/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0702 - accuracy: 0.9793\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0486 - accuracy: 0.9860\n",
      "Epoch 54/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0524 - accuracy: 0.9849\n",
      "Epoch 55/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0428 - accuracy: 0.9875\n",
      "Epoch 56/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0533 - accuracy: 0.9842\n",
      "Epoch 57/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0592 - accuracy: 0.9822\n",
      "Epoch 58/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0603 - accuracy: 0.9816\n",
      "Epoch 59/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0419 - accuracy: 0.9886\n",
      "Epoch 60/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0394 - accuracy: 0.9902\n",
      "Epoch 61/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0383 - accuracy: 0.9895\n",
      "Epoch 62/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0880 - accuracy: 0.9742\n",
      "Epoch 63/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0566 - accuracy: 0.9841\n",
      "Epoch 64/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0301 - accuracy: 0.9923\n",
      "Epoch 65/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0336 - accuracy: 0.9906\n",
      "Epoch 66/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0604 - accuracy: 0.9821\n",
      "Epoch 67/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0290 - accuracy: 0.9927\n",
      "Epoch 68/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0461 - accuracy: 0.9869\n",
      "Epoch 69/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0432 - accuracy: 0.9888\n",
      "Epoch 70/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0512 - accuracy: 0.9845\n",
      "Epoch 71/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0593 - accuracy: 0.9825\n",
      "Epoch 72/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0336 - accuracy: 0.9918\n",
      "Epoch 73/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0260 - accuracy: 0.9933\n",
      "Epoch 74/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0183 - accuracy: 0.9958\n",
      "Epoch 75/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0450 - accuracy: 0.9867\n",
      "Epoch 76/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0751 - accuracy: 0.9786\n",
      "Epoch 77/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0401 - accuracy: 0.9887\n",
      "Epoch 78/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0212 - accuracy: 0.9953\n",
      "Epoch 79/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0430 - accuracy: 0.9890\n",
      "Epoch 80/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0397 - accuracy: 0.9884\n",
      "Epoch 81/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0458 - accuracy: 0.9880\n",
      "Epoch 82/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0367 - accuracy: 0.9902\n",
      "Epoch 83/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0492 - accuracy: 0.9855\n",
      "Epoch 84/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0152 - accuracy: 0.9969\n",
      "Epoch 85/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0358 - accuracy: 0.9907\n",
      "Epoch 86/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0429 - accuracy: 0.9889\n",
      "Epoch 87/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0387 - accuracy: 0.9897\n",
      "Epoch 88/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0248 - accuracy: 0.9939\n",
      "Epoch 89/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0238 - accuracy: 0.9943\n",
      "Epoch 90/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0306 - accuracy: 0.9923\n",
      "Epoch 91/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0474 - accuracy: 0.9869\n",
      "Epoch 92/150\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0447 - accuracy: 0.9875\n",
      "Epoch 93/150\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.0176 - accuracy: 0.9970\n",
      "Epoch 94/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0174 - accuracy: 0.9960\n",
      "Epoch 95/150\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0531 - accuracy: 0.9861\n",
      "Epoch 96/150\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0240 - accuracy: 0.9943\n",
      "Epoch 97/150\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0335 - accuracy: 0.9910\n",
      "Epoch 98/150\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.0300 - accuracy: 0.9925\n",
      "Epoch 99/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0266 - accuracy: 0.9929\n",
      "Epoch 100/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0182 - accuracy: 0.9964\n",
      "Epoch 101/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0458 - accuracy: 0.9885\n",
      "Epoch 102/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0491 - accuracy: 0.9861\n",
      "Epoch 103/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0156 - accuracy: 0.9970\n",
      "Score for fold  1: loss of 0.03529352322220802; accuracy of 99.00568127632141%\n",
      "---------------------------------------------------\n",
      "Training for fold 2 -------\n",
      "Epoch 1/150\n",
      "313/313 [==============================] - 65s 143ms/step - loss: 4.5123 - accuracy: 0.0259\n",
      "Epoch 2/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 3.6184 - accuracy: 0.0280\n",
      "Epoch 3/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 3.5803 - accuracy: 0.0319\n",
      "Epoch 4/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 3.5659 - accuracy: 0.0295\n",
      "Epoch 5/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 3.5286 - accuracy: 0.0408\n",
      "Epoch 6/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 3.2472 - accuracy: 0.0902\n",
      "Epoch 7/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 2.6422 - accuracy: 0.2253\n",
      "Epoch 8/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 2.1131 - accuracy: 0.3760\n",
      "Epoch 9/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 1.6762 - accuracy: 0.5043\n",
      "Epoch 10/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 1.3568 - accuracy: 0.5973\n",
      "Epoch 11/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 1.1352 - accuracy: 0.6574\n",
      "Epoch 12/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.9289 - accuracy: 0.7213\n",
      "Epoch 13/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.7678 - accuracy: 0.7725\n",
      "Epoch 14/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.6051 - accuracy: 0.8192\n",
      "Epoch 15/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.4843 - accuracy: 0.8582\n",
      "Epoch 16/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.4188 - accuracy: 0.8757\n",
      "Epoch 17/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.3497 - accuracy: 0.8982\n",
      "Epoch 18/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.2935 - accuracy: 0.9131\n",
      "Epoch 19/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.2611 - accuracy: 0.9249\n",
      "Epoch 20/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.2303 - accuracy: 0.9316\n",
      "Epoch 21/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.1807 - accuracy: 0.9500\n",
      "Epoch 22/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.1524 - accuracy: 0.9583\n",
      "Epoch 23/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.1454 - accuracy: 0.9613\n",
      "Epoch 24/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.1487 - accuracy: 0.9596\n",
      "Epoch 25/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.1182 - accuracy: 0.9687\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 45s 144ms/step - loss: 0.1014 - accuracy: 0.9738\n",
      "Epoch 27/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0981 - accuracy: 0.9737\n",
      "Epoch 28/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0899 - accuracy: 0.9766\n",
      "Epoch 29/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0991 - accuracy: 0.9743\n",
      "Epoch 30/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0693 - accuracy: 0.9830\n",
      "Epoch 31/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0798 - accuracy: 0.9786\n",
      "Epoch 32/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.0892 - accuracy: 0.9773\n",
      "Epoch 33/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0663 - accuracy: 0.9839\n",
      "Epoch 34/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0662 - accuracy: 0.9842\n",
      "Epoch 35/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0624 - accuracy: 0.9844\n",
      "Epoch 36/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0475 - accuracy: 0.9895\n",
      "Epoch 37/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0782 - accuracy: 0.9794\n",
      "Epoch 38/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0557 - accuracy: 0.9865\n",
      "Epoch 39/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0491 - accuracy: 0.9880\n",
      "Epoch 40/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0707 - accuracy: 0.9829\n",
      "Epoch 41/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0437 - accuracy: 0.9906\n",
      "Epoch 42/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0504 - accuracy: 0.9877\n",
      "Epoch 43/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0490 - accuracy: 0.9887\n",
      "Epoch 44/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0555 - accuracy: 0.9861\n",
      "Epoch 45/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.0559 - accuracy: 0.9871\n",
      "Epoch 46/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0514 - accuracy: 0.9887\n",
      "Epoch 47/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0323 - accuracy: 0.9941\n",
      "Epoch 48/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0370 - accuracy: 0.9931\n",
      "Epoch 49/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0573 - accuracy: 0.9860\n",
      "Epoch 50/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0449 - accuracy: 0.9918\n",
      "Epoch 51/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0318 - accuracy: 0.9943\n",
      "Epoch 52/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.0536 - accuracy: 0.9883\n",
      "Epoch 53/150\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0429 - accuracy: 0.9912\n",
      "Epoch 54/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0402 - accuracy: 0.9921\n",
      "Epoch 55/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0403 - accuracy: 0.9927\n",
      "Epoch 56/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0484 - accuracy: 0.9897\n",
      "Epoch 57/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0415 - accuracy: 0.9918\n",
      "Epoch 58/150\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.0444 - accuracy: 0.9913\n",
      "Epoch 59/150\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0432 - accuracy: 0.9917\n",
      "Epoch 60/150\n",
      "106/313 [=========>....................] - ETA: 29s - loss: 0.0381 - accuracy: 0.9948"
     ]
    }
   ],
   "source": [
    "run_experiment(input_size, n_folds,  config.batch_size, config.epochs, start_subject, total_subject, session, path, \n",
    "                       input_type,n_channels, extend, extend_size, center, whiten, ratio, noise_db, std,\n",
    "                       config.projected_dim, config.patch_size, config.num_shift_blocks_per_stages,\n",
    "                        config.epsilon, config.mlp_dropout_rate, config.stochastic_depth_rate, config.num_div, config.shift_pixel,\n",
    "                        config.mlp_expand_ratio, type_of_experiment, config.lr_start, config.lr_max, config.weight_decay)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "shiftvit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "decomp",
   "language": "python",
   "name": "decomp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
